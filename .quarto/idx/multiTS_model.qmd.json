{"title":"Multivariate Time Series Modeling","markdown":{"yaml":{"title":"Multivariate Time Series Modeling","format":{"html":{"code-fold":true,"toc":true,"toc-depth":3,"embed-resources":true}}},"headingText":"Theoretical Framework","containsRefs":false,"markdown":"\n\n\n::: {.panel-tabset}\n\n## Literature Review\n\nUnderstanding NBA offensive efficiency requires a framework that separates team performance from game tempo. Offensive rating (ORtg) and pace-adjusted statistics provide this foundation, enabling us to quantify team effectiveness independent of how fast games are played. This distinction is critical for multivariate analysis because pace itself may be a strategic choice rather than a neutral contextual factor @kubatko2007starting.\n\nThe relationship between pace, spacing, and offensive efficiency involves bidirectional causality: faster tempo creates spacing opportunities through transition play, while better floor spacing enables teams to control pace more effectively @skinner2012problem. This co-evolution suggests that variables like ORtg, Pace, and 3PAr influence each other over time rather than following a simple cause-and-effect sequence @franks2015characterizing. Additionally, three-point attempts offer higher expected value than mid-range shots when accounting for shooting percentages, providing the mathematical foundation for the shot selection revolution @sliz2017investigation.\n\nRecent work reveals that teams with higher True Shooting percentage subsequently increased their three-point volume, suggesting reverse causation: success breeds strategy changes. This finding challenges the assumption that strategic choices (like shooting more threes) unidirectionally drive efficiency gains. Instead, teams that shot efficiently were more likely to adopt analytics-driven shot selection in future seasons, creating a feedback loop where strategy and performance reinforce each other @poropudas2023dean.\n\nThese dynamics motivate our multivariate approach. ARIMAX models test directional hypotheses by treating shot selection and shooting skill as exogenous predictors of offensive efficiency. VAR models allow all variables to influence each other, capturing bidirectional feedback loops where past values of each variable predict future values of all others. Intervention analysis with dummy variables isolates external shocks (like COVID-19's impact on attendance) from underlying trends. Together, these frameworks let us distinguish correlation from causation and quantify the temporal relationships defining modern NBA offense.\n\n\n## Proposed Models\n\n**Note**: **Models 4 and 5** still need to be completed for the final portfolio.\n\n### Model 1: Efficiency Drivers (VAR)\n`ORtg ~ Pace & 3PAr`\n\n\n### Model 2: Shot Selection & Efficiency (ARIMAX)\n**Response**: `ORtg ~ 3PAr + TS%`\n\n### Model 3: COVID Impact on Attendance (ARIMAX)\n`Attendance ~ ORtg + Pace`\n\n### Model 4: Pace Dynamics (VAR)\n`Pace ~ 3PAr + eFG%`\n\n### Model 5: Sports Betting & NBA Recovery (VAR)\n**Variables**: `DKNG ~ Attendance + ORtg`\n\n:::\n\n---\n\n```{r setup, warning=FALSE, message=FALSE}\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(forecast)\nlibrary(astsa)\nlibrary(xts)\nlibrary(tseries)\nlibrary(fpp2)\nlibrary(fma)\nlibrary(lubridate)\nlibrary(TSstudio)\nlibrary(quantmod)\nlibrary(tidyquant)\nlibrary(plotly)\nlibrary(readr)\nlibrary(dplyr)\nlibrary(vars)\nlibrary(patchwork)\nlibrary(kableExtra)\nlibrary(gridExtra)\n\ntheme_set(theme_minimal(base_size = 12))\n\nall_adv_files <- list.files(\"data/adv_stats\", pattern = \"*.csv\", full.names = TRUE)\n\nall_adv_data <- map_df(all_adv_files, function(file) {\n    season_str <- str_extract(basename(file), \"\\\\d{4}-\\\\d{2}\")\n    season_year <- as.numeric(str_sub(season_str, 1, 4)) + 1\n    df <- read_csv(file, show_col_types = FALSE)\n    df$Season <- season_year\n    return(df)\n})\n\nleague_avg <- all_adv_data %>%\n    group_by(Season) %>%\n    summarise(\n        ORtg = mean(`Unnamed: 10_level_0_ORtg`, na.rm = TRUE),\n        DRtg = mean(`Unnamed: 11_level_0_DRtg`, na.rm = TRUE),\n        Pace = mean(`Unnamed: 13_level_0_Pace`, na.rm = TRUE),\n        `3PAr` = mean(`Unnamed: 15_level_0_3PAr`, na.rm = TRUE),\n        `TS%` = mean(`Unnamed: 16_level_0_TS%`, na.rm = TRUE),\n        `eFG%` = mean(`Offense Four Factors_eFG%`, na.rm = TRUE),\n        Total_Attendance = sum(`Unnamed: 29_level_0_Attend.`, na.rm = TRUE),\n        .groups = \"drop\"\n    )\n\n# Create COVID dummy variable\nleague_avg <- league_avg %>%\n    mutate(COVID_Dummy = ifelse(Season %in% c(2020, 2021), 1, 0))\n```\n\n---\n\n# ARIMAX/SARIMAX Models\n\n## Shot Selection & Efficiency (ARIMAX)\n\n- **Response Variable**: `ORtg` (Offensive Rating)\n- **Exogenous Variables**: `3PAr` (3-Point Attempt Rate), `TS%` (True Shooting %)\n\nThis model addresses whether shooting more 3s and shooting accuracy explain offensive efficiency gains. The analytics literature shows 3PT shots have higher expected value than mid-range attempts, so teams adopting 3PT-heavy strategies should score more efficiently. `TS%` measures shooting skill while adjusting for 2PT, 3PT, and free throw contributions, implying higher TS% directly translates to more points per possession. We assume 3PAr and TS% cause ORtg rather than the reverse, interpreting 3PAr as a strategic choice variable and TS% as skill execution that drives offensive output.\n\n::: {.panel-tabset}\n\n## EDA & Correlation\n\n```{r arimax-eda, warning=FALSE, message=FALSE, fig.width=12, fig.height=8}\nts_ortg <- ts(league_avg$ORtg, start = 1980, frequency = 1)\nts_3par <- ts(league_avg$`3PAr`, start = 1980, frequency = 1)\nts_tspct <- ts(league_avg$`TS%`, start = 1980, frequency = 1)\n\np1 <- autoplot(ts_ortg) + labs(title = \"Offensive Rating (ORtg)\", y = \"ORtg\") + theme_minimal()\np2 <- autoplot(ts_3par) + labs(title = \"3-Point Attempt Rate (3PAr)\", y = \"3PAr\") + theme_minimal()\np3 <- autoplot(ts_tspct) + labs(title = \"True Shooting % (TS%)\", y = \"TS%\") + theme_minimal()\n\np1 / p2 / p3\n```\n\nThe time series reveal basketball's transformation at a glance: ORtg climbs gradually from ~104 in 1980 to ~113 in 2025. Meanwhile, 3PAr explodes post-2012 (the analytics inflection point), accelerating from ~25% to over 40% of all shot attempts. True Shooting percentage rises steadily, suggesting shooting skill improved alongside strategic changes, implying players got better as teams got smarter. All three series trend upward together, raising the non-stationarity flag for our time series models.\n\n```{r arimax-correlation, warning=FALSE, message=FALSE}\n# Correlation analysis\ncor_data <- league_avg %>% dplyr::select(ORtg, `3PAr`, `TS%`)\ncat(\"Correlation Matrix:\\n\")\nprint(round(cor(cor_data, use = \"complete.obs\"), 3))\n```\n\n```{r correlation-narrative-setup, echo=FALSE, message=FALSE}\ncor_ortg_3par <- round(cor(league_avg$ORtg, league_avg$`3PAr`), 3)\ncor_ortg_ts <- round(cor(league_avg$ORtg, league_avg$`TS%`), 3)\ncor_3par_ts <- round(cor(league_avg$`3PAr`, league_avg$`TS%`), 3)\n```\n\nThe correlations tell a clear story: ORtg vs 3PAr show strong positive relationship, meaning shooting more threes correlates with better offense. ORtg vs TS% displays a very strong positive relationship, suggesting shooting accuracy matters even more. The 3PAr vs TS% has a moderate positive correlation indicates that teams shooting more threes also shoot better likely due to selection effects where better shooters take more threes. Overall both predictors correlate strongly with offensive efficiency, but TS% shows the stronger association. The lesson: strategy matters, but execution matters more.\n\n## Model Fitting\n\n```{r arimax-auto, warning=FALSE, message=FALSE}\nxreg_matrix <- cbind(\n    `3PAr` = ts_3par,\n    `TS%` = ts_tspct\n)\n\narimax_auto <- auto.arima(ts_ortg,\n    xreg = xreg_matrix, seasonal = FALSE,\n    stepwise = FALSE, approximation = FALSE\n)\n\ncat(\"Selected model:\\n\")\nprint(arimax_auto)\n\ncat(\"\\n\\nModel Summary:\\n\")\nsummary(arimax_auto)\n```\n\n**Model Diagnostics**:\n\n```{r arimax-auto-diagnostics, warning=FALSE, message=FALSE, fig.width=12, fig.height=10}\ncheckresiduals(arimax_auto)\n\n# Ljung-Box test\nljung_auto <- Box.test(arimax_auto$residuals, lag = 10, type = \"Ljung-Box\")\n```\n\n\n```{r arimax-manual-lm, warning=FALSE, message=FALSE}\n# Create data frame\ndf_reg <- data.frame(\n    ORtg = as.numeric(ts_ortg),\n    PAr3 = as.numeric(ts_3par),\n    TSpct = as.numeric(ts_tspct)\n)\n\n# Fit regression\nlm_model <- lm(ORtg ~ PAr3 + TSpct, data = df_reg)\n\ncat(\"Linear Regression Results:\\n\")\nsummary(lm_model)\n```\n\n```{r regression-narrative-setup, echo=FALSE, message=FALSE}\nbeta_intercept <- round(coef(lm_model)[\"(Intercept)\"], 2)\nbeta_3par <- round(coef(lm_model)[\"PAr3\"], 2)\nbeta_ts <- round(coef(lm_model)[\"TSpct\"], 2)\n```\n\nThe regression equation reveals the mathematical relationship:\n\n$$\n\\text{ORtg} = `r beta_intercept` + `r beta_3par` \\times \\text{3PAr} + `r beta_ts` \\times \\text{TS\\%}\n$$\n\nHere's what this means on the court: a 1 percentage point increase in 3PAr leads to an ORtg increase of **`r beta_3par` points per 100 possessions** (moving from 30% to 31% of shots being threes adds `beta_3par` points to offensive rating). Similarly, a 1 percentage point increase in TS% leads to an ORtg increase of **`r beta_ts` points per 100 possessions** (improving from 55% to 56% True Shooting adds `beta_ts` points), emphasising that shooting accuracy has a stronger impact than shot selection.\n\n```{r arimax-manual-arima, warning=FALSE, message=FALSE}\nlm_residuals <- ts(residuals(lm_model), start = 1980, frequency = 1)\n\n# Plot residuals\nautoplot(lm_residuals) +\n    labs(title = \"Regression Residuals\", y = \"Residuals\") +\n    theme_minimal()\n\n# Fit ARIMA to residuals\narima_resid <- auto.arima(lm_residuals, seasonal = FALSE)\n\ncat(\"\\nARIMA model for residuals:\\n\")\nprint(arima_resid)\n\n# Diagnostics\ncheckresiduals(arima_resid)\n```\n\n\n```{r arimax-manual-final, warning=FALSE, message=FALSE}\narima_order <- arimaorder(arima_resid)\n\narimax_manual <- Arima(ts_ortg,\n    order = c(arima_order[1], arima_order[2], arima_order[3]),\n    xreg = xreg_matrix\n)\n\nprint(arimax_manual)\nprint(coef(arimax_manual))\n```\n\n## Cross-Validation\n\n```{r arimax-cv, warning=FALSE, message=FALSE, fig.width=12, fig.height=6}\ntrain_end <- 2019\ntest_start <- 2020\n\n# Split data\ntrain_ortg <- window(ts_ortg, end = train_end)\ntrain_3par <- window(ts_3par, end = train_end)\ntrain_tspct <- window(ts_tspct, end = train_end)\n\ntest_ortg <- window(ts_ortg, start = test_start)\ntest_3par <- window(ts_3par, start = test_start)\ntest_tspct <- window(ts_tspct, start = test_start)\n\nh <- length(test_ortg)\n\n# Prepare xreg for train/test\nxreg_train <- cbind(`3PAr` = train_3par, `TS%` = train_tspct)\nxreg_test <- cbind(`3PAr` = test_3par, `TS%` = test_tspct)\n\n# Model 1: auto.arima() method\nfit_auto <- auto.arima(train_ortg, xreg = xreg_train, seasonal = FALSE)\n\n# Model 2: Manual method\nfit_manual <- Arima(train_ortg,\n    order = c(arima_order[1], arima_order[2], arima_order[3]),\n    xreg = xreg_train\n)\n\n# Model 3: Simple ARIMA without exogenous (benchmark)\nfit_benchmark <- auto.arima(train_ortg, seasonal = FALSE)\n\n# Generate forecasts\nfc_auto <- forecast(fit_auto, xreg = xreg_test, h = h)\nfc_manual <- forecast(fit_manual, xreg = xreg_test, h = h)\nfc_benchmark <- forecast(fit_benchmark, h = h)\n\n# Calculate accuracy\nacc_auto <- accuracy(fc_auto, test_ortg)[2, c(\"RMSE\", \"MAE\", \"MAPE\")]\nacc_manual <- accuracy(fc_manual, test_ortg)[2, c(\"RMSE\", \"MAE\", \"MAPE\")]\nacc_benchmark <- accuracy(fc_benchmark, test_ortg)[2, c(\"RMSE\", \"MAE\", \"MAPE\")]\n\n# Display results\ncat(\"\\n=== CROSS-VALIDATION RESULTS (Test Set: 2020-2024) ===\\n\\n\")\ncv_results <- data.frame(\n    Model = c(\"ARIMAX\", \"ARIMAX\", \"ARIMA\"),\n    RMSE = c(acc_auto[\"RMSE\"], acc_manual[\"RMSE\"], acc_benchmark[\"RMSE\"]),\n    MAE = c(acc_auto[\"MAE\"], acc_manual[\"MAE\"], acc_benchmark[\"MAE\"]),\n    MAPE = c(acc_auto[\"MAPE\"], acc_manual[\"MAPE\"], acc_benchmark[\"MAPE\"])\n)\n\n# Display formatted table\nkable(cv_results,\n    format = \"html\",\n    digits = 3,\n    caption = \"Cross-Validation Results: ORtg Models\",\n    col.names = c(\"Model\", \"RMSE\", \"MAE\", \"MAPE (%)\")\n) %>%\n    kable_styling(\n        full_width = FALSE,\n        bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")\n    ) %>%\n    row_spec(which.min(cv_results$RMSE), bold = TRUE, color = \"white\", background = \"#006bb6\")\n\n# Determine best model\nbest_idx <- which.min(cv_results$RMSE)\ncat(\"\\n\\n*** BEST MODEL: \", cv_results$Model[best_idx], \" ***\\n\")\ncat(\"RMSE =\", round(cv_results$RMSE[best_idx], 3), \"\\n\")\n\n# Select best model based on CV\nif (cv_results$Model[best_idx] == \"ARIMAX (auto.arima)\") {\n    final_arimax <- arimax_auto\n} else if (cv_results$Model[best_idx] == \"ARIMAX (manual)\") {\n    final_arimax <- arimax_manual\n} else {\n    final_arimax <- auto.arima(ts_ortg, seasonal = FALSE)\n}\n```\n\n```{r cv-interpretation-setup, echo=FALSE, message=FALSE}\nbest_model_name <- cv_results$Model[best_idx]\nbest_rmse <- round(cv_results$RMSE[best_idx], 3)\narimax_better <- grepl(\"ARIMAX\", best_model_name)\n```\n\n**What Cross-Validation Reveals**\n\n```{r echo=FALSE, results='asis'}\nif (arimax_better) {\n    cat(\"The winner is **\", best_model_name, \"** with RMSE = \", best_rmse, \". This confirms that **exogenous variables add real predictive power**.\\n\\nThe analytics revolution is quantifiable: shot selection and shooting skill aren't just correlated with efficiency, they *predict* it.\", sep = \"\")\n} else {\n    cat(\"Surprisingly, the plain **ARIMA model** (no exogenous variables) won with RMSE = \", best_rmse, \". This suggests that ORtg's temporal structure—its own past values—contains enough information to forecast the future.\\n\\nWhy? High multicollinearity: 3PAr, TS%, and ORtg all trend together so strongly that including them as separate predictors doesn't improve forecasts. The ARIMA model implicitly captures their co-evolution through autocorrelation.\", sep = \"\")\n}\n```\n\n## Final Model & Equation\n\n```{r arimax-final-model, warning=FALSE, message=FALSE}\n# Refit winning model on full data\nif (\"xreg\" %in% names(final_arimax$call)) {\n    final_fit <- Arima(ts_ortg,\n        order = arimaorder(final_arimax)[1:3],\n        xreg = xreg_matrix\n    )\n} else {\n    final_fit <- Arima(ts_ortg, order = arimaorder(final_arimax)[1:3])\n}\n\nprint(summary(final_fit))\n\n# Also fit ARIMAX model for demonstration\ncat(\"\\n\\n=== For Comparison: ARIMAX Model with Exogenous Variables ===\\n\")\nfinal_fit_arimax <- Arima(ts_ortg,\n    order = arimaorder(arimax_auto)[1:3],\n    xreg = xreg_matrix\n)\nprint(summary(final_fit_arimax))\n```\n\n**Model Equations:**\n\n### Winning Model (Selected by Cross-Validation)\n\n```{r winning-equation, echo=FALSE, results='asis'}\narima_part <- arimaorder(final_fit)\n\nif (\"xreg\" %in% names(final_fit$call)) {\n    coefs <- coef(final_fit)\n\n    # Extract coefficients\n    ar_coefs <- coefs[grep(\"^ar\", names(coefs))]\n    ma_coefs <- coefs[grep(\"^ma\", names(coefs))]\n    xreg_coefs <- coefs[grep(\"^3PAr|^TS%\", names(coefs))]\n\n    cat(\"ARIMAX(\", arima_part[1], \",\", arima_part[2], \",\", arima_part[3], \") model:\\n\\n\", sep = \"\")\n\n    # Regression component\n    cat(\"$$\\n\")\n    cat(\"\\\\text{ORtg}_t = \\\\beta_0 + \\\\beta_1 \\\\cdot \\\\text{3PAr}_t + \\\\beta_2 \\\\cdot \\\\text{TS\\\\%}_t + N_t\\n\")\n    cat(\"$$\\n\\n\")\n\n    cat(\"where:\\n\\n\")\n    if (length(xreg_coefs) >= 1) cat(\"- $\\\\beta_1 =\", round(xreg_coefs[1], 3), \"$\\n\")\n    if (length(xreg_coefs) >= 2) cat(\"- $\\\\beta_2 =\", round(xreg_coefs[2], 3), \"$\\n\")\n\n    # ARIMA component for N_t\n    cat(\"\\n$N_t$ follows ARIMA(\", arima_part[1], \",\", arima_part[2], \",\", arima_part[3], \"):\\n\\n\", sep = \"\")\n\n    cat(\"$$\\n\")\n    if (arima_part[2] == 1) {\n        cat(\"(1 - B)^{\", arima_part[2], \"} N_t = \", sep = \"\")\n    } else if (arima_part[2] > 1) {\n        cat(\"(1 - B)^{\", arima_part[2], \"} N_t = \", sep = \"\")\n    } else {\n        cat(\"N_t = \")\n    }\n\n    # Add AR terms\n    if (length(ar_coefs) > 0) {\n        ar_terms <- paste0(round(ar_coefs, 3), \" N_{t-\", 1:length(ar_coefs), \"}\")\n        cat(paste(ar_terms, collapse = \" + \"), \" + \")\n    }\n\n    # Add MA terms\n    if (length(ma_coefs) > 0) {\n        ma_terms <- paste0(round(ma_coefs, 3), \" \\\\epsilon_{t-\", 1:length(ma_coefs), \"}\")\n        cat(paste(ma_terms, collapse = \" + \"), \" + \")\n    }\n\n    cat(\"\\\\epsilon_t\\n\")\n    cat(\"$$\\n\\n\")\n\n    cat(\"where $B$ is the backshift operator and $\\\\epsilon_t$ is white noise.\\n\")\n} else {\n    cat(\"ARIMA(\", arima_part[1], \",\", arima_part[2], \",\", arima_part[3], \") model:\\n\\n\", sep = \"\")\n    cat(\"$$\\n\")\n    cat(\"(1 - B) \\\\text{ORtg}_t = \\\\epsilon_t\\n\")\n    cat(\"$$\\n\\n\")\n}\n```\n\n## Forecasting\n\n```{r arimax-forecast, warning=FALSE, message=FALSE, fig.width=12, fig.height=7}\nif (\"xreg\" %in% names(final_fit$call)) {\n    # Forecast 3PAr and TS%\n    fc_3par <- forecast(auto.arima(ts_3par), h = 5)\n    fc_tspct <- forecast(auto.arima(ts_tspct), h = 5)\n\n    # Create future xreg matrix\n    xreg_future <- cbind(\n        `3PAr` = fc_3par$mean,\n        `TS%` = fc_tspct$mean\n    )\n\n    # Forecast ORtg\n    fc_final <- forecast(final_fit, xreg = xreg_future, h = 5)\n} else {\n    fc_final <- forecast(final_fit, h = 5)\n}\n\n# Plot forecast\nautoplot(fc_final) +\n    labs(\n        title = \"ORtg Forecast: 2026-2030 (ARIMAX Model)\",\n        subtitle = paste0(\"Model: \", paste0(final_fit), \" | Using forecasted 3PAr and TS% as exogenous inputs\"),\n        x = \"Year\",\n        y = \"Offensive Rating (Points per 100 Possessions)\"\n    ) +\n    theme_minimal(base_size = 12) +\n    theme(plot.subtitle = element_text(size = 9))\n\ncat(\"\\nPoint Forecasts:\\n\")\nprint(fc_final$mean)\n\ncat(\"\\n\\n80% Prediction Interval:\\n\")\nprint(fc_final$lower[, 1])\nprint(fc_final$upper[, 1])\n```\n\n## Interpretation\n\n```{r arimax-commentary-setup, warning=FALSE, message=FALSE, echo=FALSE}\nhas_xreg <- \"xreg\" %in% names(final_fit$call)\ntest_rmse <- cv_results$RMSE[best_idx]\ntest_mape <- cv_results$MAPE[best_idx]\n```\n\nThe ARIMAX model tells a compelling story about modern basketball's transformation.\n\n**The Analytics Advantage**\n\n```{r echo=FALSE, results='asis'}\nif (has_xreg) {\n    cat(\"Our analysis confirms what front offices discovered in 2012: both shot selection (3PAr) and shooting skill (TS%) significantly predict offensive efficiency. The model reveals that **shooting accuracy matters more than strategy**—a one percentage point increase in True Shooting% has a larger impact on offensive rating than the same increase in three-point attempt rate.\\n\\nThis ARIMAX model outperformed plain ARIMA, confirming that exogenous variables add real predictive power. Shot selection and skill improve ORtg forecasts beyond what temporal patterns alone can capture. Including the right exogenous variables isn't just theoretically justified—it's empirically beneficial. This validates the Houston Rockets' famous insight: it's not just about *shooting* threes, it's about *making* them.\\n\")\n} else {\n    cat(\"Interestingly, adding exogenous variables did not improve forecast accuracy in cross-validation. This suggests high multicollinearity between ORtg and its predictors. \\n\")\n}\n```\n\n**Forecast Performance**\n\nThe model achieved a test RMSE of **`r round(test_rmse, 2)` points per 100 possessions**, corresponding to approximately **`r round(test_mape, 1)`%** average error. To put this in context, the difference between the best and worst offense in 2024 was about 15 points per 100 possessions.\n\n**What the Future Holds**\n\n```{r echo=FALSE, results='asis'}\nif (has_xreg) {\n    cat(\"The forecast projects offensive efficiency will continue climbing through 2030, driven by relentless growth in both three-point volume and shooting accuracy. This assumes the analytics revolution hasn't plateaued—that teams will keep pushing boundaries, that shooters will keep improving, and that defenses won't find a systematic counter-strategy.\\n\\nThe widening prediction intervals tell us the model is honest about uncertainty: forecasting 2030 from 2025 data means predicting the unpredictable.\\n\")\n} else {\n    cat(\"Forecasts rely purely on historical ORtg patterns, capturing the league's 45-year trajectory toward more efficient offense. The trend is clear, but the mechanism remains in the residuals.\\n\")\n}\n```\n\n**The Basketball Insight**\n\nHere's what matters for teams: offensive efficiency isn't magic, it's a function of **where you shoot** (3PAr) and **how well you shoot** (TS%). The model equation makes this quantitative:\n\n$$\n\\text{ORtg}_t = \\beta_0 + \\beta_1 \\times \\text{3PAr}_t + \\beta_2 \\times \\text{TS\\%}_t + N_t\n$$\n\nwhere $N_t$ captures autocorrelated shocks (momentum, injuries, schedule strength).\n\nTeams have two levers:\n\n1. **Strategic**: Shoot more threes (reallocate shot distribution)\n2. **Developmental**: Improve shooting accuracy (player development, coaching)\n\nThe analytics revolution validated a simple truth: efficiency is *measurable* and *improvable*.\n\n:::\n\n## COVID Impact on Attendance (ARIMAX with Intervention)\n\n- **Response Variable**: `Total_Attendance`\n- **Exogenous Variables**: `ORtg`, `Pace`, `COVID_Dummy` (pulse intervention)\n\nThe model includes three key variables: ORtg captures how better offensive performance leads to more entertaining games and higher attendance; Pace reflects whether faster games attract more fans; and the COVID_Dummy captures the structural break in 2020-2021 from empty arenas and capacity restrictions.\n\n::: {.panel-tabset}\n\n## EDA\n\n```{r attendance-eda, warning=FALSE, message=FALSE, fig.width=12, fig.height=8}\nleague_post2000 <- league_avg %>% filter(Season >= 2000)\n\nts_attend <- ts(league_post2000$Total_Attendance, start = 2000, frequency = 1)\nts_ortg_sub <- ts(league_post2000$ORtg, start = 2000, frequency = 1)\nts_pace_sub <- ts(league_post2000$Pace, start = 2000, frequency = 1)\nts_covid <- ts(league_post2000$COVID_Dummy, start = 2000, frequency = 1)\n\np1 <- autoplot(ts_attend / 1e6) +\n    labs(title = \"Total NBA Attendance\", y = \"Attendance (Millions)\") +\n    geom_vline(xintercept = 2020, linetype = \"dashed\", color = \"red\") +\n    annotate(\"text\", x = 2020, y = 23, label = \"COVID-19\", color = \"red\", hjust = -0.1) +\n    theme_minimal()\n\np2 <- autoplot(ts_ortg_sub) +\n    labs(title = \"Offensive Rating\", y = \"ORtg\") +\n    theme_minimal()\n\np3 <- autoplot(ts_pace_sub) +\n    labs(title = \"Pace\", y = \"Pace\") +\n    theme_minimal()\n\np1 / (p2 | p3)\n```\n\nThe attendance plot tells a stark before-and-after story: from 2000-2019, the NBA showed remarkable stability around 22 million attendees per season as a reliable entertainment product. In 2020, attendance collapsed to essentially zero due to empty arenas, the bubble, and capacity restrictions. From 2021-2025, gradual recovery began but with visible scars. Meanwhile, ORtg and Pace continued their upward trends during COVID—games were still played, analytics still mattered, but no one was there to watch.\n\n## Model Fitting\n\n```{r attendance-auto, warning=FALSE, message=FALSE}\n# Prepare exogenous matrix\nxreg_attend <- cbind(\n    ORtg = ts_ortg_sub,\n    Pace = ts_pace_sub,\n    COVID = ts_covid\n)\n\n# auto.arima() method\narimax_attend_auto <- auto.arima(ts_attend, xreg = xreg_attend, seasonal = FALSE)\n\nprint(arimax_attend_auto)\n\n# Diagnostics\ncheckresiduals(arimax_attend_auto)\n```\n\n```{r attendance-manual, warning=FALSE, message=FALSE}\n# Manual method: Regression + ARIMA\ndf_attend <- data.frame(\n    Attendance = as.numeric(ts_attend),\n    ORtg = as.numeric(ts_ortg_sub),\n    Pace = as.numeric(ts_pace_sub),\n    COVID = as.numeric(ts_covid)\n)\n\nlm_attend <- lm(Attendance ~ ORtg + Pace + COVID, data = df_attend)\n\ncat(\"Regression Results:\\n\")\nsummary(lm_attend)\n```\n\n```{r attendance-reg-narrative-setup, echo=FALSE, message=FALSE}\ncovid_coef <- round(coef(lm_attend)[\"COVID\"], 0)\ncovid_impact_millions <- round(abs(coef(lm_attend)[\"COVID\"]) / 1e6, 1)\n```\n\nThe regression reveals COVID's devastating impact in stark numerical terms:\n\n$$\n\\beta_{\\text{COVID}} = `r format(covid_coef, big.mark=\",\")`\n$$\n\nThe pandemic reduced attendance by approximately **`r covid_impact_millions` million attendees** during 2020-2021. For context, total pre-pandemic attendance was around 22 million per season, this represents a near-complete collapse.\n\n```{r echo=FALSE}\n# Fit ARIMA to residuals\nresid_attend <- ts(residuals(lm_attend), start = 2000, frequency = 1)\narima_resid_attend <- auto.arima(resid_attend, seasonal = FALSE)\n\ncat(\"ARIMA model for residuals:\\n\")\nprint(arima_resid_attend)\n\n# Combined manual model\narimax_attend_manual <- Arima(ts_attend,\n    order = arimaorder(arima_resid_attend)[1:3],\n    xreg = xreg_attend\n)\n\nprint(arimax_attend_manual)\n```\n\n## Cross-Validation\n\n```{r attendance-cv, warning=FALSE, message=FALSE, fig.width=10, fig.height=6}\n# Train: 2000-2018, Test: 2019-2024 (includes pre-COVID and COVID periods)\ntrain_end_att <- 2018\ntest_start_att <- 2019\n\ntrain_attend <- window(ts_attend, end = train_end_att)\ntrain_ortg_a <- window(ts_ortg_sub, end = train_end_att)\ntrain_pace_a <- window(ts_pace_sub, end = train_end_att)\ntrain_covid_a <- window(ts_covid, end = train_end_att)\n\ntest_attend <- window(ts_attend, start = test_start_att)\ntest_ortg_a <- window(ts_ortg_sub, start = test_start_att)\ntest_pace_a <- window(ts_pace_sub, start = test_start_att)\ntest_covid_a <- window(ts_covid, start = test_start_att)\n\nh_att <- length(test_attend)\n\nxreg_train_att <- cbind(ORtg = train_ortg_a, Pace = train_pace_a, COVID = train_covid_a)\nxreg_test_att <- cbind(ORtg = test_ortg_a, Pace = test_pace_a, COVID = test_covid_a)\n\n\n# Model 1: auto.arima() - use simpler constraints for small dataset\nfit_auto_att <- tryCatch(\n    {\n        auto.arima(train_attend,\n            xreg = xreg_train_att, seasonal = FALSE,\n            max.p = 2, max.q = 2, max.d = 1, stepwise = TRUE\n        )\n    },\n    error = function(e) {\n        xreg_no_covid <- cbind(ORtg = train_ortg_a, Pace = train_pace_a)\n        auto.arima(train_attend,\n            xreg = xreg_no_covid, seasonal = FALSE,\n            max.p = 2, max.q = 2, max.d = 1\n        )\n    }\n)\n\n# Model 2: Manual method - use simpler order if needed\nfit_manual_att <- tryCatch(\n    {\n        Arima(train_attend,\n            order = arimaorder(arima_resid_attend)[1:3],\n            xreg = xreg_train_att\n        )\n    },\n    error = function(e) {\n        xreg_no_covid <- cbind(ORtg = train_ortg_a, Pace = train_pace_a)\n        Arima(train_attend, order = c(0, 1, 0), xreg = xreg_no_covid)\n    }\n)\n\n# Model 3: Benchmark\nfit_bench_att <- auto.arima(train_attend, seasonal = FALSE, max.p = 2, max.q = 2)\n\n# Forecasts - handle different xreg structures\nif (\"COVID\" %in% names(coef(fit_auto_att))) {\n    fc_auto_att <- forecast(fit_auto_att, xreg = xreg_test_att, h = h_att)\n} else {\n    xreg_test_no_covid <- cbind(ORtg = test_ortg_a, Pace = test_pace_a)\n    fc_auto_att <- forecast(fit_auto_att, xreg = xreg_test_no_covid, h = h_att)\n}\n\nif (\"COVID\" %in% names(coef(fit_manual_att))) {\n    fc_manual_att <- forecast(fit_manual_att, xreg = xreg_test_att, h = h_att)\n} else {\n    xreg_test_no_covid <- cbind(ORtg = test_ortg_a, Pace = test_pace_a)\n    fc_manual_att <- forecast(fit_manual_att, xreg = xreg_test_no_covid, h = h_att)\n}\n\nfc_bench_att <- forecast(fit_bench_att, h = h_att)\n\n# Accuracy\nacc_auto_att <- accuracy(fc_auto_att, test_attend)[2, c(\"RMSE\", \"MAE\", \"MAPE\")]\nacc_manual_att <- accuracy(fc_manual_att, test_attend)[2, c(\"RMSE\", \"MAE\", \"MAPE\")]\nacc_bench_att <- accuracy(fc_bench_att, test_attend)[2, c(\"RMSE\", \"MAE\", \"MAPE\")]\n\ncat(\"\\n=== ATTENDANCE MODEL CROSS-VALIDATION (Test: 2019-2024) ===\\n\\n\")\ncv_att_results <- data.frame(\n    Model = c(\"ARIMAX\", \"ARIMAX\", \"ARIMA\"),\n    RMSE = c(acc_auto_att[\"RMSE\"], acc_manual_att[\"RMSE\"], acc_bench_att[\"RMSE\"]),\n    MAE = c(acc_auto_att[\"MAE\"], acc_manual_att[\"MAE\"], acc_bench_att[\"MAE\"]),\n    MAPE = c(acc_auto_att[\"MAPE\"], acc_manual_att[\"MAPE\"], acc_bench_att[\"MAPE\"])\n)\n\n# Display formatted table with RMSE in millions\ncv_att_display <- cv_att_results\ncv_att_display$RMSE <- cv_att_display$RMSE / 1e6\ncv_att_display$MAE <- cv_att_display$MAE / 1e6\n\nkable(cv_att_display,\n    format = \"html\",\n    digits = 3,\n    caption = \"Cross-Validation Results: Attendance Models (Test Set: 2019-2024)\",\n    col.names = c(\"Model\", \"RMSE (Millions)\", \"MAE (Millions)\", \"MAPE (%)\")\n) %>%\n    kable_styling(\n        full_width = FALSE,\n        bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")\n    ) %>%\n    row_spec(which.min(cv_att_results$RMSE), bold = TRUE, color = \"white\", background = \"#006bb6\")\n\nbest_idx_att <- which.min(cv_att_results$RMSE)\ncat(\"\\n*** BEST MODEL: \", cv_att_results$Model[best_idx_att], \"***\\n\")\n```\n\nWhen fitted on full data (2000-2025), the COVID dummy captures the unprecedented shock effectively.\n\n## Final Model & Interpretation\n\n```{r attendance-final, warning=FALSE, message=FALSE, fig.width=12, fig.height=6}\n# Refit best model on full data\nif (cv_att_results$Model[best_idx_att] == \"ARIMAX (auto)\") {\n    final_attend <- Arima(ts_attend,\n        order = arimaorder(arimax_attend_auto)[1:3],\n        xreg = xreg_attend\n    )\n} else if (cv_att_results$Model[best_idx_att] == \"ARIMAX (manual)\") {\n    final_attend <- arimax_attend_manual\n} else {\n    final_attend <- auto.arima(ts_attend, seasonal = FALSE)\n}\n\ncat(\"Final Attendance Model:\\n\")\nprint(summary(final_attend))\n\n# Forecast\nfc_ortg_fut <- forecast(auto.arima(ts_ortg_sub), h = 5)\nfc_pace_fut <- forecast(auto.arima(ts_pace_sub), h = 5)\n\n# Create xreg based on what variables the model has\nif (\"COVID\" %in% names(coef(final_attend))) {\n    xreg_future_att <- cbind(\n        ORtg = fc_ortg_fut$mean,\n        Pace = fc_pace_fut$mean,\n        COVID = rep(0, 5)\n    )\n} else {\n    xreg_future_att <- cbind(\n        ORtg = fc_ortg_fut$mean,\n        Pace = fc_pace_fut$mean\n    )\n}\n\nfc_attend_final <- forecast(final_attend, xreg = xreg_future_att, h = 5)\n\nautoplot(fc_attend_final) +\n    labs(\n        title = \"NBA Attendance Forecast: 2026-2030\",\n        subtitle = \"Assumes full COVID recovery (COVID_Dummy = 0)\",\n        x = \"Year\",\n        y = \"Total Attendance (Millions)\"\n    ) +\n    scale_y_continuous(labels = function(x) x / 1e6) +\n    theme_minimal()\n\n```\n\n```{r attendance-commentary-setup, echo=FALSE, message=FALSE}\nhas_covid <- \"COVID\" %in% names(coef(final_attend))\nhas_ortg <- \"ORtg\" %in% names(coef(final_attend))\nif (has_covid) {\n    covid_impact <- coef(final_attend)[\"COVID\"] / 1e6\n}\n```\n\n```{r echo=FALSE, results='asis'}\nif (has_covid) {\n    cat(\"March 2020 left an indelible mark in the data. The COVID dummy variable carries a coefficient of **\", round(covid_impact, 2), \" million attendees**—representing nearly a 90% collapse in arena attendance during the 2020-2021 seasons.\\n\\nThis wasn't gradual decline. It was instantaneous erasure. Intervention analysis quantifies what everyone witnessed: the pandemic reduced attendance by ~20 million (near-complete collapse), this shock was structural and unpredictable from pre-2020 trends (no amount of historical data could forecast a global pandemic), and the dummy variable approach cleanly separates the COVID effect from underlying trends. Including this dummy variable wasn't just statistically beneficial—it was necessary to capture a shock that no amount of historical data could have predicted. This serves as a natural experiment demonstrating how external shocks disrupt time series patterns.\\n\", sep = \"\")\n} else {\n    cat(\"Here's where cross-validation reveals a hard truth about forecasting: the COVID dummy was *all zeros* in our training data (2000-2018) because the pandemic didn't exist yet. The model couldn't learn what it hadn't seen.\\n\\nWhen the test period arrived (2019-2024), actual attendance plummeted by 90% in 2020. However our model, trained on pre-pandemic patterns, had no mechanism to anticipate this. This demonstrates the fundamental challenge of time series forecasting: **external shocks that have never occurred before are, by definition, unforecastable**.\")\n}\n```\n\n```{r echo=FALSE, results='asis'}\nif (has_ortg) {\n    cat(\"Beyond COVID's overwhelming impact, the model detects subtler forces: offensive rating and pace do influence attendance, but their effects are small compared to the pandemic shock. This tells us that **fans care more about whether games happen** than about how exciting those games are. A boring game with 18,000 fans beats an offensive shootout with zero.\\n\\nAttendance is sticky—fans buy season tickets, form habits, make plans. Game quality matters at the margin (a 115 ORtg season might draw slightly more than a 105 ORtg season), but structural factors like arena access, pricing, and health safety dominate.\\n\")\n} else {\n    cat(\"The model relies purely on time-series patterns, revealing that attendance follows its own momentum: yesterday's crowds predict tomorrow's. This makes sense; season ticket holders commit months in advance, and casual fans follow habits more than real-time performance metrics.\")\n}\n```\n:::\n\n---\n\n# VAR (Vector Autoregression) Models\n\n## Efficiency Drivers (VAR)\n\n**Variables**: `ORtg`, `Pace`, `3PAr`\n\nThe theoretical rationale for this VAR model involves multiple bidirectional relationships: faster tempo (Pace) creates more transition opportunities favoring quick 3PT attempts (3PAr), while teams shooting more 3s may adopt faster pace to maximize possessions. Similarly, efficient offense (ORtg) may enable teams to control tempo (Pace), while higher pace may increase transition scoring efficiency (ORtg). We use VAR rather than ARIMAX because we do not assume unidirectional causality.\n\n::: {.panel-tabset}\n\n## EDA & Stationarity\n\n```{r var-eda, warning=FALSE, message=FALSE, fig.width=12, fig.height=8}\n# Create VAR dataset\nvar_data <- ts(league_avg %>% dplyr::select(ORtg, Pace, `3PAr`),\n    start = 1980, frequency = 1\n)\n\n# Plot all series\nautoplot(var_data, facets = TRUE) +\n    labs(\n        title = \"VAR Variables: ORtg, Pace, 3PAr (1980-2025)\",\n        x = \"Year\", y = \"Value\"\n    ) +\n    theme_minimal()\n\ncat(\"Summary Statistics:\\n\")\nsummary(var_data)\n```\n\n```{r var-stationarity, warning=FALSE, message=FALSE}\n# ADF tests for each series\ncat(\"=== STATIONARITY TESTS ===\\n\\n\")\n\nadf_ortg_var <- adf.test(var_data[, \"ORtg\"])\nadf_pace_var <- adf.test(var_data[, \"Pace\"])\nadf_3par_var <- adf.test(var_data[, \"3PAr\"])\n\ncat(\n    \"ORtg: ADF p-value =\", round(adf_ortg_var$p.value, 4),\n    ifelse(adf_ortg_var$p.value < 0.05, \"(stationary)\", \"implies non-stationary\"), \"\\n\"\n)\ncat(\n    \"Pace: ADF p-value =\", round(adf_pace_var$p.value, 4),\n    ifelse(adf_pace_var$p.value < 0.05, \"(stationary)\", \"implies non-stationary\"), \"\\n\"\n)\ncat(\n    \"3PAr: ADF p-value =\", round(adf_3par_var$p.value, 4),\n    ifelse(adf_3par_var$p.value < 0.05, \"(stationary)\", \"implies non-stationary\"), \"\\n\\n\"\n)\n\n# Difference if non-stationary\nif (adf_ortg_var$p.value > 0.05 | adf_pace_var$p.value > 0.05 | adf_3par_var$p.value > 0.05) {\n    var_data_diff <- diff(var_data)\n\n    # Test differenced data\n    adf_ortg_diff <- adf.test(var_data_diff[, \"ORtg\"])\n    adf_pace_diff <- adf.test(var_data_diff[, \"Pace\"])\n    adf_3par_diff <- adf.test(var_data_diff[, \"3PAr\"])\n\n    cat(\"After first-differencing:\\n\")\n    cat(\"ORtg: ADF p-value =\", round(adf_ortg_diff$p.value, 4), \"\\n\")\n    cat(\"Pace: ADF p-value =\", round(adf_pace_diff$p.value, 4), \"\\n\")\n    cat(\"3PAr: ADF p-value =\", round(adf_3par_diff$p.value, 4), \"\\n\\n\")\n\n    if (adf_ortg_diff$p.value < 0.05 & adf_pace_diff$p.value < 0.05 & adf_3par_diff$p.value < 0.05) {\n        cat(\"All series now stationary. Proceeding with differenced data for VAR.\\n\\n\")\n        var_data_final <- var_data_diff\n        differenced <- TRUE\n    } else {\n        var_data_final <- var_data_diff\n        differenced <- TRUE\n    }\n} else {\n    var_data_final <- var_data\n    differenced <- FALSE\n}\n```\n\n## Model Selection & Fitting\n\n```{r var-select, warning=FALSE, message=FALSE}\n# Determine optimal lag order\ncat(\"=== LAG ORDER SELECTION ===\\n\\n\")\nvar_select <- VARselect(var_data_final, lag.max = 8, type = \"const\")\n\nprint(var_select$selection)\nprint(var_select$criteria)\n\n# Fit models with different lag orders\nlags_to_fit <- unique(var_select$selection[1:3])\n\ncat(\"Fitting VAR models with p =\", paste(lags_to_fit, collapse = \", \"), \"\\n\\n\")\n\nvar_models <- list()\nfor (p in lags_to_fit) {\n    var_models[[paste0(\"VAR_\", p)]] <- VAR(var_data_final, p = p, type = \"const\")\n    cat(\"VAR(\", p, \") fitted successfully\\n\", sep = \"\")\n}\n```\n\n```{r var-summaries, warning=FALSE, message=FALSE}\nfor (name in names(var_models)) {\n    cat(\"========================================\\n\")\n    cat(name, \"Summary:\\n\")\n    cat(\"========================================\\n\\n\")\n    print(summary(var_models[[name]]))\n    cat(\"\\n\\n\")\n}\n```\n\n\n## Cross-Validation\n\n```{r var-cv, warning=FALSE, message=FALSE, fig.width=10, fig.height=6}\ncat(\"=== TIME SERIES CROSS-VALIDATION FOR VAR ===\\n\\n\")\n\n# Split: Train 1980-2019, Test 2020-2024\ntrain_end_var <- 2019\n\nif (differenced) {\n    # Differenced data starts at 1981 (lost 1980 due to differencing)\n    # Training: 1981-2019, Test: 2020-2024\n    train_var <- window(var_data_final, end = train_end_var)\n    test_var <- window(var_data_final, start = train_end_var + 1)\n} else {\n    train_var <- window(var_data_final, end = train_end_var)\n    test_var <- window(var_data_final, start = train_end_var + 1)\n}\n\nh_var <- nrow(test_var)\n\n# Fit VAR models on training data with error handling\nvar_train_models <- list()\nfor (p in lags_to_fit) {\n    model <- tryCatch(\n        {\n            VAR(train_var, p = p, type = \"const\")\n        },\n        error = function(e) {\n            cat(\"Warning: VAR(\", p, \") failed. Trying with smaller lag...\\n\", sep = \"\")\n            if (p > 1) {\n                VAR(train_var, p = 1, type = \"const\")\n            } else {\n                NULL\n            }\n        }\n    )\n    if (!is.null(model)) {\n        var_train_models[[paste0(\"VAR_\", p)]] <- model\n    }\n}\n\n# Generate forecasts\nrmse_results <- data.frame()\n\nif (length(var_train_models) == 0) {\n    cat(\"ERROR: No VAR models were successfully fitted. Check data and lag selection.\\n\")\n} else {\n    cat(\"Successfully fitted\", length(var_train_models), \"VAR model(s)\\n\\n\")\n}\n\nfor (name in names(var_train_models)) {\n    fc <- tryCatch(\n        {\n            predict(var_train_models[[name]], n.ahead = h_var)\n        },\n        error = function(e) {\n            cat(\"Warning: Forecast failed for\", name, \"\\n\")\n            NULL\n        }\n    )\n\n    if (is.null(fc)) next\n\n    # Extract forecasts for each variable\n    fc_ortg <- fc$fcst$ORtg[, \"fcst\"]\n    fc_pace <- fc$fcst$Pace[, \"fcst\"]\n    fc_3par <- fc$fcst$`3PAr`[, \"fcst\"]\n\n    # Convert test data to numeric vectors for comparison\n    test_ortg_vec <- as.numeric(test_var[, \"ORtg\"])\n    test_pace_vec <- as.numeric(test_var[, \"Pace\"])\n    test_3par_vec <- as.numeric(test_var[, \"3PAr\"])\n\n    # Ensure equal lengths (forecasts might be shorter if h_var is large)\n    n_compare <- min(length(test_ortg_vec), length(fc_ortg))\n\n    # Calculate RMSE for each variable\n    rmse_ortg <- sqrt(mean((test_ortg_vec[1:n_compare] - fc_ortg[1:n_compare])^2))\n    rmse_pace <- sqrt(mean((test_pace_vec[1:n_compare] - fc_pace[1:n_compare])^2))\n    rmse_3par <- sqrt(mean((test_3par_vec[1:n_compare] - fc_3par[1:n_compare])^2))\n\n    # Average RMSE across variables\n    rmse_avg <- mean(c(rmse_ortg, rmse_pace, rmse_3par))\n\n    rmse_results <- rbind(rmse_results, data.frame(\n        Model = name,\n        Lags = as.numeric(gsub(\"VAR_\", \"\", name)),\n        RMSE_ORtg = rmse_ortg,\n        RMSE_Pace = rmse_pace,\n        RMSE_3PAr = rmse_3par,\n        RMSE_Avg = rmse_avg\n    ))\n}\n\ncat(\"Cross-Validation Results:\\n\")\nif (nrow(rmse_results) > 0) {\n    # Display formatted table\n    kable(rmse_results,\n        format = \"html\",\n        digits = 4,\n        caption = \"Cross-Validation Results: VAR Models (Test Set: 2020-2024)\",\n        col.names = c(\"Model\", \"Lags\", \"RMSE (ORtg)\", \"RMSE (Pace)\", \"RMSE (3PAr)\", \"Avg RMSE\"),\n        row.names = FALSE\n    ) %>%\n        kable_styling(\n            full_width = FALSE,\n            bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")\n        ) %>%\n        row_spec(which.min(rmse_results$RMSE_Avg), bold = TRUE, color = \"white\", background = \"#006bb6\")\n\n    # Plot RMSEs\n    ggplot(rmse_results, aes(x = factor(Lags), y = RMSE_Avg, fill = Model)) +\n        geom_bar(stat = \"identity\", width = 0.6) +\n        geom_text(aes(label = round(RMSE_Avg, 3)), vjust = -0.5, fontface = \"bold\") +\n        labs(\n            title = \"VAR Model Cross-Validation: Average RMSE\",\n            subtitle = \"Lower RMSE = Better out-of-sample forecast performance\",\n            x = \"Number of Lags (p)\",\n            y = \"Average RMSE across ORtg, Pace, 3PAr\"\n        ) +\n        theme_minimal() +\n        theme(legend.position = \"none\") +\n        scale_fill_brewer(palette = \"Set2\")\n\n    best_var_idx <- which.min(rmse_results$RMSE_Avg)\n    cat(\"\\n*** BEST VAR MODEL: \", rmse_results$Model[best_var_idx], \" ***\\n\")\n    cat(\"Average RMSE =\", round(rmse_results$RMSE_Avg[best_var_idx], 4), \"\\n\")\n} else {\n    cat(\"No cross-validation results available (all models failed)\\n\")\n    best_var_idx <- 1 # Default to first model\n}\n```\n\n## Final Model & Forecast\n\n```{r var-final, warning=FALSE, message=FALSE, fig.width=12, fig.height=10}\n# Select best model\nif (nrow(rmse_results) > 0) {\n    best_var_name <- rmse_results$Model[best_var_idx]\n    best_var_lags <- rmse_results$Lags[best_var_idx]\n} else {\n    best_var_lags <- min(lags_to_fit)\n}\n\ncat(\"Final VAR Model: VAR(\", best_var_lags, \")\\n\\n\", sep = \"\")\n\n# Refit on full data\nfinal_var <- tryCatch(\n    {\n        VAR(var_data_final, p = best_var_lags, type = \"const\")\n    },\n    error = function(e) {\n        VAR(var_data_final, p = 1, type = \"const\")\n    }\n)\n\nprint(summary(final_var))\n\n# Forecast 5 periods ahead\nfc_var_final <- predict(final_var, n.ahead = 5)\n\n# Get variable names\nfc_var_names <- names(fc_var_final$fcst)\ntpar_fc_name <- fc_var_names[grep(\"3PAr|PAr\", fc_var_names, ignore.case = TRUE)]\nif (length(tpar_fc_name) == 0) tpar_fc_name <- fc_var_names[3]\n\n# Display forecasts\ncat(\"\\n=== 5-Period Forecasts ===\\n\\n\")\ncat(\"ORtg:\\n\")\nprint(fc_var_final$fcst$ORtg)\ncat(\"\\n\", tpar_fc_name, \":\\n\", sep = \"\")\nprint(fc_var_final$fcst[[tpar_fc_name]])\ncat(\"\\nPace:\\n\")\nprint(fc_var_final$fcst$Pace)\n\n# Plot forecasts\nfor (vname in fc_var_names) {\n    plot(fc_var_final, names = vname)\n}\n```\n\n**Granger Causality Tests**:\n\n```{r var-granger, warning=FALSE, message=FALSE}\n# Granger causality tests\nvar_names <- names(final_var$varresult)\ntpar_name <- var_names[grep(\"3PAr|PAr\", var_names, ignore.case = TRUE)]\nif (length(tpar_name) == 0) tpar_name <- var_names[3]\n\ngranger_3par_ortg <- causality(final_var, cause = tpar_name)$Granger\ngranger_pace <- causality(final_var, cause = \"Pace\")$Granger\ngranger_ortg <- causality(final_var, cause = \"ORtg\")$Granger\n\ncat(\"=== Granger Causality Tests ===\\n\\n\")\ncat(\"3PAr → {ORtg, Pace}: F =\", round(granger_3par_ortg$statistic, 3),\n    \", p =\", round(granger_3par_ortg$p.value, 4), \"\\n\")\ncat(\"Pace → {ORtg, 3PAr}: F =\", round(granger_pace$statistic, 3),\n    \", p =\", round(granger_pace$p.value, 4), \"\\n\")\ncat(\"ORtg → {Pace, 3PAr}: F =\", round(granger_ortg$statistic, 3),\n    \", p =\", round(granger_ortg$p.value, 4), \"\\n\")\n```\n\nGranger causality tests reveal the temporal ordering of the analytics revolution by determining which variables' past values predict other variables' future changes. These tests show whether the rise in three-point shooting preceded changes in offensive efficiency and pace, or whether successful offenses drove teams to adopt more three-pointers, providing empirical evidence about the direction of causation during the NBA's transformation.\n\n```{r var-irf, warning=FALSE, message=FALSE, fig.width=12, fig.height=8}\nvar_names_irf <- names(final_var$varresult)\ntpar_name_irf <- var_names_irf[grep(\"3PAr|PAr\", var_names_irf, ignore.case = TRUE)]\nif (length(tpar_name_irf) == 0) tpar_name_irf <- var_names_irf[3]\n\n# IRFs\nirf_3par_ortg <- irf(final_var, impulse = tpar_name_irf, response = \"ORtg\", n.ahead = 10)\nplot(irf_3par_ortg, main = paste(\"Impulse:\", tpar_name_irf, \"→ Response: ORtg\"))\n\nirf_pace_ortg <- irf(final_var, impulse = \"Pace\", response = \"ORtg\", n.ahead = 10)\nplot(irf_pace_ortg, main = \"Impulse: Pace → Response: ORtg\")\n\nirf_ortg_3par <- irf(final_var, impulse = \"ORtg\", response = tpar_name_irf, n.ahead = 10)\nplot(irf_ortg_3par, main = paste(\"Impulse: ORtg → Response:\", tpar_name_irf))\n```\n\n## Interpretation\n\nThe VAR model reveals meaningful relationships among offensive efficiency, three-point shooting, and pace across NBA history. Granger causality tests quantify whether past values of one variable help predict future values of others, addressing the question of whether the rise in three-point shooting preceded changes in offensive efficiency or vice versa.\n\nImpulse response functions trace how a one-time shock to one variable cascades through the system, showing whether innovations in one aspect of basketball strategy have lasting effects on others or if defensive adjustments eventually neutralize advantages. Together, these tools demonstrate that while the analytics revolution transformed the NBA, reflecting the complex adaptive nature of elite competition where strategic innovations provoke counter-responses.\n","srcMarkdownNoYaml":"\n\n# Theoretical Framework\n\n::: {.panel-tabset}\n\n## Literature Review\n\nUnderstanding NBA offensive efficiency requires a framework that separates team performance from game tempo. Offensive rating (ORtg) and pace-adjusted statistics provide this foundation, enabling us to quantify team effectiveness independent of how fast games are played. This distinction is critical for multivariate analysis because pace itself may be a strategic choice rather than a neutral contextual factor @kubatko2007starting.\n\nThe relationship between pace, spacing, and offensive efficiency involves bidirectional causality: faster tempo creates spacing opportunities through transition play, while better floor spacing enables teams to control pace more effectively @skinner2012problem. This co-evolution suggests that variables like ORtg, Pace, and 3PAr influence each other over time rather than following a simple cause-and-effect sequence @franks2015characterizing. Additionally, three-point attempts offer higher expected value than mid-range shots when accounting for shooting percentages, providing the mathematical foundation for the shot selection revolution @sliz2017investigation.\n\nRecent work reveals that teams with higher True Shooting percentage subsequently increased their three-point volume, suggesting reverse causation: success breeds strategy changes. This finding challenges the assumption that strategic choices (like shooting more threes) unidirectionally drive efficiency gains. Instead, teams that shot efficiently were more likely to adopt analytics-driven shot selection in future seasons, creating a feedback loop where strategy and performance reinforce each other @poropudas2023dean.\n\nThese dynamics motivate our multivariate approach. ARIMAX models test directional hypotheses by treating shot selection and shooting skill as exogenous predictors of offensive efficiency. VAR models allow all variables to influence each other, capturing bidirectional feedback loops where past values of each variable predict future values of all others. Intervention analysis with dummy variables isolates external shocks (like COVID-19's impact on attendance) from underlying trends. Together, these frameworks let us distinguish correlation from causation and quantify the temporal relationships defining modern NBA offense.\n\n\n## Proposed Models\n\n**Note**: **Models 4 and 5** still need to be completed for the final portfolio.\n\n### Model 1: Efficiency Drivers (VAR)\n`ORtg ~ Pace & 3PAr`\n\n\n### Model 2: Shot Selection & Efficiency (ARIMAX)\n**Response**: `ORtg ~ 3PAr + TS%`\n\n### Model 3: COVID Impact on Attendance (ARIMAX)\n`Attendance ~ ORtg + Pace`\n\n### Model 4: Pace Dynamics (VAR)\n`Pace ~ 3PAr + eFG%`\n\n### Model 5: Sports Betting & NBA Recovery (VAR)\n**Variables**: `DKNG ~ Attendance + ORtg`\n\n:::\n\n---\n\n```{r setup, warning=FALSE, message=FALSE}\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(forecast)\nlibrary(astsa)\nlibrary(xts)\nlibrary(tseries)\nlibrary(fpp2)\nlibrary(fma)\nlibrary(lubridate)\nlibrary(TSstudio)\nlibrary(quantmod)\nlibrary(tidyquant)\nlibrary(plotly)\nlibrary(readr)\nlibrary(dplyr)\nlibrary(vars)\nlibrary(patchwork)\nlibrary(kableExtra)\nlibrary(gridExtra)\n\ntheme_set(theme_minimal(base_size = 12))\n\nall_adv_files <- list.files(\"data/adv_stats\", pattern = \"*.csv\", full.names = TRUE)\n\nall_adv_data <- map_df(all_adv_files, function(file) {\n    season_str <- str_extract(basename(file), \"\\\\d{4}-\\\\d{2}\")\n    season_year <- as.numeric(str_sub(season_str, 1, 4)) + 1\n    df <- read_csv(file, show_col_types = FALSE)\n    df$Season <- season_year\n    return(df)\n})\n\nleague_avg <- all_adv_data %>%\n    group_by(Season) %>%\n    summarise(\n        ORtg = mean(`Unnamed: 10_level_0_ORtg`, na.rm = TRUE),\n        DRtg = mean(`Unnamed: 11_level_0_DRtg`, na.rm = TRUE),\n        Pace = mean(`Unnamed: 13_level_0_Pace`, na.rm = TRUE),\n        `3PAr` = mean(`Unnamed: 15_level_0_3PAr`, na.rm = TRUE),\n        `TS%` = mean(`Unnamed: 16_level_0_TS%`, na.rm = TRUE),\n        `eFG%` = mean(`Offense Four Factors_eFG%`, na.rm = TRUE),\n        Total_Attendance = sum(`Unnamed: 29_level_0_Attend.`, na.rm = TRUE),\n        .groups = \"drop\"\n    )\n\n# Create COVID dummy variable\nleague_avg <- league_avg %>%\n    mutate(COVID_Dummy = ifelse(Season %in% c(2020, 2021), 1, 0))\n```\n\n---\n\n# ARIMAX/SARIMAX Models\n\n## Shot Selection & Efficiency (ARIMAX)\n\n- **Response Variable**: `ORtg` (Offensive Rating)\n- **Exogenous Variables**: `3PAr` (3-Point Attempt Rate), `TS%` (True Shooting %)\n\nThis model addresses whether shooting more 3s and shooting accuracy explain offensive efficiency gains. The analytics literature shows 3PT shots have higher expected value than mid-range attempts, so teams adopting 3PT-heavy strategies should score more efficiently. `TS%` measures shooting skill while adjusting for 2PT, 3PT, and free throw contributions, implying higher TS% directly translates to more points per possession. We assume 3PAr and TS% cause ORtg rather than the reverse, interpreting 3PAr as a strategic choice variable and TS% as skill execution that drives offensive output.\n\n::: {.panel-tabset}\n\n## EDA & Correlation\n\n```{r arimax-eda, warning=FALSE, message=FALSE, fig.width=12, fig.height=8}\nts_ortg <- ts(league_avg$ORtg, start = 1980, frequency = 1)\nts_3par <- ts(league_avg$`3PAr`, start = 1980, frequency = 1)\nts_tspct <- ts(league_avg$`TS%`, start = 1980, frequency = 1)\n\np1 <- autoplot(ts_ortg) + labs(title = \"Offensive Rating (ORtg)\", y = \"ORtg\") + theme_minimal()\np2 <- autoplot(ts_3par) + labs(title = \"3-Point Attempt Rate (3PAr)\", y = \"3PAr\") + theme_minimal()\np3 <- autoplot(ts_tspct) + labs(title = \"True Shooting % (TS%)\", y = \"TS%\") + theme_minimal()\n\np1 / p2 / p3\n```\n\nThe time series reveal basketball's transformation at a glance: ORtg climbs gradually from ~104 in 1980 to ~113 in 2025. Meanwhile, 3PAr explodes post-2012 (the analytics inflection point), accelerating from ~25% to over 40% of all shot attempts. True Shooting percentage rises steadily, suggesting shooting skill improved alongside strategic changes, implying players got better as teams got smarter. All three series trend upward together, raising the non-stationarity flag for our time series models.\n\n```{r arimax-correlation, warning=FALSE, message=FALSE}\n# Correlation analysis\ncor_data <- league_avg %>% dplyr::select(ORtg, `3PAr`, `TS%`)\ncat(\"Correlation Matrix:\\n\")\nprint(round(cor(cor_data, use = \"complete.obs\"), 3))\n```\n\n```{r correlation-narrative-setup, echo=FALSE, message=FALSE}\ncor_ortg_3par <- round(cor(league_avg$ORtg, league_avg$`3PAr`), 3)\ncor_ortg_ts <- round(cor(league_avg$ORtg, league_avg$`TS%`), 3)\ncor_3par_ts <- round(cor(league_avg$`3PAr`, league_avg$`TS%`), 3)\n```\n\nThe correlations tell a clear story: ORtg vs 3PAr show strong positive relationship, meaning shooting more threes correlates with better offense. ORtg vs TS% displays a very strong positive relationship, suggesting shooting accuracy matters even more. The 3PAr vs TS% has a moderate positive correlation indicates that teams shooting more threes also shoot better likely due to selection effects where better shooters take more threes. Overall both predictors correlate strongly with offensive efficiency, but TS% shows the stronger association. The lesson: strategy matters, but execution matters more.\n\n## Model Fitting\n\n```{r arimax-auto, warning=FALSE, message=FALSE}\nxreg_matrix <- cbind(\n    `3PAr` = ts_3par,\n    `TS%` = ts_tspct\n)\n\narimax_auto <- auto.arima(ts_ortg,\n    xreg = xreg_matrix, seasonal = FALSE,\n    stepwise = FALSE, approximation = FALSE\n)\n\ncat(\"Selected model:\\n\")\nprint(arimax_auto)\n\ncat(\"\\n\\nModel Summary:\\n\")\nsummary(arimax_auto)\n```\n\n**Model Diagnostics**:\n\n```{r arimax-auto-diagnostics, warning=FALSE, message=FALSE, fig.width=12, fig.height=10}\ncheckresiduals(arimax_auto)\n\n# Ljung-Box test\nljung_auto <- Box.test(arimax_auto$residuals, lag = 10, type = \"Ljung-Box\")\n```\n\n\n```{r arimax-manual-lm, warning=FALSE, message=FALSE}\n# Create data frame\ndf_reg <- data.frame(\n    ORtg = as.numeric(ts_ortg),\n    PAr3 = as.numeric(ts_3par),\n    TSpct = as.numeric(ts_tspct)\n)\n\n# Fit regression\nlm_model <- lm(ORtg ~ PAr3 + TSpct, data = df_reg)\n\ncat(\"Linear Regression Results:\\n\")\nsummary(lm_model)\n```\n\n```{r regression-narrative-setup, echo=FALSE, message=FALSE}\nbeta_intercept <- round(coef(lm_model)[\"(Intercept)\"], 2)\nbeta_3par <- round(coef(lm_model)[\"PAr3\"], 2)\nbeta_ts <- round(coef(lm_model)[\"TSpct\"], 2)\n```\n\nThe regression equation reveals the mathematical relationship:\n\n$$\n\\text{ORtg} = `r beta_intercept` + `r beta_3par` \\times \\text{3PAr} + `r beta_ts` \\times \\text{TS\\%}\n$$\n\nHere's what this means on the court: a 1 percentage point increase in 3PAr leads to an ORtg increase of **`r beta_3par` points per 100 possessions** (moving from 30% to 31% of shots being threes adds `beta_3par` points to offensive rating). Similarly, a 1 percentage point increase in TS% leads to an ORtg increase of **`r beta_ts` points per 100 possessions** (improving from 55% to 56% True Shooting adds `beta_ts` points), emphasising that shooting accuracy has a stronger impact than shot selection.\n\n```{r arimax-manual-arima, warning=FALSE, message=FALSE}\nlm_residuals <- ts(residuals(lm_model), start = 1980, frequency = 1)\n\n# Plot residuals\nautoplot(lm_residuals) +\n    labs(title = \"Regression Residuals\", y = \"Residuals\") +\n    theme_minimal()\n\n# Fit ARIMA to residuals\narima_resid <- auto.arima(lm_residuals, seasonal = FALSE)\n\ncat(\"\\nARIMA model for residuals:\\n\")\nprint(arima_resid)\n\n# Diagnostics\ncheckresiduals(arima_resid)\n```\n\n\n```{r arimax-manual-final, warning=FALSE, message=FALSE}\narima_order <- arimaorder(arima_resid)\n\narimax_manual <- Arima(ts_ortg,\n    order = c(arima_order[1], arima_order[2], arima_order[3]),\n    xreg = xreg_matrix\n)\n\nprint(arimax_manual)\nprint(coef(arimax_manual))\n```\n\n## Cross-Validation\n\n```{r arimax-cv, warning=FALSE, message=FALSE, fig.width=12, fig.height=6}\ntrain_end <- 2019\ntest_start <- 2020\n\n# Split data\ntrain_ortg <- window(ts_ortg, end = train_end)\ntrain_3par <- window(ts_3par, end = train_end)\ntrain_tspct <- window(ts_tspct, end = train_end)\n\ntest_ortg <- window(ts_ortg, start = test_start)\ntest_3par <- window(ts_3par, start = test_start)\ntest_tspct <- window(ts_tspct, start = test_start)\n\nh <- length(test_ortg)\n\n# Prepare xreg for train/test\nxreg_train <- cbind(`3PAr` = train_3par, `TS%` = train_tspct)\nxreg_test <- cbind(`3PAr` = test_3par, `TS%` = test_tspct)\n\n# Model 1: auto.arima() method\nfit_auto <- auto.arima(train_ortg, xreg = xreg_train, seasonal = FALSE)\n\n# Model 2: Manual method\nfit_manual <- Arima(train_ortg,\n    order = c(arima_order[1], arima_order[2], arima_order[3]),\n    xreg = xreg_train\n)\n\n# Model 3: Simple ARIMA without exogenous (benchmark)\nfit_benchmark <- auto.arima(train_ortg, seasonal = FALSE)\n\n# Generate forecasts\nfc_auto <- forecast(fit_auto, xreg = xreg_test, h = h)\nfc_manual <- forecast(fit_manual, xreg = xreg_test, h = h)\nfc_benchmark <- forecast(fit_benchmark, h = h)\n\n# Calculate accuracy\nacc_auto <- accuracy(fc_auto, test_ortg)[2, c(\"RMSE\", \"MAE\", \"MAPE\")]\nacc_manual <- accuracy(fc_manual, test_ortg)[2, c(\"RMSE\", \"MAE\", \"MAPE\")]\nacc_benchmark <- accuracy(fc_benchmark, test_ortg)[2, c(\"RMSE\", \"MAE\", \"MAPE\")]\n\n# Display results\ncat(\"\\n=== CROSS-VALIDATION RESULTS (Test Set: 2020-2024) ===\\n\\n\")\ncv_results <- data.frame(\n    Model = c(\"ARIMAX\", \"ARIMAX\", \"ARIMA\"),\n    RMSE = c(acc_auto[\"RMSE\"], acc_manual[\"RMSE\"], acc_benchmark[\"RMSE\"]),\n    MAE = c(acc_auto[\"MAE\"], acc_manual[\"MAE\"], acc_benchmark[\"MAE\"]),\n    MAPE = c(acc_auto[\"MAPE\"], acc_manual[\"MAPE\"], acc_benchmark[\"MAPE\"])\n)\n\n# Display formatted table\nkable(cv_results,\n    format = \"html\",\n    digits = 3,\n    caption = \"Cross-Validation Results: ORtg Models\",\n    col.names = c(\"Model\", \"RMSE\", \"MAE\", \"MAPE (%)\")\n) %>%\n    kable_styling(\n        full_width = FALSE,\n        bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")\n    ) %>%\n    row_spec(which.min(cv_results$RMSE), bold = TRUE, color = \"white\", background = \"#006bb6\")\n\n# Determine best model\nbest_idx <- which.min(cv_results$RMSE)\ncat(\"\\n\\n*** BEST MODEL: \", cv_results$Model[best_idx], \" ***\\n\")\ncat(\"RMSE =\", round(cv_results$RMSE[best_idx], 3), \"\\n\")\n\n# Select best model based on CV\nif (cv_results$Model[best_idx] == \"ARIMAX (auto.arima)\") {\n    final_arimax <- arimax_auto\n} else if (cv_results$Model[best_idx] == \"ARIMAX (manual)\") {\n    final_arimax <- arimax_manual\n} else {\n    final_arimax <- auto.arima(ts_ortg, seasonal = FALSE)\n}\n```\n\n```{r cv-interpretation-setup, echo=FALSE, message=FALSE}\nbest_model_name <- cv_results$Model[best_idx]\nbest_rmse <- round(cv_results$RMSE[best_idx], 3)\narimax_better <- grepl(\"ARIMAX\", best_model_name)\n```\n\n**What Cross-Validation Reveals**\n\n```{r echo=FALSE, results='asis'}\nif (arimax_better) {\n    cat(\"The winner is **\", best_model_name, \"** with RMSE = \", best_rmse, \". This confirms that **exogenous variables add real predictive power**.\\n\\nThe analytics revolution is quantifiable: shot selection and shooting skill aren't just correlated with efficiency, they *predict* it.\", sep = \"\")\n} else {\n    cat(\"Surprisingly, the plain **ARIMA model** (no exogenous variables) won with RMSE = \", best_rmse, \". This suggests that ORtg's temporal structure—its own past values—contains enough information to forecast the future.\\n\\nWhy? High multicollinearity: 3PAr, TS%, and ORtg all trend together so strongly that including them as separate predictors doesn't improve forecasts. The ARIMA model implicitly captures their co-evolution through autocorrelation.\", sep = \"\")\n}\n```\n\n## Final Model & Equation\n\n```{r arimax-final-model, warning=FALSE, message=FALSE}\n# Refit winning model on full data\nif (\"xreg\" %in% names(final_arimax$call)) {\n    final_fit <- Arima(ts_ortg,\n        order = arimaorder(final_arimax)[1:3],\n        xreg = xreg_matrix\n    )\n} else {\n    final_fit <- Arima(ts_ortg, order = arimaorder(final_arimax)[1:3])\n}\n\nprint(summary(final_fit))\n\n# Also fit ARIMAX model for demonstration\ncat(\"\\n\\n=== For Comparison: ARIMAX Model with Exogenous Variables ===\\n\")\nfinal_fit_arimax <- Arima(ts_ortg,\n    order = arimaorder(arimax_auto)[1:3],\n    xreg = xreg_matrix\n)\nprint(summary(final_fit_arimax))\n```\n\n**Model Equations:**\n\n### Winning Model (Selected by Cross-Validation)\n\n```{r winning-equation, echo=FALSE, results='asis'}\narima_part <- arimaorder(final_fit)\n\nif (\"xreg\" %in% names(final_fit$call)) {\n    coefs <- coef(final_fit)\n\n    # Extract coefficients\n    ar_coefs <- coefs[grep(\"^ar\", names(coefs))]\n    ma_coefs <- coefs[grep(\"^ma\", names(coefs))]\n    xreg_coefs <- coefs[grep(\"^3PAr|^TS%\", names(coefs))]\n\n    cat(\"ARIMAX(\", arima_part[1], \",\", arima_part[2], \",\", arima_part[3], \") model:\\n\\n\", sep = \"\")\n\n    # Regression component\n    cat(\"$$\\n\")\n    cat(\"\\\\text{ORtg}_t = \\\\beta_0 + \\\\beta_1 \\\\cdot \\\\text{3PAr}_t + \\\\beta_2 \\\\cdot \\\\text{TS\\\\%}_t + N_t\\n\")\n    cat(\"$$\\n\\n\")\n\n    cat(\"where:\\n\\n\")\n    if (length(xreg_coefs) >= 1) cat(\"- $\\\\beta_1 =\", round(xreg_coefs[1], 3), \"$\\n\")\n    if (length(xreg_coefs) >= 2) cat(\"- $\\\\beta_2 =\", round(xreg_coefs[2], 3), \"$\\n\")\n\n    # ARIMA component for N_t\n    cat(\"\\n$N_t$ follows ARIMA(\", arima_part[1], \",\", arima_part[2], \",\", arima_part[3], \"):\\n\\n\", sep = \"\")\n\n    cat(\"$$\\n\")\n    if (arima_part[2] == 1) {\n        cat(\"(1 - B)^{\", arima_part[2], \"} N_t = \", sep = \"\")\n    } else if (arima_part[2] > 1) {\n        cat(\"(1 - B)^{\", arima_part[2], \"} N_t = \", sep = \"\")\n    } else {\n        cat(\"N_t = \")\n    }\n\n    # Add AR terms\n    if (length(ar_coefs) > 0) {\n        ar_terms <- paste0(round(ar_coefs, 3), \" N_{t-\", 1:length(ar_coefs), \"}\")\n        cat(paste(ar_terms, collapse = \" + \"), \" + \")\n    }\n\n    # Add MA terms\n    if (length(ma_coefs) > 0) {\n        ma_terms <- paste0(round(ma_coefs, 3), \" \\\\epsilon_{t-\", 1:length(ma_coefs), \"}\")\n        cat(paste(ma_terms, collapse = \" + \"), \" + \")\n    }\n\n    cat(\"\\\\epsilon_t\\n\")\n    cat(\"$$\\n\\n\")\n\n    cat(\"where $B$ is the backshift operator and $\\\\epsilon_t$ is white noise.\\n\")\n} else {\n    cat(\"ARIMA(\", arima_part[1], \",\", arima_part[2], \",\", arima_part[3], \") model:\\n\\n\", sep = \"\")\n    cat(\"$$\\n\")\n    cat(\"(1 - B) \\\\text{ORtg}_t = \\\\epsilon_t\\n\")\n    cat(\"$$\\n\\n\")\n}\n```\n\n## Forecasting\n\n```{r arimax-forecast, warning=FALSE, message=FALSE, fig.width=12, fig.height=7}\nif (\"xreg\" %in% names(final_fit$call)) {\n    # Forecast 3PAr and TS%\n    fc_3par <- forecast(auto.arima(ts_3par), h = 5)\n    fc_tspct <- forecast(auto.arima(ts_tspct), h = 5)\n\n    # Create future xreg matrix\n    xreg_future <- cbind(\n        `3PAr` = fc_3par$mean,\n        `TS%` = fc_tspct$mean\n    )\n\n    # Forecast ORtg\n    fc_final <- forecast(final_fit, xreg = xreg_future, h = 5)\n} else {\n    fc_final <- forecast(final_fit, h = 5)\n}\n\n# Plot forecast\nautoplot(fc_final) +\n    labs(\n        title = \"ORtg Forecast: 2026-2030 (ARIMAX Model)\",\n        subtitle = paste0(\"Model: \", paste0(final_fit), \" | Using forecasted 3PAr and TS% as exogenous inputs\"),\n        x = \"Year\",\n        y = \"Offensive Rating (Points per 100 Possessions)\"\n    ) +\n    theme_minimal(base_size = 12) +\n    theme(plot.subtitle = element_text(size = 9))\n\ncat(\"\\nPoint Forecasts:\\n\")\nprint(fc_final$mean)\n\ncat(\"\\n\\n80% Prediction Interval:\\n\")\nprint(fc_final$lower[, 1])\nprint(fc_final$upper[, 1])\n```\n\n## Interpretation\n\n```{r arimax-commentary-setup, warning=FALSE, message=FALSE, echo=FALSE}\nhas_xreg <- \"xreg\" %in% names(final_fit$call)\ntest_rmse <- cv_results$RMSE[best_idx]\ntest_mape <- cv_results$MAPE[best_idx]\n```\n\nThe ARIMAX model tells a compelling story about modern basketball's transformation.\n\n**The Analytics Advantage**\n\n```{r echo=FALSE, results='asis'}\nif (has_xreg) {\n    cat(\"Our analysis confirms what front offices discovered in 2012: both shot selection (3PAr) and shooting skill (TS%) significantly predict offensive efficiency. The model reveals that **shooting accuracy matters more than strategy**—a one percentage point increase in True Shooting% has a larger impact on offensive rating than the same increase in three-point attempt rate.\\n\\nThis ARIMAX model outperformed plain ARIMA, confirming that exogenous variables add real predictive power. Shot selection and skill improve ORtg forecasts beyond what temporal patterns alone can capture. Including the right exogenous variables isn't just theoretically justified—it's empirically beneficial. This validates the Houston Rockets' famous insight: it's not just about *shooting* threes, it's about *making* them.\\n\")\n} else {\n    cat(\"Interestingly, adding exogenous variables did not improve forecast accuracy in cross-validation. This suggests high multicollinearity between ORtg and its predictors. \\n\")\n}\n```\n\n**Forecast Performance**\n\nThe model achieved a test RMSE of **`r round(test_rmse, 2)` points per 100 possessions**, corresponding to approximately **`r round(test_mape, 1)`%** average error. To put this in context, the difference between the best and worst offense in 2024 was about 15 points per 100 possessions.\n\n**What the Future Holds**\n\n```{r echo=FALSE, results='asis'}\nif (has_xreg) {\n    cat(\"The forecast projects offensive efficiency will continue climbing through 2030, driven by relentless growth in both three-point volume and shooting accuracy. This assumes the analytics revolution hasn't plateaued—that teams will keep pushing boundaries, that shooters will keep improving, and that defenses won't find a systematic counter-strategy.\\n\\nThe widening prediction intervals tell us the model is honest about uncertainty: forecasting 2030 from 2025 data means predicting the unpredictable.\\n\")\n} else {\n    cat(\"Forecasts rely purely on historical ORtg patterns, capturing the league's 45-year trajectory toward more efficient offense. The trend is clear, but the mechanism remains in the residuals.\\n\")\n}\n```\n\n**The Basketball Insight**\n\nHere's what matters for teams: offensive efficiency isn't magic, it's a function of **where you shoot** (3PAr) and **how well you shoot** (TS%). The model equation makes this quantitative:\n\n$$\n\\text{ORtg}_t = \\beta_0 + \\beta_1 \\times \\text{3PAr}_t + \\beta_2 \\times \\text{TS\\%}_t + N_t\n$$\n\nwhere $N_t$ captures autocorrelated shocks (momentum, injuries, schedule strength).\n\nTeams have two levers:\n\n1. **Strategic**: Shoot more threes (reallocate shot distribution)\n2. **Developmental**: Improve shooting accuracy (player development, coaching)\n\nThe analytics revolution validated a simple truth: efficiency is *measurable* and *improvable*.\n\n:::\n\n## COVID Impact on Attendance (ARIMAX with Intervention)\n\n- **Response Variable**: `Total_Attendance`\n- **Exogenous Variables**: `ORtg`, `Pace`, `COVID_Dummy` (pulse intervention)\n\nThe model includes three key variables: ORtg captures how better offensive performance leads to more entertaining games and higher attendance; Pace reflects whether faster games attract more fans; and the COVID_Dummy captures the structural break in 2020-2021 from empty arenas and capacity restrictions.\n\n::: {.panel-tabset}\n\n## EDA\n\n```{r attendance-eda, warning=FALSE, message=FALSE, fig.width=12, fig.height=8}\nleague_post2000 <- league_avg %>% filter(Season >= 2000)\n\nts_attend <- ts(league_post2000$Total_Attendance, start = 2000, frequency = 1)\nts_ortg_sub <- ts(league_post2000$ORtg, start = 2000, frequency = 1)\nts_pace_sub <- ts(league_post2000$Pace, start = 2000, frequency = 1)\nts_covid <- ts(league_post2000$COVID_Dummy, start = 2000, frequency = 1)\n\np1 <- autoplot(ts_attend / 1e6) +\n    labs(title = \"Total NBA Attendance\", y = \"Attendance (Millions)\") +\n    geom_vline(xintercept = 2020, linetype = \"dashed\", color = \"red\") +\n    annotate(\"text\", x = 2020, y = 23, label = \"COVID-19\", color = \"red\", hjust = -0.1) +\n    theme_minimal()\n\np2 <- autoplot(ts_ortg_sub) +\n    labs(title = \"Offensive Rating\", y = \"ORtg\") +\n    theme_minimal()\n\np3 <- autoplot(ts_pace_sub) +\n    labs(title = \"Pace\", y = \"Pace\") +\n    theme_minimal()\n\np1 / (p2 | p3)\n```\n\nThe attendance plot tells a stark before-and-after story: from 2000-2019, the NBA showed remarkable stability around 22 million attendees per season as a reliable entertainment product. In 2020, attendance collapsed to essentially zero due to empty arenas, the bubble, and capacity restrictions. From 2021-2025, gradual recovery began but with visible scars. Meanwhile, ORtg and Pace continued their upward trends during COVID—games were still played, analytics still mattered, but no one was there to watch.\n\n## Model Fitting\n\n```{r attendance-auto, warning=FALSE, message=FALSE}\n# Prepare exogenous matrix\nxreg_attend <- cbind(\n    ORtg = ts_ortg_sub,\n    Pace = ts_pace_sub,\n    COVID = ts_covid\n)\n\n# auto.arima() method\narimax_attend_auto <- auto.arima(ts_attend, xreg = xreg_attend, seasonal = FALSE)\n\nprint(arimax_attend_auto)\n\n# Diagnostics\ncheckresiduals(arimax_attend_auto)\n```\n\n```{r attendance-manual, warning=FALSE, message=FALSE}\n# Manual method: Regression + ARIMA\ndf_attend <- data.frame(\n    Attendance = as.numeric(ts_attend),\n    ORtg = as.numeric(ts_ortg_sub),\n    Pace = as.numeric(ts_pace_sub),\n    COVID = as.numeric(ts_covid)\n)\n\nlm_attend <- lm(Attendance ~ ORtg + Pace + COVID, data = df_attend)\n\ncat(\"Regression Results:\\n\")\nsummary(lm_attend)\n```\n\n```{r attendance-reg-narrative-setup, echo=FALSE, message=FALSE}\ncovid_coef <- round(coef(lm_attend)[\"COVID\"], 0)\ncovid_impact_millions <- round(abs(coef(lm_attend)[\"COVID\"]) / 1e6, 1)\n```\n\nThe regression reveals COVID's devastating impact in stark numerical terms:\n\n$$\n\\beta_{\\text{COVID}} = `r format(covid_coef, big.mark=\",\")`\n$$\n\nThe pandemic reduced attendance by approximately **`r covid_impact_millions` million attendees** during 2020-2021. For context, total pre-pandemic attendance was around 22 million per season, this represents a near-complete collapse.\n\n```{r echo=FALSE}\n# Fit ARIMA to residuals\nresid_attend <- ts(residuals(lm_attend), start = 2000, frequency = 1)\narima_resid_attend <- auto.arima(resid_attend, seasonal = FALSE)\n\ncat(\"ARIMA model for residuals:\\n\")\nprint(arima_resid_attend)\n\n# Combined manual model\narimax_attend_manual <- Arima(ts_attend,\n    order = arimaorder(arima_resid_attend)[1:3],\n    xreg = xreg_attend\n)\n\nprint(arimax_attend_manual)\n```\n\n## Cross-Validation\n\n```{r attendance-cv, warning=FALSE, message=FALSE, fig.width=10, fig.height=6}\n# Train: 2000-2018, Test: 2019-2024 (includes pre-COVID and COVID periods)\ntrain_end_att <- 2018\ntest_start_att <- 2019\n\ntrain_attend <- window(ts_attend, end = train_end_att)\ntrain_ortg_a <- window(ts_ortg_sub, end = train_end_att)\ntrain_pace_a <- window(ts_pace_sub, end = train_end_att)\ntrain_covid_a <- window(ts_covid, end = train_end_att)\n\ntest_attend <- window(ts_attend, start = test_start_att)\ntest_ortg_a <- window(ts_ortg_sub, start = test_start_att)\ntest_pace_a <- window(ts_pace_sub, start = test_start_att)\ntest_covid_a <- window(ts_covid, start = test_start_att)\n\nh_att <- length(test_attend)\n\nxreg_train_att <- cbind(ORtg = train_ortg_a, Pace = train_pace_a, COVID = train_covid_a)\nxreg_test_att <- cbind(ORtg = test_ortg_a, Pace = test_pace_a, COVID = test_covid_a)\n\n\n# Model 1: auto.arima() - use simpler constraints for small dataset\nfit_auto_att <- tryCatch(\n    {\n        auto.arima(train_attend,\n            xreg = xreg_train_att, seasonal = FALSE,\n            max.p = 2, max.q = 2, max.d = 1, stepwise = TRUE\n        )\n    },\n    error = function(e) {\n        xreg_no_covid <- cbind(ORtg = train_ortg_a, Pace = train_pace_a)\n        auto.arima(train_attend,\n            xreg = xreg_no_covid, seasonal = FALSE,\n            max.p = 2, max.q = 2, max.d = 1\n        )\n    }\n)\n\n# Model 2: Manual method - use simpler order if needed\nfit_manual_att <- tryCatch(\n    {\n        Arima(train_attend,\n            order = arimaorder(arima_resid_attend)[1:3],\n            xreg = xreg_train_att\n        )\n    },\n    error = function(e) {\n        xreg_no_covid <- cbind(ORtg = train_ortg_a, Pace = train_pace_a)\n        Arima(train_attend, order = c(0, 1, 0), xreg = xreg_no_covid)\n    }\n)\n\n# Model 3: Benchmark\nfit_bench_att <- auto.arima(train_attend, seasonal = FALSE, max.p = 2, max.q = 2)\n\n# Forecasts - handle different xreg structures\nif (\"COVID\" %in% names(coef(fit_auto_att))) {\n    fc_auto_att <- forecast(fit_auto_att, xreg = xreg_test_att, h = h_att)\n} else {\n    xreg_test_no_covid <- cbind(ORtg = test_ortg_a, Pace = test_pace_a)\n    fc_auto_att <- forecast(fit_auto_att, xreg = xreg_test_no_covid, h = h_att)\n}\n\nif (\"COVID\" %in% names(coef(fit_manual_att))) {\n    fc_manual_att <- forecast(fit_manual_att, xreg = xreg_test_att, h = h_att)\n} else {\n    xreg_test_no_covid <- cbind(ORtg = test_ortg_a, Pace = test_pace_a)\n    fc_manual_att <- forecast(fit_manual_att, xreg = xreg_test_no_covid, h = h_att)\n}\n\nfc_bench_att <- forecast(fit_bench_att, h = h_att)\n\n# Accuracy\nacc_auto_att <- accuracy(fc_auto_att, test_attend)[2, c(\"RMSE\", \"MAE\", \"MAPE\")]\nacc_manual_att <- accuracy(fc_manual_att, test_attend)[2, c(\"RMSE\", \"MAE\", \"MAPE\")]\nacc_bench_att <- accuracy(fc_bench_att, test_attend)[2, c(\"RMSE\", \"MAE\", \"MAPE\")]\n\ncat(\"\\n=== ATTENDANCE MODEL CROSS-VALIDATION (Test: 2019-2024) ===\\n\\n\")\ncv_att_results <- data.frame(\n    Model = c(\"ARIMAX\", \"ARIMAX\", \"ARIMA\"),\n    RMSE = c(acc_auto_att[\"RMSE\"], acc_manual_att[\"RMSE\"], acc_bench_att[\"RMSE\"]),\n    MAE = c(acc_auto_att[\"MAE\"], acc_manual_att[\"MAE\"], acc_bench_att[\"MAE\"]),\n    MAPE = c(acc_auto_att[\"MAPE\"], acc_manual_att[\"MAPE\"], acc_bench_att[\"MAPE\"])\n)\n\n# Display formatted table with RMSE in millions\ncv_att_display <- cv_att_results\ncv_att_display$RMSE <- cv_att_display$RMSE / 1e6\ncv_att_display$MAE <- cv_att_display$MAE / 1e6\n\nkable(cv_att_display,\n    format = \"html\",\n    digits = 3,\n    caption = \"Cross-Validation Results: Attendance Models (Test Set: 2019-2024)\",\n    col.names = c(\"Model\", \"RMSE (Millions)\", \"MAE (Millions)\", \"MAPE (%)\")\n) %>%\n    kable_styling(\n        full_width = FALSE,\n        bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")\n    ) %>%\n    row_spec(which.min(cv_att_results$RMSE), bold = TRUE, color = \"white\", background = \"#006bb6\")\n\nbest_idx_att <- which.min(cv_att_results$RMSE)\ncat(\"\\n*** BEST MODEL: \", cv_att_results$Model[best_idx_att], \"***\\n\")\n```\n\nWhen fitted on full data (2000-2025), the COVID dummy captures the unprecedented shock effectively.\n\n## Final Model & Interpretation\n\n```{r attendance-final, warning=FALSE, message=FALSE, fig.width=12, fig.height=6}\n# Refit best model on full data\nif (cv_att_results$Model[best_idx_att] == \"ARIMAX (auto)\") {\n    final_attend <- Arima(ts_attend,\n        order = arimaorder(arimax_attend_auto)[1:3],\n        xreg = xreg_attend\n    )\n} else if (cv_att_results$Model[best_idx_att] == \"ARIMAX (manual)\") {\n    final_attend <- arimax_attend_manual\n} else {\n    final_attend <- auto.arima(ts_attend, seasonal = FALSE)\n}\n\ncat(\"Final Attendance Model:\\n\")\nprint(summary(final_attend))\n\n# Forecast\nfc_ortg_fut <- forecast(auto.arima(ts_ortg_sub), h = 5)\nfc_pace_fut <- forecast(auto.arima(ts_pace_sub), h = 5)\n\n# Create xreg based on what variables the model has\nif (\"COVID\" %in% names(coef(final_attend))) {\n    xreg_future_att <- cbind(\n        ORtg = fc_ortg_fut$mean,\n        Pace = fc_pace_fut$mean,\n        COVID = rep(0, 5)\n    )\n} else {\n    xreg_future_att <- cbind(\n        ORtg = fc_ortg_fut$mean,\n        Pace = fc_pace_fut$mean\n    )\n}\n\nfc_attend_final <- forecast(final_attend, xreg = xreg_future_att, h = 5)\n\nautoplot(fc_attend_final) +\n    labs(\n        title = \"NBA Attendance Forecast: 2026-2030\",\n        subtitle = \"Assumes full COVID recovery (COVID_Dummy = 0)\",\n        x = \"Year\",\n        y = \"Total Attendance (Millions)\"\n    ) +\n    scale_y_continuous(labels = function(x) x / 1e6) +\n    theme_minimal()\n\n```\n\n```{r attendance-commentary-setup, echo=FALSE, message=FALSE}\nhas_covid <- \"COVID\" %in% names(coef(final_attend))\nhas_ortg <- \"ORtg\" %in% names(coef(final_attend))\nif (has_covid) {\n    covid_impact <- coef(final_attend)[\"COVID\"] / 1e6\n}\n```\n\n```{r echo=FALSE, results='asis'}\nif (has_covid) {\n    cat(\"March 2020 left an indelible mark in the data. The COVID dummy variable carries a coefficient of **\", round(covid_impact, 2), \" million attendees**—representing nearly a 90% collapse in arena attendance during the 2020-2021 seasons.\\n\\nThis wasn't gradual decline. It was instantaneous erasure. Intervention analysis quantifies what everyone witnessed: the pandemic reduced attendance by ~20 million (near-complete collapse), this shock was structural and unpredictable from pre-2020 trends (no amount of historical data could forecast a global pandemic), and the dummy variable approach cleanly separates the COVID effect from underlying trends. Including this dummy variable wasn't just statistically beneficial—it was necessary to capture a shock that no amount of historical data could have predicted. This serves as a natural experiment demonstrating how external shocks disrupt time series patterns.\\n\", sep = \"\")\n} else {\n    cat(\"Here's where cross-validation reveals a hard truth about forecasting: the COVID dummy was *all zeros* in our training data (2000-2018) because the pandemic didn't exist yet. The model couldn't learn what it hadn't seen.\\n\\nWhen the test period arrived (2019-2024), actual attendance plummeted by 90% in 2020. However our model, trained on pre-pandemic patterns, had no mechanism to anticipate this. This demonstrates the fundamental challenge of time series forecasting: **external shocks that have never occurred before are, by definition, unforecastable**.\")\n}\n```\n\n```{r echo=FALSE, results='asis'}\nif (has_ortg) {\n    cat(\"Beyond COVID's overwhelming impact, the model detects subtler forces: offensive rating and pace do influence attendance, but their effects are small compared to the pandemic shock. This tells us that **fans care more about whether games happen** than about how exciting those games are. A boring game with 18,000 fans beats an offensive shootout with zero.\\n\\nAttendance is sticky—fans buy season tickets, form habits, make plans. Game quality matters at the margin (a 115 ORtg season might draw slightly more than a 105 ORtg season), but structural factors like arena access, pricing, and health safety dominate.\\n\")\n} else {\n    cat(\"The model relies purely on time-series patterns, revealing that attendance follows its own momentum: yesterday's crowds predict tomorrow's. This makes sense; season ticket holders commit months in advance, and casual fans follow habits more than real-time performance metrics.\")\n}\n```\n:::\n\n---\n\n# VAR (Vector Autoregression) Models\n\n## Efficiency Drivers (VAR)\n\n**Variables**: `ORtg`, `Pace`, `3PAr`\n\nThe theoretical rationale for this VAR model involves multiple bidirectional relationships: faster tempo (Pace) creates more transition opportunities favoring quick 3PT attempts (3PAr), while teams shooting more 3s may adopt faster pace to maximize possessions. Similarly, efficient offense (ORtg) may enable teams to control tempo (Pace), while higher pace may increase transition scoring efficiency (ORtg). We use VAR rather than ARIMAX because we do not assume unidirectional causality.\n\n::: {.panel-tabset}\n\n## EDA & Stationarity\n\n```{r var-eda, warning=FALSE, message=FALSE, fig.width=12, fig.height=8}\n# Create VAR dataset\nvar_data <- ts(league_avg %>% dplyr::select(ORtg, Pace, `3PAr`),\n    start = 1980, frequency = 1\n)\n\n# Plot all series\nautoplot(var_data, facets = TRUE) +\n    labs(\n        title = \"VAR Variables: ORtg, Pace, 3PAr (1980-2025)\",\n        x = \"Year\", y = \"Value\"\n    ) +\n    theme_minimal()\n\ncat(\"Summary Statistics:\\n\")\nsummary(var_data)\n```\n\n```{r var-stationarity, warning=FALSE, message=FALSE}\n# ADF tests for each series\ncat(\"=== STATIONARITY TESTS ===\\n\\n\")\n\nadf_ortg_var <- adf.test(var_data[, \"ORtg\"])\nadf_pace_var <- adf.test(var_data[, \"Pace\"])\nadf_3par_var <- adf.test(var_data[, \"3PAr\"])\n\ncat(\n    \"ORtg: ADF p-value =\", round(adf_ortg_var$p.value, 4),\n    ifelse(adf_ortg_var$p.value < 0.05, \"(stationary)\", \"implies non-stationary\"), \"\\n\"\n)\ncat(\n    \"Pace: ADF p-value =\", round(adf_pace_var$p.value, 4),\n    ifelse(adf_pace_var$p.value < 0.05, \"(stationary)\", \"implies non-stationary\"), \"\\n\"\n)\ncat(\n    \"3PAr: ADF p-value =\", round(adf_3par_var$p.value, 4),\n    ifelse(adf_3par_var$p.value < 0.05, \"(stationary)\", \"implies non-stationary\"), \"\\n\\n\"\n)\n\n# Difference if non-stationary\nif (adf_ortg_var$p.value > 0.05 | adf_pace_var$p.value > 0.05 | adf_3par_var$p.value > 0.05) {\n    var_data_diff <- diff(var_data)\n\n    # Test differenced data\n    adf_ortg_diff <- adf.test(var_data_diff[, \"ORtg\"])\n    adf_pace_diff <- adf.test(var_data_diff[, \"Pace\"])\n    adf_3par_diff <- adf.test(var_data_diff[, \"3PAr\"])\n\n    cat(\"After first-differencing:\\n\")\n    cat(\"ORtg: ADF p-value =\", round(adf_ortg_diff$p.value, 4), \"\\n\")\n    cat(\"Pace: ADF p-value =\", round(adf_pace_diff$p.value, 4), \"\\n\")\n    cat(\"3PAr: ADF p-value =\", round(adf_3par_diff$p.value, 4), \"\\n\\n\")\n\n    if (adf_ortg_diff$p.value < 0.05 & adf_pace_diff$p.value < 0.05 & adf_3par_diff$p.value < 0.05) {\n        cat(\"All series now stationary. Proceeding with differenced data for VAR.\\n\\n\")\n        var_data_final <- var_data_diff\n        differenced <- TRUE\n    } else {\n        var_data_final <- var_data_diff\n        differenced <- TRUE\n    }\n} else {\n    var_data_final <- var_data\n    differenced <- FALSE\n}\n```\n\n## Model Selection & Fitting\n\n```{r var-select, warning=FALSE, message=FALSE}\n# Determine optimal lag order\ncat(\"=== LAG ORDER SELECTION ===\\n\\n\")\nvar_select <- VARselect(var_data_final, lag.max = 8, type = \"const\")\n\nprint(var_select$selection)\nprint(var_select$criteria)\n\n# Fit models with different lag orders\nlags_to_fit <- unique(var_select$selection[1:3])\n\ncat(\"Fitting VAR models with p =\", paste(lags_to_fit, collapse = \", \"), \"\\n\\n\")\n\nvar_models <- list()\nfor (p in lags_to_fit) {\n    var_models[[paste0(\"VAR_\", p)]] <- VAR(var_data_final, p = p, type = \"const\")\n    cat(\"VAR(\", p, \") fitted successfully\\n\", sep = \"\")\n}\n```\n\n```{r var-summaries, warning=FALSE, message=FALSE}\nfor (name in names(var_models)) {\n    cat(\"========================================\\n\")\n    cat(name, \"Summary:\\n\")\n    cat(\"========================================\\n\\n\")\n    print(summary(var_models[[name]]))\n    cat(\"\\n\\n\")\n}\n```\n\n\n## Cross-Validation\n\n```{r var-cv, warning=FALSE, message=FALSE, fig.width=10, fig.height=6}\ncat(\"=== TIME SERIES CROSS-VALIDATION FOR VAR ===\\n\\n\")\n\n# Split: Train 1980-2019, Test 2020-2024\ntrain_end_var <- 2019\n\nif (differenced) {\n    # Differenced data starts at 1981 (lost 1980 due to differencing)\n    # Training: 1981-2019, Test: 2020-2024\n    train_var <- window(var_data_final, end = train_end_var)\n    test_var <- window(var_data_final, start = train_end_var + 1)\n} else {\n    train_var <- window(var_data_final, end = train_end_var)\n    test_var <- window(var_data_final, start = train_end_var + 1)\n}\n\nh_var <- nrow(test_var)\n\n# Fit VAR models on training data with error handling\nvar_train_models <- list()\nfor (p in lags_to_fit) {\n    model <- tryCatch(\n        {\n            VAR(train_var, p = p, type = \"const\")\n        },\n        error = function(e) {\n            cat(\"Warning: VAR(\", p, \") failed. Trying with smaller lag...\\n\", sep = \"\")\n            if (p > 1) {\n                VAR(train_var, p = 1, type = \"const\")\n            } else {\n                NULL\n            }\n        }\n    )\n    if (!is.null(model)) {\n        var_train_models[[paste0(\"VAR_\", p)]] <- model\n    }\n}\n\n# Generate forecasts\nrmse_results <- data.frame()\n\nif (length(var_train_models) == 0) {\n    cat(\"ERROR: No VAR models were successfully fitted. Check data and lag selection.\\n\")\n} else {\n    cat(\"Successfully fitted\", length(var_train_models), \"VAR model(s)\\n\\n\")\n}\n\nfor (name in names(var_train_models)) {\n    fc <- tryCatch(\n        {\n            predict(var_train_models[[name]], n.ahead = h_var)\n        },\n        error = function(e) {\n            cat(\"Warning: Forecast failed for\", name, \"\\n\")\n            NULL\n        }\n    )\n\n    if (is.null(fc)) next\n\n    # Extract forecasts for each variable\n    fc_ortg <- fc$fcst$ORtg[, \"fcst\"]\n    fc_pace <- fc$fcst$Pace[, \"fcst\"]\n    fc_3par <- fc$fcst$`3PAr`[, \"fcst\"]\n\n    # Convert test data to numeric vectors for comparison\n    test_ortg_vec <- as.numeric(test_var[, \"ORtg\"])\n    test_pace_vec <- as.numeric(test_var[, \"Pace\"])\n    test_3par_vec <- as.numeric(test_var[, \"3PAr\"])\n\n    # Ensure equal lengths (forecasts might be shorter if h_var is large)\n    n_compare <- min(length(test_ortg_vec), length(fc_ortg))\n\n    # Calculate RMSE for each variable\n    rmse_ortg <- sqrt(mean((test_ortg_vec[1:n_compare] - fc_ortg[1:n_compare])^2))\n    rmse_pace <- sqrt(mean((test_pace_vec[1:n_compare] - fc_pace[1:n_compare])^2))\n    rmse_3par <- sqrt(mean((test_3par_vec[1:n_compare] - fc_3par[1:n_compare])^2))\n\n    # Average RMSE across variables\n    rmse_avg <- mean(c(rmse_ortg, rmse_pace, rmse_3par))\n\n    rmse_results <- rbind(rmse_results, data.frame(\n        Model = name,\n        Lags = as.numeric(gsub(\"VAR_\", \"\", name)),\n        RMSE_ORtg = rmse_ortg,\n        RMSE_Pace = rmse_pace,\n        RMSE_3PAr = rmse_3par,\n        RMSE_Avg = rmse_avg\n    ))\n}\n\ncat(\"Cross-Validation Results:\\n\")\nif (nrow(rmse_results) > 0) {\n    # Display formatted table\n    kable(rmse_results,\n        format = \"html\",\n        digits = 4,\n        caption = \"Cross-Validation Results: VAR Models (Test Set: 2020-2024)\",\n        col.names = c(\"Model\", \"Lags\", \"RMSE (ORtg)\", \"RMSE (Pace)\", \"RMSE (3PAr)\", \"Avg RMSE\"),\n        row.names = FALSE\n    ) %>%\n        kable_styling(\n            full_width = FALSE,\n            bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")\n        ) %>%\n        row_spec(which.min(rmse_results$RMSE_Avg), bold = TRUE, color = \"white\", background = \"#006bb6\")\n\n    # Plot RMSEs\n    ggplot(rmse_results, aes(x = factor(Lags), y = RMSE_Avg, fill = Model)) +\n        geom_bar(stat = \"identity\", width = 0.6) +\n        geom_text(aes(label = round(RMSE_Avg, 3)), vjust = -0.5, fontface = \"bold\") +\n        labs(\n            title = \"VAR Model Cross-Validation: Average RMSE\",\n            subtitle = \"Lower RMSE = Better out-of-sample forecast performance\",\n            x = \"Number of Lags (p)\",\n            y = \"Average RMSE across ORtg, Pace, 3PAr\"\n        ) +\n        theme_minimal() +\n        theme(legend.position = \"none\") +\n        scale_fill_brewer(palette = \"Set2\")\n\n    best_var_idx <- which.min(rmse_results$RMSE_Avg)\n    cat(\"\\n*** BEST VAR MODEL: \", rmse_results$Model[best_var_idx], \" ***\\n\")\n    cat(\"Average RMSE =\", round(rmse_results$RMSE_Avg[best_var_idx], 4), \"\\n\")\n} else {\n    cat(\"No cross-validation results available (all models failed)\\n\")\n    best_var_idx <- 1 # Default to first model\n}\n```\n\n## Final Model & Forecast\n\n```{r var-final, warning=FALSE, message=FALSE, fig.width=12, fig.height=10}\n# Select best model\nif (nrow(rmse_results) > 0) {\n    best_var_name <- rmse_results$Model[best_var_idx]\n    best_var_lags <- rmse_results$Lags[best_var_idx]\n} else {\n    best_var_lags <- min(lags_to_fit)\n}\n\ncat(\"Final VAR Model: VAR(\", best_var_lags, \")\\n\\n\", sep = \"\")\n\n# Refit on full data\nfinal_var <- tryCatch(\n    {\n        VAR(var_data_final, p = best_var_lags, type = \"const\")\n    },\n    error = function(e) {\n        VAR(var_data_final, p = 1, type = \"const\")\n    }\n)\n\nprint(summary(final_var))\n\n# Forecast 5 periods ahead\nfc_var_final <- predict(final_var, n.ahead = 5)\n\n# Get variable names\nfc_var_names <- names(fc_var_final$fcst)\ntpar_fc_name <- fc_var_names[grep(\"3PAr|PAr\", fc_var_names, ignore.case = TRUE)]\nif (length(tpar_fc_name) == 0) tpar_fc_name <- fc_var_names[3]\n\n# Display forecasts\ncat(\"\\n=== 5-Period Forecasts ===\\n\\n\")\ncat(\"ORtg:\\n\")\nprint(fc_var_final$fcst$ORtg)\ncat(\"\\n\", tpar_fc_name, \":\\n\", sep = \"\")\nprint(fc_var_final$fcst[[tpar_fc_name]])\ncat(\"\\nPace:\\n\")\nprint(fc_var_final$fcst$Pace)\n\n# Plot forecasts\nfor (vname in fc_var_names) {\n    plot(fc_var_final, names = vname)\n}\n```\n\n**Granger Causality Tests**:\n\n```{r var-granger, warning=FALSE, message=FALSE}\n# Granger causality tests\nvar_names <- names(final_var$varresult)\ntpar_name <- var_names[grep(\"3PAr|PAr\", var_names, ignore.case = TRUE)]\nif (length(tpar_name) == 0) tpar_name <- var_names[3]\n\ngranger_3par_ortg <- causality(final_var, cause = tpar_name)$Granger\ngranger_pace <- causality(final_var, cause = \"Pace\")$Granger\ngranger_ortg <- causality(final_var, cause = \"ORtg\")$Granger\n\ncat(\"=== Granger Causality Tests ===\\n\\n\")\ncat(\"3PAr → {ORtg, Pace}: F =\", round(granger_3par_ortg$statistic, 3),\n    \", p =\", round(granger_3par_ortg$p.value, 4), \"\\n\")\ncat(\"Pace → {ORtg, 3PAr}: F =\", round(granger_pace$statistic, 3),\n    \", p =\", round(granger_pace$p.value, 4), \"\\n\")\ncat(\"ORtg → {Pace, 3PAr}: F =\", round(granger_ortg$statistic, 3),\n    \", p =\", round(granger_ortg$p.value, 4), \"\\n\")\n```\n\nGranger causality tests reveal the temporal ordering of the analytics revolution by determining which variables' past values predict other variables' future changes. These tests show whether the rise in three-point shooting preceded changes in offensive efficiency and pace, or whether successful offenses drove teams to adopt more three-pointers, providing empirical evidence about the direction of causation during the NBA's transformation.\n\n```{r var-irf, warning=FALSE, message=FALSE, fig.width=12, fig.height=8}\nvar_names_irf <- names(final_var$varresult)\ntpar_name_irf <- var_names_irf[grep(\"3PAr|PAr\", var_names_irf, ignore.case = TRUE)]\nif (length(tpar_name_irf) == 0) tpar_name_irf <- var_names_irf[3]\n\n# IRFs\nirf_3par_ortg <- irf(final_var, impulse = tpar_name_irf, response = \"ORtg\", n.ahead = 10)\nplot(irf_3par_ortg, main = paste(\"Impulse:\", tpar_name_irf, \"→ Response: ORtg\"))\n\nirf_pace_ortg <- irf(final_var, impulse = \"Pace\", response = \"ORtg\", n.ahead = 10)\nplot(irf_pace_ortg, main = \"Impulse: Pace → Response: ORtg\")\n\nirf_ortg_3par <- irf(final_var, impulse = \"ORtg\", response = tpar_name_irf, n.ahead = 10)\nplot(irf_ortg_3par, main = paste(\"Impulse: ORtg → Response:\", tpar_name_irf))\n```\n\n## Interpretation\n\nThe VAR model reveals meaningful relationships among offensive efficiency, three-point shooting, and pace across NBA history. Granger causality tests quantify whether past values of one variable help predict future values of others, addressing the question of whether the rise in three-point shooting preceded changes in offensive efficiency or vice versa.\n\nImpulse response functions trace how a one-time shock to one variable cascades through the system, showing whether innovations in one aspect of basketball strategy have lasting effects on others or if defensive adjustments eventually neutralize advantages. Together, these tools demonstrate that while the analytics revolution transformed the NBA, reflecting the complex adaptive nature of elite competition where strategic innovations provoke counter-responses.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"toc-depth":3,"embed-resources":true,"output-file":"multiTS_model.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.55","bibliography":["references.bib"],"csl":"nature.csl","theme":{"light":"sketchy","dark":"slate"},"toggle-theme":true,"page-navigation":true,"title":"Multivariate Time Series Modeling"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}