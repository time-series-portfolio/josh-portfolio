{"title":"Multivariate Time Series Modeling: ARIMAX & VAR","markdown":{"yaml":{"title":"Multivariate Time Series Modeling: ARIMAX & VAR","format":{"html":{"code-fold":true,"toc":true,"toc-depth":3,"embed-resources":true}}},"headingText":"Introduction","containsRefs":false,"markdown":"\n\n\nThis section extends univariate ARIMA analysis to **multivariate time series models**, examining how NBA offensive metrics, pace, shot selection, and external factors (COVID-19, financial markets) interact over time. We employ two complementary approaches:\n\n1. **ARIMAX/SARIMAX**: Models with exogenous predictors, treating one variable as the response and others as external regressors\n2. **VAR (Vector Autoregression)**: Systems where all variables influence each other bidirectionally\n\n---\n\n## Literature Review & Variable Justification\n\n### Analytics Revolution & Efficiency Dynamics\n\n@franks2015characterizing demonstrated that **pace** and **spacing** jointly determine offensive efficiency, suggesting bidirectional causality: faster pace creates spacing opportunities, while better spacing enables controlled pace. This motivates VAR modeling of `ORtg ~ Pace + 3PAr`.\n\n@goldsberry2019sprawlball documented how **three-point volume** preceded efficiency gains (2012-2016), implying `3PAr` may Granger-cause `ORtg`. However, @poropudas2023dean showed that teams with higher `TS%` subsequently increased 3PA, suggesting reverse causation. ARIMAX models can test directional relationships.\n\n### COVID-19 as Exogenous Shock\n\n@lopez2020performance found that **empty arenas** disrupted home-court advantage and pace-of-play rhythms. Attendance serves as a proxy for game environment, making it suitable as an exogenous variable in ARIMAX models predicting `ORtg` or `Pace`.\n\n### Sports Betting & NBA Dynamics\n\n@rodenberg2011sports established that betting market efficiency correlates with league popularity and viewership. Post-COVID, sports betting stocks (DKNG) may respond to NBA performance metrics and attendance recovery, motivating VAR models linking `DKNG ~ Attendance + ORtg`.\n\n---\n\n## Proposed Models\n\nBased on the literature and our research questions (intro.qmd:60-71), we propose **5 multivariate models**:\n\n### Model 1: Efficiency Drivers (VAR)\n**Variables**: `ORtg ~ Pace + 3PAr`\n**Rationale**: Test whether pace and shot selection jointly drive efficiency, or whether efficiency improvements enable strategic changes. VAR captures bidirectional feedback loops.\n**Expected Relationship**: Positive (higher pace + 3PAr � higher ORtg), but directionality uncertain.\n\n### Model 2: Shot Selection & Efficiency (ARIMAX)\n**Response**: `ORtg`\n**Exogenous**: `3PAr`, `TS%`\n**Rationale**: Treat shot selection (3PAr) and shooting skill (TS%) as external strategy variables explaining offensive output. ARIMAX assumes these drive ORtg unidirectionally.\n**Expected Relationship**: ORtg = f(3PAr, TS%), with TS% likely stronger predictor.\n\n### Model 3: COVID Impact on Attendance (ARIMAX with Intervention)\n**Response**: `Attendance`\n**Exogenous**: `ORtg`, `Pace`, COVID dummy (2020-2021)\n**Rationale**: Attendance depends on game quality (ORtg) and entertainment value (Pace), but COVID created structural break. ARIMAX with pulse intervention.\n**Expected Relationship**: Attendance � with ORtg/Pace, but COVID dummy dominates 2020-2021.\n\n### Model 4: Pace Dynamics (VAR)\n**Variables**: `Pace ~ 3PAr + eFG%`\n**Rationale**: Fast pace and three-point shooting co-evolved post-2012. VAR tests whether pace changes preceded shot selection shifts or vice versa.\n**Expected Relationship**: Bidirectional positive feedback (3PAr � � Pace � � eFG% �).\n\n### Model 5: Sports Betting & NBA Recovery (VAR) - *Weekly Data*\n**Variables**: `DKNG ~ Attendance + ORtg` (aggregated to weekly)\n**Rationale**: Sports betting market (DKNG) responds to NBA attendance recovery and game quality post-COVID.\n**Expected Relationship**: DKNG � with Attendance recovery; ORtg weak/lagged effect.\n\n**Note**: For this analysis, we will fit **Models 1, 2, 3** (the requirement is 3 models). Models 4 and 5 will be completed for the final portfolio.\n\n---\n\n```{r setup, warning=FALSE, message=FALSE}\n# Load libraries\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(forecast)\nlibrary(astsa)\nlibrary(xts)\nlibrary(tseries)\nlibrary(fpp2)\nlibrary(fma)\nlibrary(lubridate)\nlibrary(TSstudio)\nlibrary(quantmod)\nlibrary(tidyquant)\nlibrary(plotly)\nlibrary(readr)\nlibrary(dplyr)\nlibrary(vars) # For VAR models\nlibrary(patchwork) # For plot layouts\nlibrary(kableExtra) # For formatted tables\nlibrary(gridExtra) # For arranging plots\n\n# Set theme\ntheme_set(theme_minimal(base_size = 12))\n\n# Load data\nall_adv_files <- list.files(\"data/adv_stats\", pattern = \"*.csv\", full.names = TRUE)\n\nall_adv_data <- map_df(all_adv_files, function(file) {\n    season_str <- str_extract(basename(file), \"\\\\d{4}-\\\\d{2}\")\n    season_year <- as.numeric(str_sub(season_str, 1, 4)) + 1\n    df <- read_csv(file, show_col_types = FALSE)\n    df$Season <- season_year\n    return(df)\n})\n\n# Calculate league averages\nleague_avg <- all_adv_data %>%\n    group_by(Season) %>%\n    summarise(\n        ORtg = mean(`Unnamed: 10_level_0_ORtg`, na.rm = TRUE),\n        DRtg = mean(`Unnamed: 11_level_0_DRtg`, na.rm = TRUE),\n        Pace = mean(`Unnamed: 13_level_0_Pace`, na.rm = TRUE),\n        `3PAr` = mean(`Unnamed: 15_level_0_3PAr`, na.rm = TRUE),\n        `TS%` = mean(`Unnamed: 16_level_0_TS%`, na.rm = TRUE),\n        `eFG%` = mean(`Offense Four Factors_eFG%`, na.rm = TRUE),\n        Total_Attendance = sum(`Unnamed: 29_level_0_Attend.`, na.rm = TRUE),\n        .groups = \"drop\"\n    )\n\n# Create COVID dummy variable\nleague_avg <- league_avg %>%\n    mutate(COVID_Dummy = ifelse(Season %in% c(2020, 2021), 1, 0))\n\ncat(\"Data loaded: 1980-2025,\", nrow(league_avg), \"seasons\\n\")\n```\n\n---\n\n# Part I: ARIMAX/SARIMAX Models\n\n## Model 2: Shot Selection & Efficiency (ARIMAX)\n\n**Response Variable**: `ORtg` (Offensive Rating)\n**Exogenous Variables**: `3PAr` (3-Point Attempt Rate), `TS%` (True Shooting %)\n\n### Step i) Variable Selection & Justification\n\n**Research Question**: Do strategic choices (shooting more 3s) and skill execution (shooting accuracy) explain offensive efficiency gains?\n\n**Theoretical Justification**:\n- **3PAr**: Analytics literature shows 3PT shots have higher expected value than mid-range (data_viz.qmd:109). Teams that adopt 3PT-heavy strategies should score more efficiently.\n- **TS%**: Measures shooting skill adjusting for 2PT, 3PT, and FT. Higher TS% directly translates to more points per possession.\n\n**Directional Assumption**: We assume `3PAr` and `TS%` *cause* `ORtg` (not the reverse). This is appropriate if we interpret 3PAr as a strategic choice variable and TS% as skill execution.\n\n```{r arimax-eda, warning=FALSE, message=FALSE, fig.width=12, fig.height=8}\n# Create time series\nts_ortg <- ts(league_avg$ORtg, start = 1980, frequency = 1)\nts_3par <- ts(league_avg$`3PAr`, start = 1980, frequency = 1)\nts_tspct <- ts(league_avg$`TS%`, start = 1980, frequency = 1)\n\n# Plot all three series\np1 <- autoplot(ts_ortg) + labs(title = \"Offensive Rating (ORtg)\", y = \"ORtg\") + theme_minimal()\np2 <- autoplot(ts_3par) + labs(title = \"3-Point Attempt Rate (3PAr)\", y = \"3PAr\") + theme_minimal()\np3 <- autoplot(ts_tspct) + labs(title = \"True Shooting % (TS%)\", y = \"TS%\") + theme_minimal()\n\np1 / p2 / p3\n```\n\nThe time series reveal basketball's transformation at a glance:\n\n- **ORtg** climbs gradually from ~104 in 1980 to ~113 in 2025—efficiency gains of nearly 9 points per 100 possessions\n- **3PAr** explodes post-2012 (the analytics inflection point), accelerating from ~25% to over 40% of all shot attempts\n- **TS%** rises steadily, suggesting shooting skill improved *alongside* strategic changes—players got better as teams got smarter\n\nAll three series trend upward together, raising the non-stationarity flag for our time series models.\n\n```{r arimax-correlation, warning=FALSE, message=FALSE}\n# Correlation analysis\ncor_data <- league_avg %>% dplyr::select(ORtg, `3PAr`, `TS%`)\ncat(\"Correlation Matrix:\\n\")\nprint(round(cor(cor_data, use = \"complete.obs\"), 3))\n```\n\n```{r correlation-narrative-setup, echo=FALSE, message=FALSE}\ncor_ortg_3par <- round(cor(league_avg$ORtg, league_avg$`3PAr`), 3)\ncor_ortg_ts <- round(cor(league_avg$ORtg, league_avg$`TS%`), 3)\ncor_3par_ts <- round(cor(league_avg$`3PAr`, league_avg$`TS%`), 3)\n```\n\nThe correlations tell a clear story:\n\n- **ORtg vs 3PAr**: r = `r cor_ortg_3par` (strong positive)—shooting more threes correlates with better offense\n- **ORtg vs TS%**: r = `r cor_ortg_ts` (very strong positive)—shooting accuracy matters even more\n- **3PAr vs TS%**: r = `r cor_3par_ts` (moderate positive)—teams shooting more threes also shoot better (selection effects: better shooters take more threes)\n\n**The takeaway**: Both predictors correlate strongly with offensive efficiency, but TS% shows the stronger association. Strategy matters, but execution matters more.\n\n### Step ii) Model Fitting: auto.arima() vs Manual Method\n\n#### Method 1: auto.arima() with Exogenous Variables\n\n```{r arimax-auto, warning=FALSE, message=FALSE}\n# Prepare exogenous matrix\nxreg_matrix <- cbind(\n    `3PAr` = ts_3par,\n    `TS%` = ts_tspct\n)\n\n# Fit using auto.arima()\ncat(\"Fitting ARIMAX using auto.arima()...\\n\\n\")\narimax_auto <- auto.arima(ts_ortg,\n    xreg = xreg_matrix, seasonal = FALSE,\n    stepwise = FALSE, approximation = FALSE\n)\n\ncat(\"auto.arima() selected model:\\n\")\nprint(arimax_auto)\n\ncat(\"\\n\\nModel Summary:\\n\")\nsummary(arimax_auto)\n```\n\n**Model Diagnostics**:\n\n```{r arimax-auto-diagnostics, warning=FALSE, message=FALSE, fig.width=12, fig.height=10}\n# Diagnostic plots\ncheckresiduals(arimax_auto)\n\n# Ljung-Box test\nljung_auto <- Box.test(arimax_auto$residuals, lag = 10, type = \"Ljung-Box\")\ncat(\"\\nLjung-Box Test (lag=10):\\n\")\ncat(\"  p-value =\", round(ljung_auto$p.value, 4), \"\\n\")\ncat(\"  Conclusion:\", ifelse(ljung_auto$p.value > 0.05,\n    \"Residuals are white noise \u0013\",\n    \"Some autocorrelation remains\"\n), \"\\n\")\n```\n\n#### Method 2: Manual Method (Regression + ARIMA on Residuals)\n\n**Step 1**: Fit linear regression\n\n```{r arimax-manual-lm, warning=FALSE, message=FALSE}\n# Create data frame\ndf_reg <- data.frame(\n    ORtg = as.numeric(ts_ortg),\n    PAr3 = as.numeric(ts_3par),\n    TSpct = as.numeric(ts_tspct)\n)\n\n# Fit regression\nlm_model <- lm(ORtg ~ PAr3 + TSpct, data = df_reg)\n\ncat(\"Linear Regression Results:\\n\")\nsummary(lm_model)\n```\n\n```{r regression-narrative-setup, echo=FALSE, message=FALSE}\nbeta_intercept <- round(coef(lm_model)[\"(Intercept)\"], 2)\nbeta_3par <- round(coef(lm_model)[\"PAr3\"], 2)\nbeta_ts <- round(coef(lm_model)[\"TSpct\"], 2)\n```\n\nThe regression equation reveals the mathematical relationship:\n\n$$\n\\text{ORtg} = `r beta_intercept` + `r beta_3par` \\times \\text{3PAr} + `r beta_ts` \\times \\text{TS\\%}\n$$\n\nHere's what this means on the court:\n\n- **1 percentage point increase in 3PAr** → ORtg increases by **`r beta_3par` points per 100 possessions**\n  (Moving from 30% to 31% of shots being threes adds `r beta_3par` points to offensive rating)\n\n- **1 percentage point increase in TS%** → ORtg increases by **`r beta_ts` points per 100 possessions**\n  (Improving from 55% to 56% True Shooting adds `r beta_ts` points—shooting *accuracy* has stronger impact than shot *selection*)\n```\n\n**Step 2**: Extract residuals and fit ARIMA\n\n```{r arimax-manual-arima, warning=FALSE, message=FALSE}\n# Extract residuals\nlm_residuals <- ts(residuals(lm_model), start = 1980, frequency = 1)\n\n# Plot residuals\nautoplot(lm_residuals) +\n    labs(title = \"Regression Residuals\", y = \"Residuals\") +\n    theme_minimal()\n\n# Fit ARIMA to residuals\ncat(\"\\n\\nFitting ARIMA to residuals...\\n\")\narima_resid <- auto.arima(lm_residuals, seasonal = FALSE)\n\ncat(\"\\nARIMA model for residuals:\\n\")\nprint(arima_resid)\n\n# Diagnostics\ncheckresiduals(arima_resid)\n```\n\n**Step 3**: Combine regression + ARIMA\n\n```{r arimax-manual-final, warning=FALSE, message=FALSE}\n# Manual ARIMAX: Use Arima() with same order as residual model and xreg\narima_order <- arimaorder(arima_resid)\n\narimax_manual <- Arima(ts_ortg,\n    order = c(arima_order[1], arima_order[2], arima_order[3]),\n    xreg = xreg_matrix\n)\n\ncat(\"Manual ARIMAX Model:\\n\")\nprint(arimax_manual)\n\ncat(\"\\n\\nCoefficients:\\n\")\nprint(coef(arimax_manual))\n```\n\n### Step iii) Cross-Validation to Choose Best Model\n\n```{r arimax-cv, warning=FALSE, message=FALSE, fig.width=12, fig.height=6}\ncat(\"Running time series cross-validation...\\n\\n\")\n\n# Define training period: 1980-2019, test: 2020-2024\ntrain_end <- 2019\ntest_start <- 2020\n\n# Split data\ntrain_ortg <- window(ts_ortg, end = train_end)\ntrain_3par <- window(ts_3par, end = train_end)\ntrain_tspct <- window(ts_tspct, end = train_end)\n\ntest_ortg <- window(ts_ortg, start = test_start)\ntest_3par <- window(ts_3par, start = test_start)\ntest_tspct <- window(ts_tspct, start = test_start)\n\nh <- length(test_ortg)\n\n# Prepare xreg for train/test\nxreg_train <- cbind(`3PAr` = train_3par, `TS%` = train_tspct)\nxreg_test <- cbind(`3PAr` = test_3par, `TS%` = test_tspct)\n\n# Fit models on training data\ncat(\"Fitting models on training data (1980-2019)...\\n\")\n\n# Model 1: auto.arima() method\nfit_auto <- auto.arima(train_ortg, xreg = xreg_train, seasonal = FALSE)\n\n# Model 2: Manual method\nfit_manual <- Arima(train_ortg,\n    order = c(arima_order[1], arima_order[2], arima_order[3]),\n    xreg = xreg_train\n)\n\n# Model 3: Simple ARIMA without exogenous (benchmark)\nfit_benchmark <- auto.arima(train_ortg, seasonal = FALSE)\n\n# Generate forecasts\nfc_auto <- forecast(fit_auto, xreg = xreg_test, h = h)\nfc_manual <- forecast(fit_manual, xreg = xreg_test, h = h)\nfc_benchmark <- forecast(fit_benchmark, h = h)\n\n# Calculate accuracy\nacc_auto <- accuracy(fc_auto, test_ortg)[2, c(\"RMSE\", \"MAE\", \"MAPE\")]\nacc_manual <- accuracy(fc_manual, test_ortg)[2, c(\"RMSE\", \"MAE\", \"MAPE\")]\nacc_benchmark <- accuracy(fc_benchmark, test_ortg)[2, c(\"RMSE\", \"MAE\", \"MAPE\")]\n\n# Display results\ncat(\"\\n=== CROSS-VALIDATION RESULTS (Test Set: 2020-2024) ===\\n\\n\")\ncv_results <- data.frame(\n    Model = c(\"ARIMAX (auto.arima)\", \"ARIMAX (manual)\", \"ARIMA (no exog)\"),\n    RMSE = c(acc_auto[\"RMSE\"], acc_manual[\"RMSE\"], acc_benchmark[\"RMSE\"]),\n    MAE = c(acc_auto[\"MAE\"], acc_manual[\"MAE\"], acc_benchmark[\"MAE\"]),\n    MAPE = c(acc_auto[\"MAPE\"], acc_manual[\"MAPE\"], acc_benchmark[\"MAPE\"])\n)\n\n# Display formatted table\nkable(cv_results,\n    format = \"html\",\n    digits = 3,\n    caption = \"Cross-Validation Results: ORtg Models (Test Set: 2020-2024)\",\n    col.names = c(\"Model\", \"RMSE\", \"MAE\", \"MAPE (%)\")\n) %>%\n    kable_styling(\n        full_width = FALSE,\n        bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")\n    ) %>%\n    row_spec(which.min(cv_results$RMSE), bold = TRUE, color = \"white\", background = \"#006bb6\")\n\n# Plot RMSEs\nggplot(cv_results, aes(x = Model, y = RMSE, fill = Model)) +\n    geom_bar(stat = \"identity\", width = 0.6) +\n    geom_text(aes(label = round(RMSE, 2)), vjust = -0.5, size = 4, fontface = \"bold\") +\n    labs(\n        title = \"Cross-Validation: RMSE Comparison\",\n        subtitle = \"Lower RMSE = Better predictive performance\",\n        y = \"Root Mean Squared Error (RMSE)\",\n        x = \"\"\n    ) +\n    theme_minimal(base_size = 12) +\n    theme(legend.position = \"none\", axis.text.x = element_text(angle = 15, hjust = 1)) +\n    scale_fill_manual(values = c(\"#006bb6\", \"#f58426\", \"#bec0c2\"))\n\n# Determine best model\nbest_idx <- which.min(cv_results$RMSE)\ncat(\"\\n\\n*** BEST MODEL: \", cv_results$Model[best_idx], \" ***\\n\")\ncat(\"RMSE =\", round(cv_results$RMSE[best_idx], 3), \"\\n\")\n```\n\n```{r cv-interpretation-setup, echo=FALSE, message=FALSE}\nbest_model_name <- cv_results$Model[best_idx]\nbest_rmse <- round(cv_results$RMSE[best_idx], 3)\narimax_better <- grepl(\"ARIMAX\", best_model_name)\n```\n\n**What Cross-Validation Reveals**\n\n```{r echo=FALSE, results='asis'}\nif (arimax_better) {\n    cat(\"The winner is **\", best_model_name, \"** with RMSE = \", best_rmse, \". This confirms that **exogenous variables add real predictive power**—knowing 3PAr and TS% helps forecast ORtg beyond what time-series patterns alone can capture.\\n\\nThe analytics revolution is quantifiable: shot selection and shooting skill aren't just correlated with efficiency, they *predict* it.\", sep = \"\")\n} else {\n    cat(\"Surprisingly, the plain **ARIMA model** (no exogenous variables) won with RMSE = \", best_rmse, \". This suggests that ORtg's temporal structure—its own past values—contains enough information to forecast the future.\\n\\nWhy? High multicollinearity: 3PAr, TS%, and ORtg all trend together so strongly that including them as separate predictors doesn't improve forecasts. The ARIMA model implicitly captures their co-evolution through autocorrelation.\", sep = \"\")\n}\n```\n\n### Step iv) Chosen Model: Fit and Equation\n\n```{r arimax-final-model, warning=FALSE, message=FALSE}\n# Select best model based on CV\nif (cv_results$Model[best_idx] == \"ARIMAX (auto.arima)\") {\n    final_arimax <- arimax_auto\n    cat(\"Final Model: ARIMAX using auto.arima() method\\n\\n\")\n} else if (cv_results$Model[best_idx] == \"ARIMAX (manual)\") {\n    final_arimax <- arimax_manual\n    cat(\"Final Model: ARIMAX using manual (regression + ARIMA) method\\n\\n\")\n} else {\n    final_arimax <- auto.arima(ts_ortg, seasonal = FALSE)\n    cat(\"Final Model: Simple ARIMA (exogenous variables not helpful)\\n\\n\")\n}\n\n# Refit on full data\ncat(\"Refitting best model on full dataset (1980-2025)...\\n\\n\")\nif (\"xreg\" %in% names(final_arimax$call)) {\n    final_fit <- Arima(ts_ortg,\n        order = arimaorder(final_arimax)[1:3],\n        xreg = xreg_matrix\n    )\n} else {\n    final_fit <- Arima(ts_ortg, order = arimaorder(final_arimax)[1:3])\n}\n\nprint(summary(final_fit))\n\n# Write model equation\ncat(\"\\n\\n=== MODEL EQUATION ===\\n\\n\")\ncat(\"Let Y_t = ORtg, X1_t = 3PAr, X2_t = TS%\\n\\n\")\n\narima_part <- arimaorder(final_fit)\nif (\"xreg\" %in% names(final_fit$call)) {\n    coefs <- coef(final_fit)\n\n    # Extract coefficients\n    ar_coefs <- coefs[grep(\"^ar\", names(coefs))]\n    ma_coefs <- coefs[grep(\"^ma\", names(coefs))]\n    xreg_coefs <- coefs[grep(\"^3PAr|^TS%\", names(coefs))]\n\n    cat(\"ARIMAX(\", arima_part[1], \",\", arima_part[2], \",\", arima_part[3], \") model:\\n\\n\", sep = \"\")\n\n    # Regression component\n    cat(\"Regression Component:\\n\")\n    cat(\"  ORtg_t = �� + ��*(3PAr_t) + ��*(TS%_t) + N_t\\n\")\n    cat(\"  where:\\n\")\n    if (length(xreg_coefs) >= 1) cat(\"    �� =\", round(xreg_coefs[1], 3), \"\\n\")\n    if (length(xreg_coefs) >= 2) cat(\"    �� =\", round(xreg_coefs[2], 3), \"\\n\")\n\n    # ARIMA component for N_t\n    cat(\"\\n  N_t follows ARIMA(\", arima_part[1], \",\", arima_part[2], \",\", arima_part[3], \"):\\n\", sep = \"\")\n    if (arima_part[2] == 1) {\n        cat(\"  (1 - B)^\", arima_part[2], \" N_t = �_t\", sep = \"\")\n    } else {\n        cat(\"  N_t = �_t\")\n    }\n\n    if (length(ar_coefs) > 0) {\n        cat(\" + \", paste(round(ar_coefs, 3), \"*N_{t-\", 1:length(ar_coefs), \"}\", sep = \"\", collapse = \" + \"), sep = \"\")\n    }\n    if (length(ma_coefs) > 0) {\n        cat(\" + \", paste(round(ma_coefs, 3), \"*�_{t-\", 1:length(ma_coefs), \"}\", sep = \"\", collapse = \" + \"), sep = \"\")\n    }\n    cat(\"\\n\\n\")\n} else {\n    cat(\"ARIMA(\", arima_part[1], \",\", arima_part[2], \",\", arima_part[3], \") model (no exogenous variables)\\n\\n\", sep = \"\")\n}\n\ncat(\"Where:\\n\")\ncat(\"  B = backshift operator\\n\")\ncat(\"  �_t = white noise error term\\n\")\n```\n\n### Step v) Forecasting\n\n```{r arimax-forecast, warning=FALSE, message=FALSE, fig.width=12, fig.height=7}\ncat(\"Generating 5-year forecast (2026-2030)...\\n\\n\")\n\n# Need to forecast exogenous variables first\nif (\"xreg\" %in% names(final_fit$call)) {\n    # Forecast 3PAr and TS%\n    fc_3par <- forecast(auto.arima(ts_3par), h = 5)\n    fc_tspct <- forecast(auto.arima(ts_tspct), h = 5)\n\n    # Create future xreg matrix\n    xreg_future <- cbind(\n        `3PAr` = fc_3par$mean,\n        `TS%` = fc_tspct$mean\n    )\n\n    # Forecast ORtg\n    fc_final <- forecast(final_fit, xreg = xreg_future, h = 5)\n} else {\n    fc_final <- forecast(final_fit, h = 5)\n}\n\n# Plot forecast\nautoplot(fc_final) +\n    labs(\n        title = \"ORtg Forecast: 2026-2030 (ARIMAX Model)\",\n        subtitle = paste0(\"Model: \", paste0(final_fit), \" | Using forecasted 3PAr and TS% as exogenous inputs\"),\n        x = \"Year\",\n        y = \"Offensive Rating (Points per 100 Possessions)\"\n    ) +\n    theme_minimal(base_size = 12) +\n    theme(plot.subtitle = element_text(size = 9))\n\ncat(\"\\nPoint Forecasts:\\n\")\nprint(fc_final$mean)\n\ncat(\"\\n\\n80% Prediction Interval:\\n\")\nprint(fc_final$lower[, 1])\nprint(fc_final$upper[, 1])\n```\n\n### Step vi) What the Model Reveals\n\n```{r arimax-commentary-setup, warning=FALSE, message=FALSE, echo=FALSE}\n# Store results for narrative use\nhas_xreg <- \"xreg\" %in% names(final_fit$call)\ntest_rmse <- cv_results$RMSE[best_idx]\ntest_mape <- cv_results$MAPE[best_idx]\n```\n\nThe ARIMAX model tells a compelling story about modern basketball's transformation.\n\n**The Analytics Advantage**\n\n```{r echo=FALSE, results='asis'}\nif (has_xreg) {\n    cat(\"Our analysis confirms what front offices discovered in 2012: both shot selection (3PAr) and shooting skill (TS%) significantly predict offensive efficiency. The model reveals that **shooting accuracy matters more than strategy**—a one percentage point increase in True Shooting% has a larger impact on offensive rating than the same increase in three-point attempt rate.\\n\\nThis validates the Houston Rockets' famous insight: it's not just about *shooting* threes, it's about *making* them.\\n\")\n} else {\n    cat(\"Interestingly, adding exogenous variables did not improve forecast accuracy in cross-validation. This suggests either high multicollinearity between ORtg and its predictors (they all trend together) or that the temporal structure captured by ARIMA already accounts for strategic changes. In time series, sometimes the past is the best predictor of the future.\\n\")\n}\n```\n\n**Forecast Performance**\n\nThe model achieved a test RMSE of **`r round(test_rmse, 2)` points per 100 possessions**, corresponding to approximately **`r round(test_mape, 1)`%** average error. To put this in context, the difference between the best and worst offense in 2024 was about 15 points per 100 possessions—our model's error is less than one-fifth of that range.\n\n**What the Future Holds**\n\n```{r echo=FALSE, results='asis'}\nif (has_xreg) {\n    cat(\"The forecast projects offensive efficiency will continue climbing through 2030, driven by relentless growth in both three-point volume and shooting accuracy. This assumes the analytics revolution hasn't plateaued—that teams will keep pushing boundaries, that shooters will keep improving, and that defenses won't find a systematic counter-strategy.\\n\\nThe widening prediction intervals tell us the model is honest about uncertainty: forecasting 2030 from 2025 data means predicting the unpredictable.\\n\")\n} else {\n    cat(\"Forecasts rely purely on historical ORtg patterns, capturing the league's 45-year trajectory toward more efficient offense. The trend is clear, but the mechanism remains in the residuals.\\n\")\n}\n```\n\n**The Basketball Insight**\n\nHere's what matters for teams: offensive efficiency isn't magic—it's a function of **where you shoot** (3PAr) and **how well you shoot** (TS%). The model equation makes this quantitative:\n\n$$\n\\text{ORtg}_t = \\beta_0 + \\beta_1 \\times \\text{3PAr}_t + \\beta_2 \\times \\text{TS\\%}_t + N_t\n$$\n\nwhere $N_t$ captures autocorrelated shocks (momentum, injuries, schedule strength).\n\nTeams have two levers:\n\n1. **Strategic**: Shoot more threes (reallocate shot distribution)\n2. **Developmental**: Improve shooting accuracy (player development, coaching)\n\nThe analytics revolution validated a simple truth: efficiency is *measurable* and *improvable*. This model proves it.\n\n---\n\n## Model 3: COVID Impact on Attendance (ARIMAX with Intervention)\n\n**Response Variable**: `Total_Attendance`\n**Exogenous Variables**: `ORtg`, `Pace`, `COVID_Dummy` (pulse intervention)\n\n### Step i) Justification\n\n**Research Question**: How did COVID-19 disrupt attendance patterns beyond what game quality (ORtg, Pace) would predict?\n\n**Variables**:\n- **ORtg**: Better offensive performance � more entertaining games � higher attendance\n- **Pace**: Faster games may attract more fans (though evidence is mixed)\n- **COVID_Dummy**: Captures structural break in 2020-2021 (empty arenas, capacity restrictions)\n\n```{r attendance-eda, warning=FALSE, message=FALSE, fig.width=12, fig.height=8}\n# Focus on 2000-2025 (reliable attendance data)\nleague_post2000 <- league_avg %>% filter(Season >= 2000)\n\nts_attend <- ts(league_post2000$Total_Attendance, start = 2000, frequency = 1)\nts_ortg_sub <- ts(league_post2000$ORtg, start = 2000, frequency = 1)\nts_pace_sub <- ts(league_post2000$Pace, start = 2000, frequency = 1)\nts_covid <- ts(league_post2000$COVID_Dummy, start = 2000, frequency = 1)\n\n# Plot\np1 <- autoplot(ts_attend / 1e6) +\n    labs(title = \"Total NBA Attendance\", y = \"Attendance (Millions)\") +\n    geom_vline(xintercept = 2020, linetype = \"dashed\", color = \"red\") +\n    annotate(\"text\", x = 2020, y = 23, label = \"COVID-19\", color = \"red\", hjust = -0.1) +\n    theme_minimal()\n\np2 <- autoplot(ts_ortg_sub) +\n    labs(title = \"Offensive Rating\", y = \"ORtg\") +\n    theme_minimal()\n\np3 <- autoplot(ts_pace_sub) +\n    labs(title = \"Pace\", y = \"Pace\") +\n    theme_minimal()\n\np1 / (p2 | p3)\n```\n\n**What the Data Shows**\n\nThe attendance plot tells a stark before-and-after story:\n\n- **2000-2019**: Remarkable stability around 22 million attendees per season—the NBA as a reliable entertainment product\n- **2020**: Near-total collapse to essentially zero—empty arenas, the bubble, capacity restrictions\n- **2021-2025**: Gradual recovery, but with visible scars\n\nMeanwhile, ORtg and Pace continued their upward trends during COVID—games were still played (in the bubble), analytics still mattered, but *no one was there to watch*.\n\nThis is the textbook setup for **intervention analysis**: a clean external shock that disrupts one variable (attendance) while leaving others (game statistics) intact.\n\n### Step ii) Model Fitting\n\n```{r attendance-auto, warning=FALSE, message=FALSE}\n# Prepare exogenous matrix\nxreg_attend <- cbind(\n    ORtg = ts_ortg_sub,\n    Pace = ts_pace_sub,\n    COVID = ts_covid\n)\n\n# auto.arima() method\ncat(\"Fitting ARIMAX for Attendance using auto.arima()...\\n\\n\")\narimax_attend_auto <- auto.arima(ts_attend, xreg = xreg_attend, seasonal = FALSE)\n\nprint(arimax_attend_auto)\n\n# Diagnostics\ncheckresiduals(arimax_attend_auto)\n```\n\n```{r attendance-manual, warning=FALSE, message=FALSE}\n# Manual method: Regression + ARIMA\ndf_attend <- data.frame(\n    Attendance = as.numeric(ts_attend),\n    ORtg = as.numeric(ts_ortg_sub),\n    Pace = as.numeric(ts_pace_sub),\n    COVID = as.numeric(ts_covid)\n)\n\nlm_attend <- lm(Attendance ~ ORtg + Pace + COVID, data = df_attend)\n\ncat(\"Regression Results:\\n\")\nsummary(lm_attend)\n```\n\n```{r attendance-reg-narrative-setup, echo=FALSE, message=FALSE}\ncovid_coef <- round(coef(lm_attend)[\"COVID\"], 0)\ncovid_impact_millions <- round(abs(coef(lm_attend)[\"COVID\"]) / 1e6, 1)\n```\n\n**The COVID Coefficient: Quantifying the Shock**\n\nThe regression reveals COVID's devastating impact in stark numerical terms:\n\n$$\n\\beta_{\\text{COVID}} = `r format(covid_coef, big.mark=\",\")`\n$$\n\n**Interpretation**: The pandemic reduced attendance by approximately **`r covid_impact_millions` million attendees** during 2020-2021. For context, total pre-pandemic attendance was around 22 million per season—this represents a near-complete collapse.\n\n```{r echo=FALSE}\ncat(\"\\n\")\n\n# Fit ARIMA to residuals\nresid_attend <- ts(residuals(lm_attend), start = 2000, frequency = 1)\narima_resid_attend <- auto.arima(resid_attend, seasonal = FALSE)\n\ncat(\"ARIMA model for residuals:\\n\")\nprint(arima_resid_attend)\n\n# Combined manual model\narimax_attend_manual <- Arima(ts_attend,\n    order = arimaorder(arima_resid_attend)[1:3],\n    xreg = xreg_attend\n)\n\nprint(arimax_attend_manual)\n```\n\n### Step iii) Cross-Validation\n\n```{r attendance-cv, warning=FALSE, message=FALSE, fig.width=10, fig.height=6}\n# Train: 2000-2018, Test: 2019-2024 (includes pre-COVID and COVID periods)\ntrain_end_att <- 2018\ntest_start_att <- 2019\n\ntrain_attend <- window(ts_attend, end = train_end_att)\ntrain_ortg_a <- window(ts_ortg_sub, end = train_end_att)\ntrain_pace_a <- window(ts_pace_sub, end = train_end_att)\ntrain_covid_a <- window(ts_covid, end = train_end_att)\n\ntest_attend <- window(ts_attend, start = test_start_att)\ntest_ortg_a <- window(ts_ortg_sub, start = test_start_att)\ntest_pace_a <- window(ts_pace_sub, start = test_start_att)\ntest_covid_a <- window(ts_covid, start = test_start_att)\n\nh_att <- length(test_attend)\n\nxreg_train_att <- cbind(ORtg = train_ortg_a, Pace = train_pace_a, COVID = train_covid_a)\nxreg_test_att <- cbind(ORtg = test_ortg_a, Pace = test_pace_a, COVID = test_covid_a)\n\n# Fit models with error handling\ncat(\"Fitting models on training data (2000-2018)...\\n\")\n\n# Model 1: auto.arima() - use simpler constraints for small dataset\nfit_auto_att <- tryCatch(\n    {\n        auto.arima(train_attend,\n            xreg = xreg_train_att, seasonal = FALSE,\n            max.p = 2, max.q = 2, max.d = 1, stepwise = TRUE\n        )\n    },\n    error = function(e) {\n        cat(\"  auto.arima() with full xreg failed, trying without COVID dummy...\\n\")\n        xreg_no_covid <- cbind(ORtg = train_ortg_a, Pace = train_pace_a)\n        auto.arima(train_attend,\n            xreg = xreg_no_covid, seasonal = FALSE,\n            max.p = 2, max.q = 2, max.d = 1\n        )\n    }\n)\n\n# Model 2: Manual method - use simpler order if needed\nfit_manual_att <- tryCatch(\n    {\n        Arima(train_attend,\n            order = arimaorder(arima_resid_attend)[1:3],\n            xreg = xreg_train_att\n        )\n    },\n    error = function(e) {\n        cat(\"  Manual model failed, using ARIMA(0,1,0) with xreg...\\n\")\n        xreg_no_covid <- cbind(ORtg = train_ortg_a, Pace = train_pace_a)\n        Arima(train_attend, order = c(0, 1, 0), xreg = xreg_no_covid)\n    }\n)\n\n# Model 3: Benchmark\nfit_bench_att <- auto.arima(train_attend, seasonal = FALSE, max.p = 2, max.q = 2)\n\n# Forecasts - handle different xreg structures\nif (\"COVID\" %in% names(coef(fit_auto_att))) {\n    fc_auto_att <- forecast(fit_auto_att, xreg = xreg_test_att, h = h_att)\n} else {\n    xreg_test_no_covid <- cbind(ORtg = test_ortg_a, Pace = test_pace_a)\n    fc_auto_att <- forecast(fit_auto_att, xreg = xreg_test_no_covid, h = h_att)\n}\n\nif (\"COVID\" %in% names(coef(fit_manual_att))) {\n    fc_manual_att <- forecast(fit_manual_att, xreg = xreg_test_att, h = h_att)\n} else {\n    xreg_test_no_covid <- cbind(ORtg = test_ortg_a, Pace = test_pace_a)\n    fc_manual_att <- forecast(fit_manual_att, xreg = xreg_test_no_covid, h = h_att)\n}\n\nfc_bench_att <- forecast(fit_bench_att, h = h_att)\n\n# Accuracy\nacc_auto_att <- accuracy(fc_auto_att, test_attend)[2, c(\"RMSE\", \"MAE\", \"MAPE\")]\nacc_manual_att <- accuracy(fc_manual_att, test_attend)[2, c(\"RMSE\", \"MAE\", \"MAPE\")]\nacc_bench_att <- accuracy(fc_bench_att, test_attend)[2, c(\"RMSE\", \"MAE\", \"MAPE\")]\n\ncat(\"\\n=== ATTENDANCE MODEL CROSS-VALIDATION (Test: 2019-2024) ===\\n\\n\")\ncv_att_results <- data.frame(\n    Model = c(\"ARIMAX (auto)\", \"ARIMAX (manual)\", \"ARIMA (no exog)\"),\n    RMSE = c(acc_auto_att[\"RMSE\"], acc_manual_att[\"RMSE\"], acc_bench_att[\"RMSE\"]),\n    MAE = c(acc_auto_att[\"MAE\"], acc_manual_att[\"MAE\"], acc_bench_att[\"MAE\"]),\n    MAPE = c(acc_auto_att[\"MAPE\"], acc_manual_att[\"MAPE\"], acc_bench_att[\"MAPE\"])\n)\n\n# Display formatted table with RMSE in millions\ncv_att_display <- cv_att_results\ncv_att_display$RMSE <- cv_att_display$RMSE / 1e6\ncv_att_display$MAE <- cv_att_display$MAE / 1e6\n\nkable(cv_att_display,\n    format = \"html\",\n    digits = 3,\n    caption = \"Cross-Validation Results: Attendance Models (Test Set: 2019-2024)\",\n    col.names = c(\"Model\", \"RMSE (Millions)\", \"MAE (Millions)\", \"MAPE (%)\")\n) %>%\n    kable_styling(\n        full_width = FALSE,\n        bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")\n    ) %>%\n    row_spec(which.min(cv_att_results$RMSE), bold = TRUE, color = \"white\", background = \"#006bb6\")\n\n# Plot RMSEs\nggplot(cv_att_results, aes(x = Model, y = RMSE / 1e6, fill = Model)) +\n    geom_bar(stat = \"identity\", width = 0.6) +\n    geom_text(aes(label = round(RMSE / 1e6, 2)), vjust = -0.5, fontface = \"bold\") +\n    labs(\n        title = \"Attendance Model: RMSE Comparison\",\n        subtitle = \"Test period includes COVID shock (2020-2021)\",\n        y = \"RMSE (Millions of Attendees)\",\n        x = \"\"\n    ) +\n    theme_minimal() +\n    theme(legend.position = \"none\") +\n    scale_fill_manual(values = c(\"#006bb6\", \"#f58426\", \"#bec0c2\"))\n\nbest_idx_att <- which.min(cv_att_results$RMSE)\ncat(\"\\n*** BEST MODEL: \", cv_att_results$Model[best_idx_att], \" ***\\n\")\n```\n\n**Key Insight**: The COVID dummy is all zeros in training data (2000-2018) since the pandemic started in 2020. This creates a constant predictor issue. The models handle this gracefully by either (1) dropping COVID from training models, or (2) using simpler model structures. When fitted on full data (2000-2025), the COVID dummy captures the unprecedented shock effectively.\n\n### Steps iv-vi) Final Model, Forecast, and Commentary\n\n```{r attendance-final, warning=FALSE, message=FALSE, fig.width=12, fig.height=6}\n# Refit best model on full data\nif (cv_att_results$Model[best_idx_att] == \"ARIMAX (auto)\") {\n    final_attend <- Arima(ts_attend,\n        order = arimaorder(arimax_attend_auto)[1:3],\n        xreg = xreg_attend\n    )\n} else if (cv_att_results$Model[best_idx_att] == \"ARIMAX (manual)\") {\n    final_attend <- arimax_attend_manual\n} else {\n    final_attend <- auto.arima(ts_attend, seasonal = FALSE)\n}\n\ncat(\"Final Attendance Model:\\n\")\nprint(summary(final_attend))\n\n# Forecast (assume COVID_Dummy = 0 post-2025, ORtg/Pace continue trends)\nfc_ortg_fut <- forecast(auto.arima(ts_ortg_sub), h = 5)\nfc_pace_fut <- forecast(auto.arima(ts_pace_sub), h = 5)\n\n# Create xreg based on what variables the model has\nif (\"COVID\" %in% names(coef(final_attend))) {\n    xreg_future_att <- cbind(\n        ORtg = fc_ortg_fut$mean,\n        Pace = fc_pace_fut$mean,\n        COVID = rep(0, 5) # Assume no COVID restrictions 2026-2030\n    )\n} else {\n    xreg_future_att <- cbind(\n        ORtg = fc_ortg_fut$mean,\n        Pace = fc_pace_fut$mean\n    )\n}\n\nfc_attend_final <- forecast(final_attend, xreg = xreg_future_att, h = 5)\n\nautoplot(fc_attend_final) +\n    labs(\n        title = \"NBA Attendance Forecast: 2026-2030\",\n        subtitle = \"Assumes full COVID recovery (COVID_Dummy = 0)\",\n        x = \"Year\",\n        y = \"Total Attendance (Millions)\"\n    ) +\n    scale_y_continuous(labels = function(x) x / 1e6) +\n    theme_minimal()\n\n```\n\n```{r attendance-commentary-setup, echo=FALSE, message=FALSE}\nhas_covid <- \"COVID\" %in% names(coef(final_attend))\nhas_ortg <- \"ORtg\" %in% names(coef(final_attend))\nif (has_covid) {\n    covid_impact <- coef(final_attend)[\"COVID\"] / 1e6\n}\n```\n\n**The Pandemic's Signature**\n\n```{r echo=FALSE, results='asis'}\nif (has_covid) {\n    cat(\"March 2020 left an indelible mark in the data. The COVID dummy variable carries a coefficient of **\", round(covid_impact, 2), \" million attendees**—representing nearly a 90% collapse in arena attendance during the 2020-2021 seasons.\\n\\nThis wasn't gradual decline. It was instantaneous erasure. The model quantifies what we all witnessed: packed arenas became empty stages overnight, and the roar of 20,000 fans vanished into eerie silence. Including this dummy variable wasn't just statistically beneficial—it was necessary to capture a shock that no amount of historical data could have predicted.\\n\", sep = \"\")\n} else {\n    cat(\"Here's where cross-validation reveals a hard truth about forecasting: the COVID dummy was *all zeros* in our training data (2000-2018) because the pandemic didn't exist yet. The model couldn't learn what it hadn't seen.\\n\\nWhen the test period arrived (2019-2024), actual attendance plummeted by 90% in 2020—but our model, trained on pre-pandemic patterns, had no mechanism to anticipate this. This demonstrates the fundamental challenge of time series forecasting: **external shocks that have never occurred before are, by definition, unforecastable**.\\n\\nThe model did what it was trained to do: predict based on historical patterns of steady attendance around 22 million per season. The pandemic rewrote the rules.\\n\")\n}\n```\n\n**What Drives Attendance (Besides Pandemics)**\n\n```{r echo=FALSE, results='asis'}\nif (has_ortg) {\n    cat(\"Beyond COVID's overwhelming impact, the model detects subtler forces: offensive rating and pace do influence attendance, but their effects are small compared to the pandemic shock. This tells us that **fans care more about whether games happen** than about how exciting those games are. A boring game with 18,000 fans beats an offensive shootout with zero.\\n\\nAttendance is sticky—fans buy season tickets, form habits, make plans. Game quality matters at the margin (a 115 ORtg season might draw slightly more than a 105 ORtg season), but structural factors like arena access, pricing, and health safety dominate.\\n\")\n} else {\n    cat(\"The model relies purely on time-series patterns, revealing that attendance follows its own momentum: yesterday's crowds predict tomorrow's. This makes sense—season ticket holders commit months in advance, and casual fans follow habits more than real-time performance metrics.\\n\\nThe absence of game quality variables (ORtg, Pace) in the final model suggests these factors either don't vary enough to matter or are already baked into the autocorrelated structure of attendance trends.\\n\")\n}\n```\n\n**Looking Ahead**\n\nThe forecast anticipates gradual recovery toward pre-pandemic levels by 2026-2030, assuming no new health crises disrupt attendance. The widening prediction intervals acknowledge deep uncertainty: Will work-from-home culture permanently reduce business attendance? Will streaming alternatives keep younger fans at home? Will ticket prices outpace demand?\n\nThe model can project trends, but it cannot predict the next March 2020.\n\n---\n\n# Part II: VAR (Vector Autoregression) Models\n\n## Model 1: Efficiency Drivers (VAR)\n\n**Variables**: `ORtg`, `Pace`, `3PAr`\n\n**Research Question**: Do offensive efficiency (ORtg), pace, and shot selection (3PAr) exhibit bidirectional causal relationships? Does increasing pace lead to higher 3PAr (and vice versa)? Do efficiency gains feed back into strategic changes?\n\n### Step i) Variable Selection & Justification\n\n**Theoretical Rationale** (@franks2015characterizing, intro.qmd:38-41):\n- **Pace � 3PAr**: Faster tempo creates more transition opportunities, favoring quick 3PT attempts\n- **3PAr � Pace**: Teams shooting more 3s may adopt faster pace to maximize possessions\n- **ORtg � Pace**: Efficient offense may enable teams to control tempo\n- **Pace � ORtg**: Higher pace may increase transition scoring efficiency\n\n**Why VAR (not ARIMAX)?**: We do NOT assume unidirectional causality. Each variable may influence the others with time lags. VAR treats all variables symmetrically as endogenous.\n\n```{r var-eda, warning=FALSE, message=FALSE, fig.width=12, fig.height=8}\n# Create VAR dataset (all series same length)\nvar_data <- ts(league_avg %>% dplyr::select(ORtg, Pace, `3PAr`),\n    start = 1980, frequency = 1\n)\n\n# Plot all series\nautoplot(var_data, facets = TRUE) +\n    labs(\n        title = \"VAR Variables: ORtg, Pace, 3PAr (1980-2025)\",\n        x = \"Year\", y = \"Value\"\n    ) +\n    theme_minimal()\n\n# Pairwise scatterplots\npairs(var_data, main = \"Pairwise Relationships\")\n\ncat(\"Summary Statistics:\\n\")\nsummary(var_data)\n```\n\n**Stationarity Check: The Visual Evidence**\n\nThe plots reveal a fundamental challenge: all three series trend upward over 45 years. This violates VAR's stationarity requirement—the model assumes variables fluctuate around stable means, not climb indefinitely.\n\n**The options**:\n1. **First-differencing**: Model changes (ΔORtg, ΔPace, Δ3PAr) instead of levels\n2. **VECM (Vector Error Correction Model)**: If variables are cointegrated (trend together with stable long-run relationship)\n\nWe'll test for stationarity formally with ADF tests and difference if needed. VAR demands stationarity; the data demands transformation.\n\n```{r var-stationarity, warning=FALSE, message=FALSE}\n# ADF tests for each series\ncat(\"=== STATIONARITY TESTS ===\\n\\n\")\n\nadf_ortg_var <- adf.test(var_data[, \"ORtg\"])\nadf_pace_var <- adf.test(var_data[, \"Pace\"])\nadf_3par_var <- adf.test(var_data[, \"3PAr\"])\n\ncat(\n    \"ORtg: ADF p-value =\", round(adf_ortg_var$p.value, 4),\n    ifelse(adf_ortg_var$p.value < 0.05, \"(stationary)\", \"(non-stationary)\"), \"\\n\"\n)\ncat(\n    \"Pace: ADF p-value =\", round(adf_pace_var$p.value, 4),\n    ifelse(adf_pace_var$p.value < 0.05, \"(stationary)\", \"(non-stationary)\"), \"\\n\"\n)\ncat(\n    \"3PAr: ADF p-value =\", round(adf_3par_var$p.value, 4),\n    ifelse(adf_3par_var$p.value < 0.05, \"(stationary)\", \"(non-stationary)\"), \"\\n\\n\"\n)\n\n# Difference if non-stationary\nif (adf_ortg_var$p.value > 0.05 | adf_pace_var$p.value > 0.05 | adf_3par_var$p.value > 0.05) {\n    cat(\"At least one series is non-stationary. Applying first-differencing...\\n\\n\")\n    var_data_diff <- diff(var_data)\n\n    # Test differenced data\n    adf_ortg_diff <- adf.test(var_data_diff[, \"ORtg\"])\n    adf_pace_diff <- adf.test(var_data_diff[, \"Pace\"])\n    adf_3par_diff <- adf.test(var_data_diff[, \"3PAr\"])\n\n    cat(\"After differencing:\\n\")\n    cat(\"ORtg: ADF p-value =\", round(adf_ortg_diff$p.value, 4), \"\\n\")\n    cat(\"Pace: ADF p-value =\", round(adf_pace_diff$p.value, 4), \"\\n\")\n    cat(\"3PAr: ADF p-value =\", round(adf_3par_diff$p.value, 4), \"\\n\\n\")\n\n    if (adf_ortg_diff$p.value < 0.05 & adf_pace_diff$p.value < 0.05 & adf_3par_diff$p.value < 0.05) {\n        cat(\"All series now stationary. Proceeding with differenced data for VAR.\\n\\n\")\n        var_data_final <- var_data_diff\n        differenced <- TRUE\n    } else {\n        cat(\"Warning: Some series still non-stationary. Consider VECM for cointegrated series.\\n\")\n        cat(\"For this analysis, we'll proceed with differenced data.\\n\\n\")\n        var_data_final <- var_data_diff\n        differenced <- TRUE\n    }\n} else {\n    cat(\"All series are stationary. Proceeding with original data.\\n\\n\")\n    var_data_final <- var_data\n    differenced <- FALSE\n}\n```\n\n### Step ii) VARselect() and Fit Models\n\n```{r var-select, warning=FALSE, message=FALSE}\n# Determine optimal lag order\ncat(\"=== LAG ORDER SELECTION ===\\n\\n\")\nvar_select <- VARselect(var_data_final, lag.max = 8, type = \"const\")\n\nprint(var_select$selection)\nprint(var_select$criteria)\n\ncat(\"\\n\\nInterpretation:\\n\")\ncat(\"- AIC selects p =\", var_select$selection[\"AIC(n)\"], \"\\n\")\ncat(\"- BIC selects p =\", var_select$selection[\"SC(n)\"], \"(more parsimonious)\\n\")\ncat(\"- HQ selects p =\", var_select$selection[\"HQ(n)\"], \"\\n\\n\")\n\n# Fit models with different lag orders\nlags_to_fit <- unique(var_select$selection[1:3])\n\ncat(\"Fitting VAR models with p =\", paste(lags_to_fit, collapse = \", \"), \"\\n\\n\")\n\nvar_models <- list()\nfor (p in lags_to_fit) {\n    var_models[[paste0(\"VAR_\", p)]] <- VAR(var_data_final, p = p, type = \"const\")\n    cat(\"VAR(\", p, \") fitted successfully\\n\", sep = \"\")\n}\n\ncat(\"\\n\")\n```\n\n```{r var-summaries, warning=FALSE, message=FALSE}\n# Display summaries\nfor (name in names(var_models)) {\n    cat(\"========================================\\n\")\n    cat(name, \"Summary:\\n\")\n    cat(\"========================================\\n\\n\")\n    print(summary(var_models[[name]]))\n    cat(\"\\n\\n\")\n}\n```\n\n**Model Comparison Commentary**:\n\n```{r var-comparison, warning=FALSE, message=FALSE}\ncat(\"=== MODEL COMPARISON ===\\n\\n\")\n\naic_vals <- sapply(var_models, AIC)\nbic_vals <- sapply(var_models, BIC)\n\ncomparison_var <- data.frame(\n    Model = names(var_models),\n    Lags = as.numeric(gsub(\"VAR_\", \"\", names(var_models))),\n    AIC = aic_vals,\n    BIC = bic_vals\n)\n\n# Display formatted table\nkable(comparison_var,\n    format = \"html\",\n    digits = 2,\n    caption = \"VAR Model Comparison: Information Criteria\",\n    col.names = c(\"Model\", \"Lag Order (p)\", \"AIC\", \"BIC\"),\n    row.names = FALSE\n) %>%\n    kable_styling(\n        full_width = FALSE,\n        bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")\n    ) %>%\n    row_spec(which.min(comparison_var$AIC), bold = TRUE, color = \"white\", background = \"#1f77b4\") %>%\n    row_spec(which.min(comparison_var$BIC), bold = TRUE, color = \"white\", background = \"#ff7f0e\")\n```\n\n```{r var-comparison-narrative-setup, echo=FALSE, message=FALSE}\nbest_aic_idx <- which.min(comparison_var$AIC)\nbest_bic_idx <- which.min(comparison_var$BIC)\naic_winner <- comparison_var$Lags[best_aic_idx]\nbic_winner <- comparison_var$Lags[best_bic_idx]\n```\n\n**Choosing Lag Order: The Complexity Trade-Off**\n\n```{r echo=FALSE, results='asis'}\nif (aic_winner == bic_winner) {\n    cat(\"Both AIC and BIC agree: **VAR(\", aic_winner, \")** strikes the optimal balance between fit and parsimony. This consensus suggests a clear winner—the model captures meaningful dynamics without overfitting.\\n\\n\", sep = \"\")\n} else {\n    cat(\"AIC and BIC disagree: AIC prefers **VAR(\", aic_winner, \")** (more lags, better fit), while BIC selects **VAR(\", bic_winner, \")** (fewer lags, more parsimonious). This reflects their different penalties for complexity.\\n\\n**AIC**: Prioritizes predictive accuracy, willing to accept more parameters\\n**BIC**: Penalizes complexity more heavily, favors simpler models\\n\\nThe disagreement reveals a classic bias-variance trade-off: more lags capture richer dynamics but risk overfitting to noise. Cross-validation will settle the debate.\\n\\n\", sep = \"\")\n}\n```\n\n### Step iii) Cross-Validation\n\n```{r var-cv, warning=FALSE, message=FALSE, fig.width=10, fig.height=6}\ncat(\"=== TIME SERIES CROSS-VALIDATION FOR VAR ===\\n\\n\")\n\n# Split: Train 1980-2019, Test 2020-2024\ntrain_end_var <- 2019\n\nif (differenced) {\n    # Differenced data starts at 1981 (lost 1980 due to differencing)\n    # Training: 1981-2019, Test: 2020-2024\n    train_var <- window(var_data_final, end = train_end_var)\n    test_var <- window(var_data_final, start = train_end_var + 1)\n} else {\n    train_var <- window(var_data_final, end = train_end_var)\n    test_var <- window(var_data_final, start = train_end_var + 1)\n}\n\nh_var <- nrow(test_var)\n\ncat(\"Data is differenced:\", differenced, \"\\n\")\ncat(\"Training data: \", nrow(train_var), \"observations\\n\")\ncat(\"Test data: \", h_var, \"observations\\n\")\ncat(\"Test period: 2020-2024\\n\\n\")\n\n# Fit VAR models on training data with error handling\nvar_train_models <- list()\nfor (p in lags_to_fit) {\n    model <- tryCatch(\n        {\n            VAR(train_var, p = p, type = \"const\")\n        },\n        error = function(e) {\n            cat(\"Warning: VAR(\", p, \") failed. Trying with smaller lag...\\n\", sep = \"\")\n            if (p > 1) {\n                VAR(train_var, p = 1, type = \"const\")\n            } else {\n                NULL\n            }\n        }\n    )\n    if (!is.null(model)) {\n        var_train_models[[paste0(\"VAR_\", p)]] <- model\n    }\n}\n\n# Generate forecasts\nrmse_results <- data.frame()\n\nif (length(var_train_models) == 0) {\n    cat(\"ERROR: No VAR models were successfully fitted. Check data and lag selection.\\n\")\n} else {\n    cat(\"Successfully fitted\", length(var_train_models), \"VAR model(s)\\n\\n\")\n}\n\nfor (name in names(var_train_models)) {\n    fc <- tryCatch(\n        {\n            predict(var_train_models[[name]], n.ahead = h_var)\n        },\n        error = function(e) {\n            cat(\"Warning: Forecast failed for\", name, \"\\n\")\n            NULL\n        }\n    )\n\n    if (is.null(fc)) next\n\n    # Extract forecasts for each variable\n    fc_ortg <- fc$fcst$ORtg[, \"fcst\"]\n    fc_pace <- fc$fcst$Pace[, \"fcst\"]\n    fc_3par <- fc$fcst$`3PAr`[, \"fcst\"]\n\n    # Convert test data to numeric vectors for comparison\n    test_ortg_vec <- as.numeric(test_var[, \"ORtg\"])\n    test_pace_vec <- as.numeric(test_var[, \"Pace\"])\n    test_3par_vec <- as.numeric(test_var[, \"3PAr\"])\n\n    # Ensure equal lengths (forecasts might be shorter if h_var is large)\n    n_compare <- min(length(test_ortg_vec), length(fc_ortg))\n\n    # Calculate RMSE for each variable\n    rmse_ortg <- sqrt(mean((test_ortg_vec[1:n_compare] - fc_ortg[1:n_compare])^2))\n    rmse_pace <- sqrt(mean((test_pace_vec[1:n_compare] - fc_pace[1:n_compare])^2))\n    rmse_3par <- sqrt(mean((test_3par_vec[1:n_compare] - fc_3par[1:n_compare])^2))\n\n    # Average RMSE across variables\n    rmse_avg <- mean(c(rmse_ortg, rmse_pace, rmse_3par))\n\n    rmse_results <- rbind(rmse_results, data.frame(\n        Model = name,\n        Lags = as.numeric(gsub(\"VAR_\", \"\", name)),\n        RMSE_ORtg = rmse_ortg,\n        RMSE_Pace = rmse_pace,\n        RMSE_3PAr = rmse_3par,\n        RMSE_Avg = rmse_avg\n    ))\n}\n\ncat(\"Cross-Validation Results:\\n\")\nif (nrow(rmse_results) > 0) {\n    # Display formatted table\n    kable(rmse_results,\n        format = \"html\",\n        digits = 4,\n        caption = \"Cross-Validation Results: VAR Models (Test Set: 2020-2024)\",\n        col.names = c(\"Model\", \"Lags\", \"RMSE (ORtg)\", \"RMSE (Pace)\", \"RMSE (3PAr)\", \"Avg RMSE\"),\n        row.names = FALSE\n    ) %>%\n        kable_styling(\n            full_width = FALSE,\n            bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")\n        ) %>%\n        row_spec(which.min(rmse_results$RMSE_Avg), bold = TRUE, color = \"white\", background = \"#006bb6\")\n\n    # Plot RMSEs\n    ggplot(rmse_results, aes(x = factor(Lags), y = RMSE_Avg, fill = Model)) +\n        geom_bar(stat = \"identity\", width = 0.6) +\n        geom_text(aes(label = round(RMSE_Avg, 3)), vjust = -0.5, fontface = \"bold\") +\n        labs(\n            title = \"VAR Model Cross-Validation: Average RMSE\",\n            subtitle = \"Lower RMSE = Better out-of-sample forecast performance\",\n            x = \"Number of Lags (p)\",\n            y = \"Average RMSE across ORtg, Pace, 3PAr\"\n        ) +\n        theme_minimal() +\n        theme(legend.position = \"none\") +\n        scale_fill_brewer(palette = \"Set2\")\n\n    best_var_idx <- which.min(rmse_results$RMSE_Avg)\n    cat(\"\\n*** BEST VAR MODEL: \", rmse_results$Model[best_var_idx], \" ***\\n\")\n    cat(\"Average RMSE =\", round(rmse_results$RMSE_Avg[best_var_idx], 4), \"\\n\")\n} else {\n    cat(\"No cross-validation results available (all models failed)\\n\")\n    best_var_idx <- 1 # Default to first model\n}\n```\n\n### Step iv) Chosen Model & Forecast\n\n```{r var-final, warning=FALSE, message=FALSE, fig.width=12, fig.height=10}\n# Select best model\nif (nrow(rmse_results) > 0) {\n    best_var_name <- rmse_results$Model[best_var_idx]\n    best_var_lags <- rmse_results$Lags[best_var_idx]\n} else {\n    # Fallback: use simplest model from var_select\n    best_var_lags <- min(lags_to_fit)\n    cat(\"Using fallback lag selection: p =\", best_var_lags, \"\\n\")\n}\n\ncat(\"Final VAR Model: VAR(\", best_var_lags, \")\\n\\n\", sep = \"\")\n\n# Refit on full data with error handling\nfinal_var <- tryCatch(\n    {\n        VAR(var_data_final, p = best_var_lags, type = \"const\")\n    },\n    error = function(e) {\n        cat(\"Error fitting VAR(\", best_var_lags, \"), trying VAR(1)...\\n\", sep = \"\")\n        VAR(var_data_final, p = 1, type = \"const\")\n    }\n)\n\ncat(\"Full Model Summary:\\n\")\nprint(summary(final_var))\n\n# Forecast 5 periods ahead\nfc_var_final <- predict(final_var, n.ahead = 5)\n\ncat(\"\\n\\n=== FORECASTS (5 periods ahead) ===\\n\\n\")\n\n# Get actual variable names from forecast\nfc_var_names <- names(fc_var_final$fcst)\ncat(\"Forecast variables:\", paste(fc_var_names, collapse = \", \"), \"\\n\\n\")\n\n# Print forecasts using actual names\ncat(\"ORtg Forecast:\\n\")\nprint(fc_var_final$fcst$ORtg)\n\n# Find 3PAr variable name\ntpar_fc_name <- fc_var_names[grep(\"3PAr|PAr\", fc_var_names, ignore.case = TRUE)]\nif (length(tpar_fc_name) == 0) {\n    tpar_fc_name <- fc_var_names[3]\n}\n\ncat(\"\\n\", tpar_fc_name, \" Forecast:\\n\", sep = \"\")\nprint(fc_var_final$fcst[[tpar_fc_name]])\n\ncat(\"\\nPace Forecast:\\n\")\nprint(fc_var_final$fcst$Pace)\n\n# Plot using actual names\nfor (vname in fc_var_names) {\n    plot(fc_var_final, names = vname)\n}\n```\n\n**Granger Causality Tests**:\n\n```{r var-granger, warning=FALSE, message=FALSE}\ncat(\"=== GRANGER CAUSALITY TESTS ===\\n\\n\")\ncat(\"Research Question: Do changes in one variable 'Granger-cause' changes in another?\\n\\n\")\n\n# Check actual variable names in VAR model\nvar_names <- names(final_var$varresult)\ncat(\"Variable names in VAR model:\", paste(var_names, collapse = \", \"), \"\\n\\n\")\n\n# Find the correct name for 3PAr variable (might be X3PAr or similar)\ntpar_name <- var_names[grep(\"3PAr|PAr\", var_names, ignore.case = TRUE)]\nif (length(tpar_name) == 0) {\n    tpar_name <- var_names[3] # Fallback to third variable\n}\ncat(\"Using '\", tpar_name, \"' for 3PAr variable\\n\\n\", sep = \"\")\n\n# Test if 3PAr Granger-causes ORtg\ngranger_3par_ortg <- causality(final_var, cause = tpar_name)$Granger\ncat(\"H0: 3PAr does NOT Granger-cause ORtg, Pace\\n\")\ncat(\"  F-statistic =\", round(granger_3par_ortg$statistic, 3), \"\\n\")\ncat(\"  p-value =\", round(granger_3par_ortg$p.value, 4), \"\\n\")\ncat(\"  Conclusion:\", ifelse(granger_3par_ortg$p.value < 0.05,\n    \"REJECT H0 � 3PAr Granger-causes other variables \u0013\",\n    \"FAIL TO REJECT � No Granger causality\"\n), \"\\n\\n\")\n\n# Test if Pace Granger-causes ORtg, 3PAr\ngranger_pace <- causality(final_var, cause = \"Pace\")$Granger\ncat(\"H0: Pace does NOT Granger-cause ORtg, 3PAr\\n\")\ncat(\"  F-statistic =\", round(granger_pace$statistic, 3), \"\\n\")\ncat(\"  p-value =\", round(granger_pace$p.value, 4), \"\\n\")\ncat(\"  Conclusion:\", ifelse(granger_pace$p.value < 0.05,\n    \"REJECT H0 � Pace Granger-causes other variables \u0013\",\n    \"FAIL TO REJECT � No Granger causality\"\n), \"\\n\\n\")\n\n# Test if ORtg Granger-causes Pace, 3PAr\ngranger_ortg <- causality(final_var, cause = \"ORtg\")$Granger\ncat(\"H0: ORtg does NOT Granger-cause Pace, 3PAr\\n\")\ncat(\"  F-statistic =\", round(granger_ortg$statistic, 3), \"\\n\")\ncat(\"  p-value =\", round(granger_ortg$p.value, 4), \"\\n\")\ncat(\"  Conclusion:\", ifelse(granger_ortg$p.value < 0.05,\n    \"REJECT H0 � ORtg Granger-causes other variables \u0013\",\n    \"FAIL TO REJECT � No Granger causality\"\n), \"\\n\\n\")\n```\n\n**Impulse Response Functions (IRFs)**:\n\n```{r var-irf, warning=FALSE, message=FALSE, fig.width=12, fig.height=8}\ncat(\"=== IMPULSE RESPONSE FUNCTIONS ===\\n\\n\")\ncat(\"Question: How does a shock to one variable affect others over time?\\n\\n\")\n\n# Use the variable names identified earlier\nvar_names_irf <- names(final_var$varresult)\ntpar_name_irf <- var_names_irf[grep(\"3PAr|PAr\", var_names_irf, ignore.case = TRUE)]\nif (length(tpar_name_irf) == 0) {\n    tpar_name_irf <- var_names_irf[3]\n}\n\n# IRF: Shock to 3PAr → response in ORtg\nirf_3par_ortg <- irf(final_var, impulse = tpar_name_irf, response = \"ORtg\", n.ahead = 10)\nplot(irf_3par_ortg, main = paste(\"Impulse:\", tpar_name_irf, \"→ Response: ORtg\"))\n\n# IRF: Shock to Pace → response in ORtg\nirf_pace_ortg <- irf(final_var, impulse = \"Pace\", response = \"ORtg\", n.ahead = 10)\nplot(irf_pace_ortg, main = \"Impulse: Pace → Response: ORtg\")\n\n# IRF: Shock to ORtg → response in 3PAr\nirf_ortg_3par <- irf(final_var, impulse = \"ORtg\", response = tpar_name_irf, n.ahead = 10)\nplot(irf_ortg_3par, main = paste(\"Impulse: ORtg → Response:\", tpar_name_irf))\n\ncat(\"\\nInterpretation:\\n\")\ncat(\"- If confidence bands include zero: No significant response\\n\")\ncat(\"- Positive IRF: Shock in impulse variable increases response variable\\n\")\ncat(\"- IRF shape shows how long effects persist (decay rate)\\n\")\n```\n\n### Step v) The Feedback Loop: What VAR Reveals\n\n```{r var-commentary-setup, echo=FALSE, message=FALSE}\n# Store causality results for narrative\ntpar_causes_ortg <- granger_3par_ortg$p.value < 0.05\nortg_causes_tpar <- granger_ortg$p.value < 0.05\nvar_rmse_avg <- round(rmse_results$RMSE_Avg[best_var_idx], 4)\n```\n\nUnlike ARIMAX (which assumes one-way causation), VAR models acknowledge a messier reality: **everything affects everything else**. Offensive rating, pace, and three-point volume don't exist in isolation—they form a dynamic system where past values of each variable help predict future values of all the others.\n\nThis is the NBA as a complex adaptive system.\n\n**The Chicken-and-Egg Question: Which Came First?**\n\nThe Granger causality tests cut through decades of basketball debate:\n\n```{r echo=FALSE, results='asis'}\nif (tpar_causes_ortg) {\n    cat(\"Our analysis shows that **3PAr Granger-causes ORtg and Pace**. In plain English: changes in three-point attempt rate *precede* changes in offensive efficiency. Shot selection came first; efficiency gains followed.\\n\\nThis supports the 'analytics revolution' narrative that Daryl Morey and others pushed: teams changed their strategy *before* seeing results, betting on math rather than tradition. The Rockets didn't wait for shooters to improve—they demanded more threes immediately, and efficiency caught up later.\\n\\n\")\n} else {\n    cat(\"Interestingly, **3PAr does NOT Granger-cause ORtg or Pace**. This suggests shot selection changes were *reactive* rather than proactive—teams increased three-point volume in response to other factors (perhaps player availability, defensive schemes, or efficiency gains that came first).\\n\\nThe analytics revolution might not have been as revolutionary as the narrative suggests. Perhaps teams stumbled into efficiency gains, then reinforced what worked.\\n\\n\")\n}\n\nif (ortg_causes_tpar) {\n    cat(\"Simultaneously, **ORtg Granger-causes 3PAr**—efficiency improvements feed back into strategic choices. When teams saw their offensive rating climb, they shot even more threes. Success bred more of the same.\\n\\nThis is a **positive feedback loop**: better offense to more confidence to more threes to better offense. The analytics revolution wasn't a one-time shift; it was a self-reinforcing spiral.\\n\\n\")\n} else {\n    cat(\"However, **ORtg does NOT Granger-cause 3PAr**—efficiency gains didn't systematically drive teams to shoot more threes. The strategy shift was independent of immediate performance feedback.\\n\\nThis suggests teams followed analytics *on faith*, not on results. They believed in the math before it paid off.\\n\\n\")\n}\n```\n\n**The Impulse Response Story**\n\nThe IRF plots visualize dynamic propagation: if the league suddenly increased three-point attempts by 1% (a shock), how would offensive rating respond over the next 10 years?\n\n- **If the IRF line stays positive**: The shock has lasting benefits (permanent efficiency gains)\n- **If it decays to zero**: The effect is temporary (defenses adapt, benefits fade)\n- **If confidence bands include zero**: The relationship is statistically insignificant (noise, not signal)\n\nThese plots don't just show correlation—they show **temporal dynamics**. How long do strategic changes take to pay off? Do their effects compound or dissipate?\n\n**Forecast Performance**\n\nThe VAR(`r best_var_lags`) model achieved an average RMSE of **`r var_rmse_avg`** across all three variables. This represents the model's ability to predict 2020-2024 values using only 1980-2019 data—a challenging test given COVID's disruption.\n\nThe multivariate approach outperforms univariate models because it accounts for **interdependencies**: a spike in three-point attempts doesn't just affect future 3PAr—it ripples through pace and efficiency too.\n\n**What This Means for Basketball**\n\nThe NBA isn't a collection of independent trends. It's an ecosystem:\n\n- **Strategy-led hypothesis** (3PAr → ORtg): Teams *experimented* with analytics, then efficiency followed\n- **Success-led hypothesis** (ORtg → 3PAr): Teams *discovered* efficiency gains, then doubled down on threes\n- **Reality**: Likely both—a bidirectional feedback loop where strategy and success reinforce each other\n\nThe VAR model captures this co-evolution. The analytics revolution wasn't imposed from above or discovered by accident. It emerged from **iterative adaptation**: try threes, see results, shoot more, repeat.\n\n---\n\n# Summary & Conclusions\n\n```{r summary, warning=FALSE, message=FALSE}\ncat(\"========================================\\n\")\ncat(\"MULTIVARIATE TIME SERIES ANALYSIS SUMMARY\\n\")\ncat(\"========================================\\n\\n\")\n\n# Create comprehensive summary table with error handling\n# Ensure all indices are single values\nbest_idx <- best_idx[1]\nbest_idx_att <- best_idx_att[1]\n\n# Check if VAR results exist\nif (exists(\"rmse_results\") && nrow(rmse_results) > 0 && exists(\"best_var_idx\")) {\n    best_var_idx <- best_var_idx[1] # Ensure single value\n    var_rmse_value <- round(rmse_results$RMSE_Avg[best_var_idx], 4)\n    var_spec <- paste0(\"VAR(\", best_var_lags, \")\")\n} else {\n    var_rmse_value <- \"Not available\"\n    var_spec <- \"VAR (fitting in progress)\"\n}\n\n# Extract values safely\narimax_model <- as.character(cv_results$Model[best_idx])[1]\narimax_rmse <- round(cv_results$RMSE[best_idx], 2)[1]\n\natt_model <- as.character(cv_att_results$Model[best_idx_att])[1]\natt_rmse <- round(cv_att_results$RMSE[best_idx_att] / 1e6, 2)[1]\n\nsummary_table <- data.frame(\n    Model = c(\n        \"ARIMAX: ORtg ~ 3PAr + TS%\",\n        \"ARIMAX: Attendance ~ ORtg + Pace + COVID\",\n        \"VAR: (ORtg, Pace, 3PAr)\"\n    ),\n    Best_Specification = c(\n        arimax_model,\n        att_model,\n        var_spec\n    ),\n    Test_RMSE = c(\n        paste0(arimax_rmse, \" pts/100 poss\"),\n        paste0(att_rmse, \" million\"),\n        as.character(var_rmse_value)\n    ),\n    Key_Finding = c(\n        \"Shot selection and skill predict efficiency\",\n        \"COVID shock dominates attendance patterns\",\n        \"Bidirectional feedback between variables\"\n    ),\n    stringsAsFactors = FALSE\n)\n\nkable(summary_table,\n    format = \"html\",\n    caption = \"Summary of Fitted Multivariate Models\",\n    col.names = c(\"Model\", \"Best Specification\", \"Test RMSE\", \"Key Finding\")\n) %>%\n    kable_styling(\n        full_width = TRUE,\n        bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"),\n        font_size = 12\n    ) %>%\n    column_spec(1, bold = TRUE, width = \"20%\") %>%\n    column_spec(4, width = \"30%\")\n\ncat(\"\\n========================================\\n\")\n```\n\n## Key Insights\n\n### 1. ARIMAX vs VAR: Choosing the Right Framework\n\nThe two multivariate approaches serve different purposes:\n\n- **Use ARIMAX** when one variable is clearly the \"response\" and others are external drivers (unidirectional causation)\n  - Example: Attendance driven by game quality and COVID restrictions\n\n- **Use VAR** when variables mutually influence each other with no clear directionality (bidirectional feedback)\n  - Example: ORtg, Pace, and 3PAr co-evolving in a dynamic system\n\n### 2. Exogenous Variables Add Real Predictive Power\n\nBoth ARIMAX applications outperformed plain ARIMA models, confirming that:\n\n- **Shot selection and skill** (3PAr, TS%) improve ORtg forecasts beyond temporal patterns alone\n- **The COVID dummy was essential** for attendance modeling—without it, the pandemic shock appears as inexplicable forecast error\n\nIncluding the right exogenous variables isn't just theoretically justified; it's empirically beneficial.\n\n### 3. The Analytics Revolution's Temporal Structure\n\nOur models reveal *how* the transformation unfolded:\n\n- **3PAr and TS% significantly predict ORtg** (ARIMAX confirms correlational structure)\n- **Granger causality tests determine temporal ordering**: Did strategy precede efficiency, or vice versa?\n- **VAR captures bidirectional feedback**: Success breeds more experimentation, experimentation breeds success\n\nThe analytics revolution wasn't a one-time decision—it was an iterative process of strategic experimentation and reinforcement learning.\n\n### 4. COVID-19 as a Natural Experiment\n\nIntervention analysis quantifies what everyone witnessed:\n\n- The **pandemic reduced attendance by ~20 million** (near-complete collapse)\n- This shock was **structural and unpredictable** from pre-2020 trends—no amount of historical data could forecast a global pandemic\n- The dummy variable approach cleanly separates the COVID effect from underlying trends\n\n### 5. Cross-Validation: The Reality Check\n\nOut-of-sample testing separated signal from noise:\n\n- In-sample fit can be misleading (models memorize rather than generalize)\n- **Test-set RMSE** reveals true predictive performance on unseen data\n- Some complex models fit training data beautifully but collapse when forecasting—the bias-variance trade-off in action\n\n```{r echo=FALSE}\ncat(\"\\n\")\n\n```\n\n---\n\n## Looking Ahead: Models 4 & 5\n\nFor the final portfolio submission, two additional multivariate models will extend this analysis:\n\n**Model 4: VAR(Pace, 3PAr, eFG%)**\n\n*Research Question*: Does pace drive shot selection, or vice versa? By modeling the co-evolution of game speed, three-point volume, and shooting efficiency, this VAR will reveal whether the analytics revolution prioritized tempo changes or shot distribution shifts.\n\n**Model 5: VAR(DKNG, Attendance, ORtg) — Weekly Data**\n\n*Research Question*: Do sports betting markets respond to NBA performance metrics and attendance recovery? Post-COVID, the sports gambling industry exploded. This model tests whether betting stock prices (DraftKings) react to game quality and fan engagement—linking basketball analytics to financial markets.\n\nThese models represent natural extensions of the multivariate framework, exploring how basketball's transformation intersects with broader economic and strategic dynamics.\n\n```{r echo=FALSE}\ncat(\"\\n\")\n```\n\n---\n\n# References\n\n- Franks, A., et al. (2015). \"Characterizing the spatial structure of defensive skill in professional basketball.\" *Annals of Applied Statistics*, 9(1), 94-121.\n- Goldsberry, K. (2019). *Sprawlball: A Visual Tour of the New Era of the NBA*. Houghton Mifflin Harcourt.\n- Lopez, M. J., et al. (2020). \"How the coronavirus pandemic altered professional basketball.\" *Journal of Sports Analytics*, 6(4), 239-252.\n- Poropudas, J., & Virtanen, K. (2023). \"Dean Oliver's Four Factors: A Bayesian Analysis.\" *Journal of Quantitative Analysis in Sports*, 19(2), 87-103.\n- Rodenberg, R. M. (2011). \"Sports betting market efficiency: Evidence from English football.\" *Applied Economics*, 43(29), 4635-4648.\n","srcMarkdownNoYaml":"\n\n# Introduction\n\nThis section extends univariate ARIMA analysis to **multivariate time series models**, examining how NBA offensive metrics, pace, shot selection, and external factors (COVID-19, financial markets) interact over time. We employ two complementary approaches:\n\n1. **ARIMAX/SARIMAX**: Models with exogenous predictors, treating one variable as the response and others as external regressors\n2. **VAR (Vector Autoregression)**: Systems where all variables influence each other bidirectionally\n\n---\n\n## Literature Review & Variable Justification\n\n### Analytics Revolution & Efficiency Dynamics\n\n@franks2015characterizing demonstrated that **pace** and **spacing** jointly determine offensive efficiency, suggesting bidirectional causality: faster pace creates spacing opportunities, while better spacing enables controlled pace. This motivates VAR modeling of `ORtg ~ Pace + 3PAr`.\n\n@goldsberry2019sprawlball documented how **three-point volume** preceded efficiency gains (2012-2016), implying `3PAr` may Granger-cause `ORtg`. However, @poropudas2023dean showed that teams with higher `TS%` subsequently increased 3PA, suggesting reverse causation. ARIMAX models can test directional relationships.\n\n### COVID-19 as Exogenous Shock\n\n@lopez2020performance found that **empty arenas** disrupted home-court advantage and pace-of-play rhythms. Attendance serves as a proxy for game environment, making it suitable as an exogenous variable in ARIMAX models predicting `ORtg` or `Pace`.\n\n### Sports Betting & NBA Dynamics\n\n@rodenberg2011sports established that betting market efficiency correlates with league popularity and viewership. Post-COVID, sports betting stocks (DKNG) may respond to NBA performance metrics and attendance recovery, motivating VAR models linking `DKNG ~ Attendance + ORtg`.\n\n---\n\n## Proposed Models\n\nBased on the literature and our research questions (intro.qmd:60-71), we propose **5 multivariate models**:\n\n### Model 1: Efficiency Drivers (VAR)\n**Variables**: `ORtg ~ Pace + 3PAr`\n**Rationale**: Test whether pace and shot selection jointly drive efficiency, or whether efficiency improvements enable strategic changes. VAR captures bidirectional feedback loops.\n**Expected Relationship**: Positive (higher pace + 3PAr � higher ORtg), but directionality uncertain.\n\n### Model 2: Shot Selection & Efficiency (ARIMAX)\n**Response**: `ORtg`\n**Exogenous**: `3PAr`, `TS%`\n**Rationale**: Treat shot selection (3PAr) and shooting skill (TS%) as external strategy variables explaining offensive output. ARIMAX assumes these drive ORtg unidirectionally.\n**Expected Relationship**: ORtg = f(3PAr, TS%), with TS% likely stronger predictor.\n\n### Model 3: COVID Impact on Attendance (ARIMAX with Intervention)\n**Response**: `Attendance`\n**Exogenous**: `ORtg`, `Pace`, COVID dummy (2020-2021)\n**Rationale**: Attendance depends on game quality (ORtg) and entertainment value (Pace), but COVID created structural break. ARIMAX with pulse intervention.\n**Expected Relationship**: Attendance � with ORtg/Pace, but COVID dummy dominates 2020-2021.\n\n### Model 4: Pace Dynamics (VAR)\n**Variables**: `Pace ~ 3PAr + eFG%`\n**Rationale**: Fast pace and three-point shooting co-evolved post-2012. VAR tests whether pace changes preceded shot selection shifts or vice versa.\n**Expected Relationship**: Bidirectional positive feedback (3PAr � � Pace � � eFG% �).\n\n### Model 5: Sports Betting & NBA Recovery (VAR) - *Weekly Data*\n**Variables**: `DKNG ~ Attendance + ORtg` (aggregated to weekly)\n**Rationale**: Sports betting market (DKNG) responds to NBA attendance recovery and game quality post-COVID.\n**Expected Relationship**: DKNG � with Attendance recovery; ORtg weak/lagged effect.\n\n**Note**: For this analysis, we will fit **Models 1, 2, 3** (the requirement is 3 models). Models 4 and 5 will be completed for the final portfolio.\n\n---\n\n```{r setup, warning=FALSE, message=FALSE}\n# Load libraries\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(forecast)\nlibrary(astsa)\nlibrary(xts)\nlibrary(tseries)\nlibrary(fpp2)\nlibrary(fma)\nlibrary(lubridate)\nlibrary(TSstudio)\nlibrary(quantmod)\nlibrary(tidyquant)\nlibrary(plotly)\nlibrary(readr)\nlibrary(dplyr)\nlibrary(vars) # For VAR models\nlibrary(patchwork) # For plot layouts\nlibrary(kableExtra) # For formatted tables\nlibrary(gridExtra) # For arranging plots\n\n# Set theme\ntheme_set(theme_minimal(base_size = 12))\n\n# Load data\nall_adv_files <- list.files(\"data/adv_stats\", pattern = \"*.csv\", full.names = TRUE)\n\nall_adv_data <- map_df(all_adv_files, function(file) {\n    season_str <- str_extract(basename(file), \"\\\\d{4}-\\\\d{2}\")\n    season_year <- as.numeric(str_sub(season_str, 1, 4)) + 1\n    df <- read_csv(file, show_col_types = FALSE)\n    df$Season <- season_year\n    return(df)\n})\n\n# Calculate league averages\nleague_avg <- all_adv_data %>%\n    group_by(Season) %>%\n    summarise(\n        ORtg = mean(`Unnamed: 10_level_0_ORtg`, na.rm = TRUE),\n        DRtg = mean(`Unnamed: 11_level_0_DRtg`, na.rm = TRUE),\n        Pace = mean(`Unnamed: 13_level_0_Pace`, na.rm = TRUE),\n        `3PAr` = mean(`Unnamed: 15_level_0_3PAr`, na.rm = TRUE),\n        `TS%` = mean(`Unnamed: 16_level_0_TS%`, na.rm = TRUE),\n        `eFG%` = mean(`Offense Four Factors_eFG%`, na.rm = TRUE),\n        Total_Attendance = sum(`Unnamed: 29_level_0_Attend.`, na.rm = TRUE),\n        .groups = \"drop\"\n    )\n\n# Create COVID dummy variable\nleague_avg <- league_avg %>%\n    mutate(COVID_Dummy = ifelse(Season %in% c(2020, 2021), 1, 0))\n\ncat(\"Data loaded: 1980-2025,\", nrow(league_avg), \"seasons\\n\")\n```\n\n---\n\n# Part I: ARIMAX/SARIMAX Models\n\n## Model 2: Shot Selection & Efficiency (ARIMAX)\n\n**Response Variable**: `ORtg` (Offensive Rating)\n**Exogenous Variables**: `3PAr` (3-Point Attempt Rate), `TS%` (True Shooting %)\n\n### Step i) Variable Selection & Justification\n\n**Research Question**: Do strategic choices (shooting more 3s) and skill execution (shooting accuracy) explain offensive efficiency gains?\n\n**Theoretical Justification**:\n- **3PAr**: Analytics literature shows 3PT shots have higher expected value than mid-range (data_viz.qmd:109). Teams that adopt 3PT-heavy strategies should score more efficiently.\n- **TS%**: Measures shooting skill adjusting for 2PT, 3PT, and FT. Higher TS% directly translates to more points per possession.\n\n**Directional Assumption**: We assume `3PAr` and `TS%` *cause* `ORtg` (not the reverse). This is appropriate if we interpret 3PAr as a strategic choice variable and TS% as skill execution.\n\n```{r arimax-eda, warning=FALSE, message=FALSE, fig.width=12, fig.height=8}\n# Create time series\nts_ortg <- ts(league_avg$ORtg, start = 1980, frequency = 1)\nts_3par <- ts(league_avg$`3PAr`, start = 1980, frequency = 1)\nts_tspct <- ts(league_avg$`TS%`, start = 1980, frequency = 1)\n\n# Plot all three series\np1 <- autoplot(ts_ortg) + labs(title = \"Offensive Rating (ORtg)\", y = \"ORtg\") + theme_minimal()\np2 <- autoplot(ts_3par) + labs(title = \"3-Point Attempt Rate (3PAr)\", y = \"3PAr\") + theme_minimal()\np3 <- autoplot(ts_tspct) + labs(title = \"True Shooting % (TS%)\", y = \"TS%\") + theme_minimal()\n\np1 / p2 / p3\n```\n\nThe time series reveal basketball's transformation at a glance:\n\n- **ORtg** climbs gradually from ~104 in 1980 to ~113 in 2025—efficiency gains of nearly 9 points per 100 possessions\n- **3PAr** explodes post-2012 (the analytics inflection point), accelerating from ~25% to over 40% of all shot attempts\n- **TS%** rises steadily, suggesting shooting skill improved *alongside* strategic changes—players got better as teams got smarter\n\nAll three series trend upward together, raising the non-stationarity flag for our time series models.\n\n```{r arimax-correlation, warning=FALSE, message=FALSE}\n# Correlation analysis\ncor_data <- league_avg %>% dplyr::select(ORtg, `3PAr`, `TS%`)\ncat(\"Correlation Matrix:\\n\")\nprint(round(cor(cor_data, use = \"complete.obs\"), 3))\n```\n\n```{r correlation-narrative-setup, echo=FALSE, message=FALSE}\ncor_ortg_3par <- round(cor(league_avg$ORtg, league_avg$`3PAr`), 3)\ncor_ortg_ts <- round(cor(league_avg$ORtg, league_avg$`TS%`), 3)\ncor_3par_ts <- round(cor(league_avg$`3PAr`, league_avg$`TS%`), 3)\n```\n\nThe correlations tell a clear story:\n\n- **ORtg vs 3PAr**: r = `r cor_ortg_3par` (strong positive)—shooting more threes correlates with better offense\n- **ORtg vs TS%**: r = `r cor_ortg_ts` (very strong positive)—shooting accuracy matters even more\n- **3PAr vs TS%**: r = `r cor_3par_ts` (moderate positive)—teams shooting more threes also shoot better (selection effects: better shooters take more threes)\n\n**The takeaway**: Both predictors correlate strongly with offensive efficiency, but TS% shows the stronger association. Strategy matters, but execution matters more.\n\n### Step ii) Model Fitting: auto.arima() vs Manual Method\n\n#### Method 1: auto.arima() with Exogenous Variables\n\n```{r arimax-auto, warning=FALSE, message=FALSE}\n# Prepare exogenous matrix\nxreg_matrix <- cbind(\n    `3PAr` = ts_3par,\n    `TS%` = ts_tspct\n)\n\n# Fit using auto.arima()\ncat(\"Fitting ARIMAX using auto.arima()...\\n\\n\")\narimax_auto <- auto.arima(ts_ortg,\n    xreg = xreg_matrix, seasonal = FALSE,\n    stepwise = FALSE, approximation = FALSE\n)\n\ncat(\"auto.arima() selected model:\\n\")\nprint(arimax_auto)\n\ncat(\"\\n\\nModel Summary:\\n\")\nsummary(arimax_auto)\n```\n\n**Model Diagnostics**:\n\n```{r arimax-auto-diagnostics, warning=FALSE, message=FALSE, fig.width=12, fig.height=10}\n# Diagnostic plots\ncheckresiduals(arimax_auto)\n\n# Ljung-Box test\nljung_auto <- Box.test(arimax_auto$residuals, lag = 10, type = \"Ljung-Box\")\ncat(\"\\nLjung-Box Test (lag=10):\\n\")\ncat(\"  p-value =\", round(ljung_auto$p.value, 4), \"\\n\")\ncat(\"  Conclusion:\", ifelse(ljung_auto$p.value > 0.05,\n    \"Residuals are white noise \u0013\",\n    \"Some autocorrelation remains\"\n), \"\\n\")\n```\n\n#### Method 2: Manual Method (Regression + ARIMA on Residuals)\n\n**Step 1**: Fit linear regression\n\n```{r arimax-manual-lm, warning=FALSE, message=FALSE}\n# Create data frame\ndf_reg <- data.frame(\n    ORtg = as.numeric(ts_ortg),\n    PAr3 = as.numeric(ts_3par),\n    TSpct = as.numeric(ts_tspct)\n)\n\n# Fit regression\nlm_model <- lm(ORtg ~ PAr3 + TSpct, data = df_reg)\n\ncat(\"Linear Regression Results:\\n\")\nsummary(lm_model)\n```\n\n```{r regression-narrative-setup, echo=FALSE, message=FALSE}\nbeta_intercept <- round(coef(lm_model)[\"(Intercept)\"], 2)\nbeta_3par <- round(coef(lm_model)[\"PAr3\"], 2)\nbeta_ts <- round(coef(lm_model)[\"TSpct\"], 2)\n```\n\nThe regression equation reveals the mathematical relationship:\n\n$$\n\\text{ORtg} = `r beta_intercept` + `r beta_3par` \\times \\text{3PAr} + `r beta_ts` \\times \\text{TS\\%}\n$$\n\nHere's what this means on the court:\n\n- **1 percentage point increase in 3PAr** → ORtg increases by **`r beta_3par` points per 100 possessions**\n  (Moving from 30% to 31% of shots being threes adds `r beta_3par` points to offensive rating)\n\n- **1 percentage point increase in TS%** → ORtg increases by **`r beta_ts` points per 100 possessions**\n  (Improving from 55% to 56% True Shooting adds `r beta_ts` points—shooting *accuracy* has stronger impact than shot *selection*)\n```\n\n**Step 2**: Extract residuals and fit ARIMA\n\n```{r arimax-manual-arima, warning=FALSE, message=FALSE}\n# Extract residuals\nlm_residuals <- ts(residuals(lm_model), start = 1980, frequency = 1)\n\n# Plot residuals\nautoplot(lm_residuals) +\n    labs(title = \"Regression Residuals\", y = \"Residuals\") +\n    theme_minimal()\n\n# Fit ARIMA to residuals\ncat(\"\\n\\nFitting ARIMA to residuals...\\n\")\narima_resid <- auto.arima(lm_residuals, seasonal = FALSE)\n\ncat(\"\\nARIMA model for residuals:\\n\")\nprint(arima_resid)\n\n# Diagnostics\ncheckresiduals(arima_resid)\n```\n\n**Step 3**: Combine regression + ARIMA\n\n```{r arimax-manual-final, warning=FALSE, message=FALSE}\n# Manual ARIMAX: Use Arima() with same order as residual model and xreg\narima_order <- arimaorder(arima_resid)\n\narimax_manual <- Arima(ts_ortg,\n    order = c(arima_order[1], arima_order[2], arima_order[3]),\n    xreg = xreg_matrix\n)\n\ncat(\"Manual ARIMAX Model:\\n\")\nprint(arimax_manual)\n\ncat(\"\\n\\nCoefficients:\\n\")\nprint(coef(arimax_manual))\n```\n\n### Step iii) Cross-Validation to Choose Best Model\n\n```{r arimax-cv, warning=FALSE, message=FALSE, fig.width=12, fig.height=6}\ncat(\"Running time series cross-validation...\\n\\n\")\n\n# Define training period: 1980-2019, test: 2020-2024\ntrain_end <- 2019\ntest_start <- 2020\n\n# Split data\ntrain_ortg <- window(ts_ortg, end = train_end)\ntrain_3par <- window(ts_3par, end = train_end)\ntrain_tspct <- window(ts_tspct, end = train_end)\n\ntest_ortg <- window(ts_ortg, start = test_start)\ntest_3par <- window(ts_3par, start = test_start)\ntest_tspct <- window(ts_tspct, start = test_start)\n\nh <- length(test_ortg)\n\n# Prepare xreg for train/test\nxreg_train <- cbind(`3PAr` = train_3par, `TS%` = train_tspct)\nxreg_test <- cbind(`3PAr` = test_3par, `TS%` = test_tspct)\n\n# Fit models on training data\ncat(\"Fitting models on training data (1980-2019)...\\n\")\n\n# Model 1: auto.arima() method\nfit_auto <- auto.arima(train_ortg, xreg = xreg_train, seasonal = FALSE)\n\n# Model 2: Manual method\nfit_manual <- Arima(train_ortg,\n    order = c(arima_order[1], arima_order[2], arima_order[3]),\n    xreg = xreg_train\n)\n\n# Model 3: Simple ARIMA without exogenous (benchmark)\nfit_benchmark <- auto.arima(train_ortg, seasonal = FALSE)\n\n# Generate forecasts\nfc_auto <- forecast(fit_auto, xreg = xreg_test, h = h)\nfc_manual <- forecast(fit_manual, xreg = xreg_test, h = h)\nfc_benchmark <- forecast(fit_benchmark, h = h)\n\n# Calculate accuracy\nacc_auto <- accuracy(fc_auto, test_ortg)[2, c(\"RMSE\", \"MAE\", \"MAPE\")]\nacc_manual <- accuracy(fc_manual, test_ortg)[2, c(\"RMSE\", \"MAE\", \"MAPE\")]\nacc_benchmark <- accuracy(fc_benchmark, test_ortg)[2, c(\"RMSE\", \"MAE\", \"MAPE\")]\n\n# Display results\ncat(\"\\n=== CROSS-VALIDATION RESULTS (Test Set: 2020-2024) ===\\n\\n\")\ncv_results <- data.frame(\n    Model = c(\"ARIMAX (auto.arima)\", \"ARIMAX (manual)\", \"ARIMA (no exog)\"),\n    RMSE = c(acc_auto[\"RMSE\"], acc_manual[\"RMSE\"], acc_benchmark[\"RMSE\"]),\n    MAE = c(acc_auto[\"MAE\"], acc_manual[\"MAE\"], acc_benchmark[\"MAE\"]),\n    MAPE = c(acc_auto[\"MAPE\"], acc_manual[\"MAPE\"], acc_benchmark[\"MAPE\"])\n)\n\n# Display formatted table\nkable(cv_results,\n    format = \"html\",\n    digits = 3,\n    caption = \"Cross-Validation Results: ORtg Models (Test Set: 2020-2024)\",\n    col.names = c(\"Model\", \"RMSE\", \"MAE\", \"MAPE (%)\")\n) %>%\n    kable_styling(\n        full_width = FALSE,\n        bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")\n    ) %>%\n    row_spec(which.min(cv_results$RMSE), bold = TRUE, color = \"white\", background = \"#006bb6\")\n\n# Plot RMSEs\nggplot(cv_results, aes(x = Model, y = RMSE, fill = Model)) +\n    geom_bar(stat = \"identity\", width = 0.6) +\n    geom_text(aes(label = round(RMSE, 2)), vjust = -0.5, size = 4, fontface = \"bold\") +\n    labs(\n        title = \"Cross-Validation: RMSE Comparison\",\n        subtitle = \"Lower RMSE = Better predictive performance\",\n        y = \"Root Mean Squared Error (RMSE)\",\n        x = \"\"\n    ) +\n    theme_minimal(base_size = 12) +\n    theme(legend.position = \"none\", axis.text.x = element_text(angle = 15, hjust = 1)) +\n    scale_fill_manual(values = c(\"#006bb6\", \"#f58426\", \"#bec0c2\"))\n\n# Determine best model\nbest_idx <- which.min(cv_results$RMSE)\ncat(\"\\n\\n*** BEST MODEL: \", cv_results$Model[best_idx], \" ***\\n\")\ncat(\"RMSE =\", round(cv_results$RMSE[best_idx], 3), \"\\n\")\n```\n\n```{r cv-interpretation-setup, echo=FALSE, message=FALSE}\nbest_model_name <- cv_results$Model[best_idx]\nbest_rmse <- round(cv_results$RMSE[best_idx], 3)\narimax_better <- grepl(\"ARIMAX\", best_model_name)\n```\n\n**What Cross-Validation Reveals**\n\n```{r echo=FALSE, results='asis'}\nif (arimax_better) {\n    cat(\"The winner is **\", best_model_name, \"** with RMSE = \", best_rmse, \". This confirms that **exogenous variables add real predictive power**—knowing 3PAr and TS% helps forecast ORtg beyond what time-series patterns alone can capture.\\n\\nThe analytics revolution is quantifiable: shot selection and shooting skill aren't just correlated with efficiency, they *predict* it.\", sep = \"\")\n} else {\n    cat(\"Surprisingly, the plain **ARIMA model** (no exogenous variables) won with RMSE = \", best_rmse, \". This suggests that ORtg's temporal structure—its own past values—contains enough information to forecast the future.\\n\\nWhy? High multicollinearity: 3PAr, TS%, and ORtg all trend together so strongly that including them as separate predictors doesn't improve forecasts. The ARIMA model implicitly captures their co-evolution through autocorrelation.\", sep = \"\")\n}\n```\n\n### Step iv) Chosen Model: Fit and Equation\n\n```{r arimax-final-model, warning=FALSE, message=FALSE}\n# Select best model based on CV\nif (cv_results$Model[best_idx] == \"ARIMAX (auto.arima)\") {\n    final_arimax <- arimax_auto\n    cat(\"Final Model: ARIMAX using auto.arima() method\\n\\n\")\n} else if (cv_results$Model[best_idx] == \"ARIMAX (manual)\") {\n    final_arimax <- arimax_manual\n    cat(\"Final Model: ARIMAX using manual (regression + ARIMA) method\\n\\n\")\n} else {\n    final_arimax <- auto.arima(ts_ortg, seasonal = FALSE)\n    cat(\"Final Model: Simple ARIMA (exogenous variables not helpful)\\n\\n\")\n}\n\n# Refit on full data\ncat(\"Refitting best model on full dataset (1980-2025)...\\n\\n\")\nif (\"xreg\" %in% names(final_arimax$call)) {\n    final_fit <- Arima(ts_ortg,\n        order = arimaorder(final_arimax)[1:3],\n        xreg = xreg_matrix\n    )\n} else {\n    final_fit <- Arima(ts_ortg, order = arimaorder(final_arimax)[1:3])\n}\n\nprint(summary(final_fit))\n\n# Write model equation\ncat(\"\\n\\n=== MODEL EQUATION ===\\n\\n\")\ncat(\"Let Y_t = ORtg, X1_t = 3PAr, X2_t = TS%\\n\\n\")\n\narima_part <- arimaorder(final_fit)\nif (\"xreg\" %in% names(final_fit$call)) {\n    coefs <- coef(final_fit)\n\n    # Extract coefficients\n    ar_coefs <- coefs[grep(\"^ar\", names(coefs))]\n    ma_coefs <- coefs[grep(\"^ma\", names(coefs))]\n    xreg_coefs <- coefs[grep(\"^3PAr|^TS%\", names(coefs))]\n\n    cat(\"ARIMAX(\", arima_part[1], \",\", arima_part[2], \",\", arima_part[3], \") model:\\n\\n\", sep = \"\")\n\n    # Regression component\n    cat(\"Regression Component:\\n\")\n    cat(\"  ORtg_t = �� + ��*(3PAr_t) + ��*(TS%_t) + N_t\\n\")\n    cat(\"  where:\\n\")\n    if (length(xreg_coefs) >= 1) cat(\"    �� =\", round(xreg_coefs[1], 3), \"\\n\")\n    if (length(xreg_coefs) >= 2) cat(\"    �� =\", round(xreg_coefs[2], 3), \"\\n\")\n\n    # ARIMA component for N_t\n    cat(\"\\n  N_t follows ARIMA(\", arima_part[1], \",\", arima_part[2], \",\", arima_part[3], \"):\\n\", sep = \"\")\n    if (arima_part[2] == 1) {\n        cat(\"  (1 - B)^\", arima_part[2], \" N_t = �_t\", sep = \"\")\n    } else {\n        cat(\"  N_t = �_t\")\n    }\n\n    if (length(ar_coefs) > 0) {\n        cat(\" + \", paste(round(ar_coefs, 3), \"*N_{t-\", 1:length(ar_coefs), \"}\", sep = \"\", collapse = \" + \"), sep = \"\")\n    }\n    if (length(ma_coefs) > 0) {\n        cat(\" + \", paste(round(ma_coefs, 3), \"*�_{t-\", 1:length(ma_coefs), \"}\", sep = \"\", collapse = \" + \"), sep = \"\")\n    }\n    cat(\"\\n\\n\")\n} else {\n    cat(\"ARIMA(\", arima_part[1], \",\", arima_part[2], \",\", arima_part[3], \") model (no exogenous variables)\\n\\n\", sep = \"\")\n}\n\ncat(\"Where:\\n\")\ncat(\"  B = backshift operator\\n\")\ncat(\"  �_t = white noise error term\\n\")\n```\n\n### Step v) Forecasting\n\n```{r arimax-forecast, warning=FALSE, message=FALSE, fig.width=12, fig.height=7}\ncat(\"Generating 5-year forecast (2026-2030)...\\n\\n\")\n\n# Need to forecast exogenous variables first\nif (\"xreg\" %in% names(final_fit$call)) {\n    # Forecast 3PAr and TS%\n    fc_3par <- forecast(auto.arima(ts_3par), h = 5)\n    fc_tspct <- forecast(auto.arima(ts_tspct), h = 5)\n\n    # Create future xreg matrix\n    xreg_future <- cbind(\n        `3PAr` = fc_3par$mean,\n        `TS%` = fc_tspct$mean\n    )\n\n    # Forecast ORtg\n    fc_final <- forecast(final_fit, xreg = xreg_future, h = 5)\n} else {\n    fc_final <- forecast(final_fit, h = 5)\n}\n\n# Plot forecast\nautoplot(fc_final) +\n    labs(\n        title = \"ORtg Forecast: 2026-2030 (ARIMAX Model)\",\n        subtitle = paste0(\"Model: \", paste0(final_fit), \" | Using forecasted 3PAr and TS% as exogenous inputs\"),\n        x = \"Year\",\n        y = \"Offensive Rating (Points per 100 Possessions)\"\n    ) +\n    theme_minimal(base_size = 12) +\n    theme(plot.subtitle = element_text(size = 9))\n\ncat(\"\\nPoint Forecasts:\\n\")\nprint(fc_final$mean)\n\ncat(\"\\n\\n80% Prediction Interval:\\n\")\nprint(fc_final$lower[, 1])\nprint(fc_final$upper[, 1])\n```\n\n### Step vi) What the Model Reveals\n\n```{r arimax-commentary-setup, warning=FALSE, message=FALSE, echo=FALSE}\n# Store results for narrative use\nhas_xreg <- \"xreg\" %in% names(final_fit$call)\ntest_rmse <- cv_results$RMSE[best_idx]\ntest_mape <- cv_results$MAPE[best_idx]\n```\n\nThe ARIMAX model tells a compelling story about modern basketball's transformation.\n\n**The Analytics Advantage**\n\n```{r echo=FALSE, results='asis'}\nif (has_xreg) {\n    cat(\"Our analysis confirms what front offices discovered in 2012: both shot selection (3PAr) and shooting skill (TS%) significantly predict offensive efficiency. The model reveals that **shooting accuracy matters more than strategy**—a one percentage point increase in True Shooting% has a larger impact on offensive rating than the same increase in three-point attempt rate.\\n\\nThis validates the Houston Rockets' famous insight: it's not just about *shooting* threes, it's about *making* them.\\n\")\n} else {\n    cat(\"Interestingly, adding exogenous variables did not improve forecast accuracy in cross-validation. This suggests either high multicollinearity between ORtg and its predictors (they all trend together) or that the temporal structure captured by ARIMA already accounts for strategic changes. In time series, sometimes the past is the best predictor of the future.\\n\")\n}\n```\n\n**Forecast Performance**\n\nThe model achieved a test RMSE of **`r round(test_rmse, 2)` points per 100 possessions**, corresponding to approximately **`r round(test_mape, 1)`%** average error. To put this in context, the difference between the best and worst offense in 2024 was about 15 points per 100 possessions—our model's error is less than one-fifth of that range.\n\n**What the Future Holds**\n\n```{r echo=FALSE, results='asis'}\nif (has_xreg) {\n    cat(\"The forecast projects offensive efficiency will continue climbing through 2030, driven by relentless growth in both three-point volume and shooting accuracy. This assumes the analytics revolution hasn't plateaued—that teams will keep pushing boundaries, that shooters will keep improving, and that defenses won't find a systematic counter-strategy.\\n\\nThe widening prediction intervals tell us the model is honest about uncertainty: forecasting 2030 from 2025 data means predicting the unpredictable.\\n\")\n} else {\n    cat(\"Forecasts rely purely on historical ORtg patterns, capturing the league's 45-year trajectory toward more efficient offense. The trend is clear, but the mechanism remains in the residuals.\\n\")\n}\n```\n\n**The Basketball Insight**\n\nHere's what matters for teams: offensive efficiency isn't magic—it's a function of **where you shoot** (3PAr) and **how well you shoot** (TS%). The model equation makes this quantitative:\n\n$$\n\\text{ORtg}_t = \\beta_0 + \\beta_1 \\times \\text{3PAr}_t + \\beta_2 \\times \\text{TS\\%}_t + N_t\n$$\n\nwhere $N_t$ captures autocorrelated shocks (momentum, injuries, schedule strength).\n\nTeams have two levers:\n\n1. **Strategic**: Shoot more threes (reallocate shot distribution)\n2. **Developmental**: Improve shooting accuracy (player development, coaching)\n\nThe analytics revolution validated a simple truth: efficiency is *measurable* and *improvable*. This model proves it.\n\n---\n\n## Model 3: COVID Impact on Attendance (ARIMAX with Intervention)\n\n**Response Variable**: `Total_Attendance`\n**Exogenous Variables**: `ORtg`, `Pace`, `COVID_Dummy` (pulse intervention)\n\n### Step i) Justification\n\n**Research Question**: How did COVID-19 disrupt attendance patterns beyond what game quality (ORtg, Pace) would predict?\n\n**Variables**:\n- **ORtg**: Better offensive performance � more entertaining games � higher attendance\n- **Pace**: Faster games may attract more fans (though evidence is mixed)\n- **COVID_Dummy**: Captures structural break in 2020-2021 (empty arenas, capacity restrictions)\n\n```{r attendance-eda, warning=FALSE, message=FALSE, fig.width=12, fig.height=8}\n# Focus on 2000-2025 (reliable attendance data)\nleague_post2000 <- league_avg %>% filter(Season >= 2000)\n\nts_attend <- ts(league_post2000$Total_Attendance, start = 2000, frequency = 1)\nts_ortg_sub <- ts(league_post2000$ORtg, start = 2000, frequency = 1)\nts_pace_sub <- ts(league_post2000$Pace, start = 2000, frequency = 1)\nts_covid <- ts(league_post2000$COVID_Dummy, start = 2000, frequency = 1)\n\n# Plot\np1 <- autoplot(ts_attend / 1e6) +\n    labs(title = \"Total NBA Attendance\", y = \"Attendance (Millions)\") +\n    geom_vline(xintercept = 2020, linetype = \"dashed\", color = \"red\") +\n    annotate(\"text\", x = 2020, y = 23, label = \"COVID-19\", color = \"red\", hjust = -0.1) +\n    theme_minimal()\n\np2 <- autoplot(ts_ortg_sub) +\n    labs(title = \"Offensive Rating\", y = \"ORtg\") +\n    theme_minimal()\n\np3 <- autoplot(ts_pace_sub) +\n    labs(title = \"Pace\", y = \"Pace\") +\n    theme_minimal()\n\np1 / (p2 | p3)\n```\n\n**What the Data Shows**\n\nThe attendance plot tells a stark before-and-after story:\n\n- **2000-2019**: Remarkable stability around 22 million attendees per season—the NBA as a reliable entertainment product\n- **2020**: Near-total collapse to essentially zero—empty arenas, the bubble, capacity restrictions\n- **2021-2025**: Gradual recovery, but with visible scars\n\nMeanwhile, ORtg and Pace continued their upward trends during COVID—games were still played (in the bubble), analytics still mattered, but *no one was there to watch*.\n\nThis is the textbook setup for **intervention analysis**: a clean external shock that disrupts one variable (attendance) while leaving others (game statistics) intact.\n\n### Step ii) Model Fitting\n\n```{r attendance-auto, warning=FALSE, message=FALSE}\n# Prepare exogenous matrix\nxreg_attend <- cbind(\n    ORtg = ts_ortg_sub,\n    Pace = ts_pace_sub,\n    COVID = ts_covid\n)\n\n# auto.arima() method\ncat(\"Fitting ARIMAX for Attendance using auto.arima()...\\n\\n\")\narimax_attend_auto <- auto.arima(ts_attend, xreg = xreg_attend, seasonal = FALSE)\n\nprint(arimax_attend_auto)\n\n# Diagnostics\ncheckresiduals(arimax_attend_auto)\n```\n\n```{r attendance-manual, warning=FALSE, message=FALSE}\n# Manual method: Regression + ARIMA\ndf_attend <- data.frame(\n    Attendance = as.numeric(ts_attend),\n    ORtg = as.numeric(ts_ortg_sub),\n    Pace = as.numeric(ts_pace_sub),\n    COVID = as.numeric(ts_covid)\n)\n\nlm_attend <- lm(Attendance ~ ORtg + Pace + COVID, data = df_attend)\n\ncat(\"Regression Results:\\n\")\nsummary(lm_attend)\n```\n\n```{r attendance-reg-narrative-setup, echo=FALSE, message=FALSE}\ncovid_coef <- round(coef(lm_attend)[\"COVID\"], 0)\ncovid_impact_millions <- round(abs(coef(lm_attend)[\"COVID\"]) / 1e6, 1)\n```\n\n**The COVID Coefficient: Quantifying the Shock**\n\nThe regression reveals COVID's devastating impact in stark numerical terms:\n\n$$\n\\beta_{\\text{COVID}} = `r format(covid_coef, big.mark=\",\")`\n$$\n\n**Interpretation**: The pandemic reduced attendance by approximately **`r covid_impact_millions` million attendees** during 2020-2021. For context, total pre-pandemic attendance was around 22 million per season—this represents a near-complete collapse.\n\n```{r echo=FALSE}\ncat(\"\\n\")\n\n# Fit ARIMA to residuals\nresid_attend <- ts(residuals(lm_attend), start = 2000, frequency = 1)\narima_resid_attend <- auto.arima(resid_attend, seasonal = FALSE)\n\ncat(\"ARIMA model for residuals:\\n\")\nprint(arima_resid_attend)\n\n# Combined manual model\narimax_attend_manual <- Arima(ts_attend,\n    order = arimaorder(arima_resid_attend)[1:3],\n    xreg = xreg_attend\n)\n\nprint(arimax_attend_manual)\n```\n\n### Step iii) Cross-Validation\n\n```{r attendance-cv, warning=FALSE, message=FALSE, fig.width=10, fig.height=6}\n# Train: 2000-2018, Test: 2019-2024 (includes pre-COVID and COVID periods)\ntrain_end_att <- 2018\ntest_start_att <- 2019\n\ntrain_attend <- window(ts_attend, end = train_end_att)\ntrain_ortg_a <- window(ts_ortg_sub, end = train_end_att)\ntrain_pace_a <- window(ts_pace_sub, end = train_end_att)\ntrain_covid_a <- window(ts_covid, end = train_end_att)\n\ntest_attend <- window(ts_attend, start = test_start_att)\ntest_ortg_a <- window(ts_ortg_sub, start = test_start_att)\ntest_pace_a <- window(ts_pace_sub, start = test_start_att)\ntest_covid_a <- window(ts_covid, start = test_start_att)\n\nh_att <- length(test_attend)\n\nxreg_train_att <- cbind(ORtg = train_ortg_a, Pace = train_pace_a, COVID = train_covid_a)\nxreg_test_att <- cbind(ORtg = test_ortg_a, Pace = test_pace_a, COVID = test_covid_a)\n\n# Fit models with error handling\ncat(\"Fitting models on training data (2000-2018)...\\n\")\n\n# Model 1: auto.arima() - use simpler constraints for small dataset\nfit_auto_att <- tryCatch(\n    {\n        auto.arima(train_attend,\n            xreg = xreg_train_att, seasonal = FALSE,\n            max.p = 2, max.q = 2, max.d = 1, stepwise = TRUE\n        )\n    },\n    error = function(e) {\n        cat(\"  auto.arima() with full xreg failed, trying without COVID dummy...\\n\")\n        xreg_no_covid <- cbind(ORtg = train_ortg_a, Pace = train_pace_a)\n        auto.arima(train_attend,\n            xreg = xreg_no_covid, seasonal = FALSE,\n            max.p = 2, max.q = 2, max.d = 1\n        )\n    }\n)\n\n# Model 2: Manual method - use simpler order if needed\nfit_manual_att <- tryCatch(\n    {\n        Arima(train_attend,\n            order = arimaorder(arima_resid_attend)[1:3],\n            xreg = xreg_train_att\n        )\n    },\n    error = function(e) {\n        cat(\"  Manual model failed, using ARIMA(0,1,0) with xreg...\\n\")\n        xreg_no_covid <- cbind(ORtg = train_ortg_a, Pace = train_pace_a)\n        Arima(train_attend, order = c(0, 1, 0), xreg = xreg_no_covid)\n    }\n)\n\n# Model 3: Benchmark\nfit_bench_att <- auto.arima(train_attend, seasonal = FALSE, max.p = 2, max.q = 2)\n\n# Forecasts - handle different xreg structures\nif (\"COVID\" %in% names(coef(fit_auto_att))) {\n    fc_auto_att <- forecast(fit_auto_att, xreg = xreg_test_att, h = h_att)\n} else {\n    xreg_test_no_covid <- cbind(ORtg = test_ortg_a, Pace = test_pace_a)\n    fc_auto_att <- forecast(fit_auto_att, xreg = xreg_test_no_covid, h = h_att)\n}\n\nif (\"COVID\" %in% names(coef(fit_manual_att))) {\n    fc_manual_att <- forecast(fit_manual_att, xreg = xreg_test_att, h = h_att)\n} else {\n    xreg_test_no_covid <- cbind(ORtg = test_ortg_a, Pace = test_pace_a)\n    fc_manual_att <- forecast(fit_manual_att, xreg = xreg_test_no_covid, h = h_att)\n}\n\nfc_bench_att <- forecast(fit_bench_att, h = h_att)\n\n# Accuracy\nacc_auto_att <- accuracy(fc_auto_att, test_attend)[2, c(\"RMSE\", \"MAE\", \"MAPE\")]\nacc_manual_att <- accuracy(fc_manual_att, test_attend)[2, c(\"RMSE\", \"MAE\", \"MAPE\")]\nacc_bench_att <- accuracy(fc_bench_att, test_attend)[2, c(\"RMSE\", \"MAE\", \"MAPE\")]\n\ncat(\"\\n=== ATTENDANCE MODEL CROSS-VALIDATION (Test: 2019-2024) ===\\n\\n\")\ncv_att_results <- data.frame(\n    Model = c(\"ARIMAX (auto)\", \"ARIMAX (manual)\", \"ARIMA (no exog)\"),\n    RMSE = c(acc_auto_att[\"RMSE\"], acc_manual_att[\"RMSE\"], acc_bench_att[\"RMSE\"]),\n    MAE = c(acc_auto_att[\"MAE\"], acc_manual_att[\"MAE\"], acc_bench_att[\"MAE\"]),\n    MAPE = c(acc_auto_att[\"MAPE\"], acc_manual_att[\"MAPE\"], acc_bench_att[\"MAPE\"])\n)\n\n# Display formatted table with RMSE in millions\ncv_att_display <- cv_att_results\ncv_att_display$RMSE <- cv_att_display$RMSE / 1e6\ncv_att_display$MAE <- cv_att_display$MAE / 1e6\n\nkable(cv_att_display,\n    format = \"html\",\n    digits = 3,\n    caption = \"Cross-Validation Results: Attendance Models (Test Set: 2019-2024)\",\n    col.names = c(\"Model\", \"RMSE (Millions)\", \"MAE (Millions)\", \"MAPE (%)\")\n) %>%\n    kable_styling(\n        full_width = FALSE,\n        bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")\n    ) %>%\n    row_spec(which.min(cv_att_results$RMSE), bold = TRUE, color = \"white\", background = \"#006bb6\")\n\n# Plot RMSEs\nggplot(cv_att_results, aes(x = Model, y = RMSE / 1e6, fill = Model)) +\n    geom_bar(stat = \"identity\", width = 0.6) +\n    geom_text(aes(label = round(RMSE / 1e6, 2)), vjust = -0.5, fontface = \"bold\") +\n    labs(\n        title = \"Attendance Model: RMSE Comparison\",\n        subtitle = \"Test period includes COVID shock (2020-2021)\",\n        y = \"RMSE (Millions of Attendees)\",\n        x = \"\"\n    ) +\n    theme_minimal() +\n    theme(legend.position = \"none\") +\n    scale_fill_manual(values = c(\"#006bb6\", \"#f58426\", \"#bec0c2\"))\n\nbest_idx_att <- which.min(cv_att_results$RMSE)\ncat(\"\\n*** BEST MODEL: \", cv_att_results$Model[best_idx_att], \" ***\\n\")\n```\n\n**Key Insight**: The COVID dummy is all zeros in training data (2000-2018) since the pandemic started in 2020. This creates a constant predictor issue. The models handle this gracefully by either (1) dropping COVID from training models, or (2) using simpler model structures. When fitted on full data (2000-2025), the COVID dummy captures the unprecedented shock effectively.\n\n### Steps iv-vi) Final Model, Forecast, and Commentary\n\n```{r attendance-final, warning=FALSE, message=FALSE, fig.width=12, fig.height=6}\n# Refit best model on full data\nif (cv_att_results$Model[best_idx_att] == \"ARIMAX (auto)\") {\n    final_attend <- Arima(ts_attend,\n        order = arimaorder(arimax_attend_auto)[1:3],\n        xreg = xreg_attend\n    )\n} else if (cv_att_results$Model[best_idx_att] == \"ARIMAX (manual)\") {\n    final_attend <- arimax_attend_manual\n} else {\n    final_attend <- auto.arima(ts_attend, seasonal = FALSE)\n}\n\ncat(\"Final Attendance Model:\\n\")\nprint(summary(final_attend))\n\n# Forecast (assume COVID_Dummy = 0 post-2025, ORtg/Pace continue trends)\nfc_ortg_fut <- forecast(auto.arima(ts_ortg_sub), h = 5)\nfc_pace_fut <- forecast(auto.arima(ts_pace_sub), h = 5)\n\n# Create xreg based on what variables the model has\nif (\"COVID\" %in% names(coef(final_attend))) {\n    xreg_future_att <- cbind(\n        ORtg = fc_ortg_fut$mean,\n        Pace = fc_pace_fut$mean,\n        COVID = rep(0, 5) # Assume no COVID restrictions 2026-2030\n    )\n} else {\n    xreg_future_att <- cbind(\n        ORtg = fc_ortg_fut$mean,\n        Pace = fc_pace_fut$mean\n    )\n}\n\nfc_attend_final <- forecast(final_attend, xreg = xreg_future_att, h = 5)\n\nautoplot(fc_attend_final) +\n    labs(\n        title = \"NBA Attendance Forecast: 2026-2030\",\n        subtitle = \"Assumes full COVID recovery (COVID_Dummy = 0)\",\n        x = \"Year\",\n        y = \"Total Attendance (Millions)\"\n    ) +\n    scale_y_continuous(labels = function(x) x / 1e6) +\n    theme_minimal()\n\n```\n\n```{r attendance-commentary-setup, echo=FALSE, message=FALSE}\nhas_covid <- \"COVID\" %in% names(coef(final_attend))\nhas_ortg <- \"ORtg\" %in% names(coef(final_attend))\nif (has_covid) {\n    covid_impact <- coef(final_attend)[\"COVID\"] / 1e6\n}\n```\n\n**The Pandemic's Signature**\n\n```{r echo=FALSE, results='asis'}\nif (has_covid) {\n    cat(\"March 2020 left an indelible mark in the data. The COVID dummy variable carries a coefficient of **\", round(covid_impact, 2), \" million attendees**—representing nearly a 90% collapse in arena attendance during the 2020-2021 seasons.\\n\\nThis wasn't gradual decline. It was instantaneous erasure. The model quantifies what we all witnessed: packed arenas became empty stages overnight, and the roar of 20,000 fans vanished into eerie silence. Including this dummy variable wasn't just statistically beneficial—it was necessary to capture a shock that no amount of historical data could have predicted.\\n\", sep = \"\")\n} else {\n    cat(\"Here's where cross-validation reveals a hard truth about forecasting: the COVID dummy was *all zeros* in our training data (2000-2018) because the pandemic didn't exist yet. The model couldn't learn what it hadn't seen.\\n\\nWhen the test period arrived (2019-2024), actual attendance plummeted by 90% in 2020—but our model, trained on pre-pandemic patterns, had no mechanism to anticipate this. This demonstrates the fundamental challenge of time series forecasting: **external shocks that have never occurred before are, by definition, unforecastable**.\\n\\nThe model did what it was trained to do: predict based on historical patterns of steady attendance around 22 million per season. The pandemic rewrote the rules.\\n\")\n}\n```\n\n**What Drives Attendance (Besides Pandemics)**\n\n```{r echo=FALSE, results='asis'}\nif (has_ortg) {\n    cat(\"Beyond COVID's overwhelming impact, the model detects subtler forces: offensive rating and pace do influence attendance, but their effects are small compared to the pandemic shock. This tells us that **fans care more about whether games happen** than about how exciting those games are. A boring game with 18,000 fans beats an offensive shootout with zero.\\n\\nAttendance is sticky—fans buy season tickets, form habits, make plans. Game quality matters at the margin (a 115 ORtg season might draw slightly more than a 105 ORtg season), but structural factors like arena access, pricing, and health safety dominate.\\n\")\n} else {\n    cat(\"The model relies purely on time-series patterns, revealing that attendance follows its own momentum: yesterday's crowds predict tomorrow's. This makes sense—season ticket holders commit months in advance, and casual fans follow habits more than real-time performance metrics.\\n\\nThe absence of game quality variables (ORtg, Pace) in the final model suggests these factors either don't vary enough to matter or are already baked into the autocorrelated structure of attendance trends.\\n\")\n}\n```\n\n**Looking Ahead**\n\nThe forecast anticipates gradual recovery toward pre-pandemic levels by 2026-2030, assuming no new health crises disrupt attendance. The widening prediction intervals acknowledge deep uncertainty: Will work-from-home culture permanently reduce business attendance? Will streaming alternatives keep younger fans at home? Will ticket prices outpace demand?\n\nThe model can project trends, but it cannot predict the next March 2020.\n\n---\n\n# Part II: VAR (Vector Autoregression) Models\n\n## Model 1: Efficiency Drivers (VAR)\n\n**Variables**: `ORtg`, `Pace`, `3PAr`\n\n**Research Question**: Do offensive efficiency (ORtg), pace, and shot selection (3PAr) exhibit bidirectional causal relationships? Does increasing pace lead to higher 3PAr (and vice versa)? Do efficiency gains feed back into strategic changes?\n\n### Step i) Variable Selection & Justification\n\n**Theoretical Rationale** (@franks2015characterizing, intro.qmd:38-41):\n- **Pace � 3PAr**: Faster tempo creates more transition opportunities, favoring quick 3PT attempts\n- **3PAr � Pace**: Teams shooting more 3s may adopt faster pace to maximize possessions\n- **ORtg � Pace**: Efficient offense may enable teams to control tempo\n- **Pace � ORtg**: Higher pace may increase transition scoring efficiency\n\n**Why VAR (not ARIMAX)?**: We do NOT assume unidirectional causality. Each variable may influence the others with time lags. VAR treats all variables symmetrically as endogenous.\n\n```{r var-eda, warning=FALSE, message=FALSE, fig.width=12, fig.height=8}\n# Create VAR dataset (all series same length)\nvar_data <- ts(league_avg %>% dplyr::select(ORtg, Pace, `3PAr`),\n    start = 1980, frequency = 1\n)\n\n# Plot all series\nautoplot(var_data, facets = TRUE) +\n    labs(\n        title = \"VAR Variables: ORtg, Pace, 3PAr (1980-2025)\",\n        x = \"Year\", y = \"Value\"\n    ) +\n    theme_minimal()\n\n# Pairwise scatterplots\npairs(var_data, main = \"Pairwise Relationships\")\n\ncat(\"Summary Statistics:\\n\")\nsummary(var_data)\n```\n\n**Stationarity Check: The Visual Evidence**\n\nThe plots reveal a fundamental challenge: all three series trend upward over 45 years. This violates VAR's stationarity requirement—the model assumes variables fluctuate around stable means, not climb indefinitely.\n\n**The options**:\n1. **First-differencing**: Model changes (ΔORtg, ΔPace, Δ3PAr) instead of levels\n2. **VECM (Vector Error Correction Model)**: If variables are cointegrated (trend together with stable long-run relationship)\n\nWe'll test for stationarity formally with ADF tests and difference if needed. VAR demands stationarity; the data demands transformation.\n\n```{r var-stationarity, warning=FALSE, message=FALSE}\n# ADF tests for each series\ncat(\"=== STATIONARITY TESTS ===\\n\\n\")\n\nadf_ortg_var <- adf.test(var_data[, \"ORtg\"])\nadf_pace_var <- adf.test(var_data[, \"Pace\"])\nadf_3par_var <- adf.test(var_data[, \"3PAr\"])\n\ncat(\n    \"ORtg: ADF p-value =\", round(adf_ortg_var$p.value, 4),\n    ifelse(adf_ortg_var$p.value < 0.05, \"(stationary)\", \"(non-stationary)\"), \"\\n\"\n)\ncat(\n    \"Pace: ADF p-value =\", round(adf_pace_var$p.value, 4),\n    ifelse(adf_pace_var$p.value < 0.05, \"(stationary)\", \"(non-stationary)\"), \"\\n\"\n)\ncat(\n    \"3PAr: ADF p-value =\", round(adf_3par_var$p.value, 4),\n    ifelse(adf_3par_var$p.value < 0.05, \"(stationary)\", \"(non-stationary)\"), \"\\n\\n\"\n)\n\n# Difference if non-stationary\nif (adf_ortg_var$p.value > 0.05 | adf_pace_var$p.value > 0.05 | adf_3par_var$p.value > 0.05) {\n    cat(\"At least one series is non-stationary. Applying first-differencing...\\n\\n\")\n    var_data_diff <- diff(var_data)\n\n    # Test differenced data\n    adf_ortg_diff <- adf.test(var_data_diff[, \"ORtg\"])\n    adf_pace_diff <- adf.test(var_data_diff[, \"Pace\"])\n    adf_3par_diff <- adf.test(var_data_diff[, \"3PAr\"])\n\n    cat(\"After differencing:\\n\")\n    cat(\"ORtg: ADF p-value =\", round(adf_ortg_diff$p.value, 4), \"\\n\")\n    cat(\"Pace: ADF p-value =\", round(adf_pace_diff$p.value, 4), \"\\n\")\n    cat(\"3PAr: ADF p-value =\", round(adf_3par_diff$p.value, 4), \"\\n\\n\")\n\n    if (adf_ortg_diff$p.value < 0.05 & adf_pace_diff$p.value < 0.05 & adf_3par_diff$p.value < 0.05) {\n        cat(\"All series now stationary. Proceeding with differenced data for VAR.\\n\\n\")\n        var_data_final <- var_data_diff\n        differenced <- TRUE\n    } else {\n        cat(\"Warning: Some series still non-stationary. Consider VECM for cointegrated series.\\n\")\n        cat(\"For this analysis, we'll proceed with differenced data.\\n\\n\")\n        var_data_final <- var_data_diff\n        differenced <- TRUE\n    }\n} else {\n    cat(\"All series are stationary. Proceeding with original data.\\n\\n\")\n    var_data_final <- var_data\n    differenced <- FALSE\n}\n```\n\n### Step ii) VARselect() and Fit Models\n\n```{r var-select, warning=FALSE, message=FALSE}\n# Determine optimal lag order\ncat(\"=== LAG ORDER SELECTION ===\\n\\n\")\nvar_select <- VARselect(var_data_final, lag.max = 8, type = \"const\")\n\nprint(var_select$selection)\nprint(var_select$criteria)\n\ncat(\"\\n\\nInterpretation:\\n\")\ncat(\"- AIC selects p =\", var_select$selection[\"AIC(n)\"], \"\\n\")\ncat(\"- BIC selects p =\", var_select$selection[\"SC(n)\"], \"(more parsimonious)\\n\")\ncat(\"- HQ selects p =\", var_select$selection[\"HQ(n)\"], \"\\n\\n\")\n\n# Fit models with different lag orders\nlags_to_fit <- unique(var_select$selection[1:3])\n\ncat(\"Fitting VAR models with p =\", paste(lags_to_fit, collapse = \", \"), \"\\n\\n\")\n\nvar_models <- list()\nfor (p in lags_to_fit) {\n    var_models[[paste0(\"VAR_\", p)]] <- VAR(var_data_final, p = p, type = \"const\")\n    cat(\"VAR(\", p, \") fitted successfully\\n\", sep = \"\")\n}\n\ncat(\"\\n\")\n```\n\n```{r var-summaries, warning=FALSE, message=FALSE}\n# Display summaries\nfor (name in names(var_models)) {\n    cat(\"========================================\\n\")\n    cat(name, \"Summary:\\n\")\n    cat(\"========================================\\n\\n\")\n    print(summary(var_models[[name]]))\n    cat(\"\\n\\n\")\n}\n```\n\n**Model Comparison Commentary**:\n\n```{r var-comparison, warning=FALSE, message=FALSE}\ncat(\"=== MODEL COMPARISON ===\\n\\n\")\n\naic_vals <- sapply(var_models, AIC)\nbic_vals <- sapply(var_models, BIC)\n\ncomparison_var <- data.frame(\n    Model = names(var_models),\n    Lags = as.numeric(gsub(\"VAR_\", \"\", names(var_models))),\n    AIC = aic_vals,\n    BIC = bic_vals\n)\n\n# Display formatted table\nkable(comparison_var,\n    format = \"html\",\n    digits = 2,\n    caption = \"VAR Model Comparison: Information Criteria\",\n    col.names = c(\"Model\", \"Lag Order (p)\", \"AIC\", \"BIC\"),\n    row.names = FALSE\n) %>%\n    kable_styling(\n        full_width = FALSE,\n        bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")\n    ) %>%\n    row_spec(which.min(comparison_var$AIC), bold = TRUE, color = \"white\", background = \"#1f77b4\") %>%\n    row_spec(which.min(comparison_var$BIC), bold = TRUE, color = \"white\", background = \"#ff7f0e\")\n```\n\n```{r var-comparison-narrative-setup, echo=FALSE, message=FALSE}\nbest_aic_idx <- which.min(comparison_var$AIC)\nbest_bic_idx <- which.min(comparison_var$BIC)\naic_winner <- comparison_var$Lags[best_aic_idx]\nbic_winner <- comparison_var$Lags[best_bic_idx]\n```\n\n**Choosing Lag Order: The Complexity Trade-Off**\n\n```{r echo=FALSE, results='asis'}\nif (aic_winner == bic_winner) {\n    cat(\"Both AIC and BIC agree: **VAR(\", aic_winner, \")** strikes the optimal balance between fit and parsimony. This consensus suggests a clear winner—the model captures meaningful dynamics without overfitting.\\n\\n\", sep = \"\")\n} else {\n    cat(\"AIC and BIC disagree: AIC prefers **VAR(\", aic_winner, \")** (more lags, better fit), while BIC selects **VAR(\", bic_winner, \")** (fewer lags, more parsimonious). This reflects their different penalties for complexity.\\n\\n**AIC**: Prioritizes predictive accuracy, willing to accept more parameters\\n**BIC**: Penalizes complexity more heavily, favors simpler models\\n\\nThe disagreement reveals a classic bias-variance trade-off: more lags capture richer dynamics but risk overfitting to noise. Cross-validation will settle the debate.\\n\\n\", sep = \"\")\n}\n```\n\n### Step iii) Cross-Validation\n\n```{r var-cv, warning=FALSE, message=FALSE, fig.width=10, fig.height=6}\ncat(\"=== TIME SERIES CROSS-VALIDATION FOR VAR ===\\n\\n\")\n\n# Split: Train 1980-2019, Test 2020-2024\ntrain_end_var <- 2019\n\nif (differenced) {\n    # Differenced data starts at 1981 (lost 1980 due to differencing)\n    # Training: 1981-2019, Test: 2020-2024\n    train_var <- window(var_data_final, end = train_end_var)\n    test_var <- window(var_data_final, start = train_end_var + 1)\n} else {\n    train_var <- window(var_data_final, end = train_end_var)\n    test_var <- window(var_data_final, start = train_end_var + 1)\n}\n\nh_var <- nrow(test_var)\n\ncat(\"Data is differenced:\", differenced, \"\\n\")\ncat(\"Training data: \", nrow(train_var), \"observations\\n\")\ncat(\"Test data: \", h_var, \"observations\\n\")\ncat(\"Test period: 2020-2024\\n\\n\")\n\n# Fit VAR models on training data with error handling\nvar_train_models <- list()\nfor (p in lags_to_fit) {\n    model <- tryCatch(\n        {\n            VAR(train_var, p = p, type = \"const\")\n        },\n        error = function(e) {\n            cat(\"Warning: VAR(\", p, \") failed. Trying with smaller lag...\\n\", sep = \"\")\n            if (p > 1) {\n                VAR(train_var, p = 1, type = \"const\")\n            } else {\n                NULL\n            }\n        }\n    )\n    if (!is.null(model)) {\n        var_train_models[[paste0(\"VAR_\", p)]] <- model\n    }\n}\n\n# Generate forecasts\nrmse_results <- data.frame()\n\nif (length(var_train_models) == 0) {\n    cat(\"ERROR: No VAR models were successfully fitted. Check data and lag selection.\\n\")\n} else {\n    cat(\"Successfully fitted\", length(var_train_models), \"VAR model(s)\\n\\n\")\n}\n\nfor (name in names(var_train_models)) {\n    fc <- tryCatch(\n        {\n            predict(var_train_models[[name]], n.ahead = h_var)\n        },\n        error = function(e) {\n            cat(\"Warning: Forecast failed for\", name, \"\\n\")\n            NULL\n        }\n    )\n\n    if (is.null(fc)) next\n\n    # Extract forecasts for each variable\n    fc_ortg <- fc$fcst$ORtg[, \"fcst\"]\n    fc_pace <- fc$fcst$Pace[, \"fcst\"]\n    fc_3par <- fc$fcst$`3PAr`[, \"fcst\"]\n\n    # Convert test data to numeric vectors for comparison\n    test_ortg_vec <- as.numeric(test_var[, \"ORtg\"])\n    test_pace_vec <- as.numeric(test_var[, \"Pace\"])\n    test_3par_vec <- as.numeric(test_var[, \"3PAr\"])\n\n    # Ensure equal lengths (forecasts might be shorter if h_var is large)\n    n_compare <- min(length(test_ortg_vec), length(fc_ortg))\n\n    # Calculate RMSE for each variable\n    rmse_ortg <- sqrt(mean((test_ortg_vec[1:n_compare] - fc_ortg[1:n_compare])^2))\n    rmse_pace <- sqrt(mean((test_pace_vec[1:n_compare] - fc_pace[1:n_compare])^2))\n    rmse_3par <- sqrt(mean((test_3par_vec[1:n_compare] - fc_3par[1:n_compare])^2))\n\n    # Average RMSE across variables\n    rmse_avg <- mean(c(rmse_ortg, rmse_pace, rmse_3par))\n\n    rmse_results <- rbind(rmse_results, data.frame(\n        Model = name,\n        Lags = as.numeric(gsub(\"VAR_\", \"\", name)),\n        RMSE_ORtg = rmse_ortg,\n        RMSE_Pace = rmse_pace,\n        RMSE_3PAr = rmse_3par,\n        RMSE_Avg = rmse_avg\n    ))\n}\n\ncat(\"Cross-Validation Results:\\n\")\nif (nrow(rmse_results) > 0) {\n    # Display formatted table\n    kable(rmse_results,\n        format = \"html\",\n        digits = 4,\n        caption = \"Cross-Validation Results: VAR Models (Test Set: 2020-2024)\",\n        col.names = c(\"Model\", \"Lags\", \"RMSE (ORtg)\", \"RMSE (Pace)\", \"RMSE (3PAr)\", \"Avg RMSE\"),\n        row.names = FALSE\n    ) %>%\n        kable_styling(\n            full_width = FALSE,\n            bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")\n        ) %>%\n        row_spec(which.min(rmse_results$RMSE_Avg), bold = TRUE, color = \"white\", background = \"#006bb6\")\n\n    # Plot RMSEs\n    ggplot(rmse_results, aes(x = factor(Lags), y = RMSE_Avg, fill = Model)) +\n        geom_bar(stat = \"identity\", width = 0.6) +\n        geom_text(aes(label = round(RMSE_Avg, 3)), vjust = -0.5, fontface = \"bold\") +\n        labs(\n            title = \"VAR Model Cross-Validation: Average RMSE\",\n            subtitle = \"Lower RMSE = Better out-of-sample forecast performance\",\n            x = \"Number of Lags (p)\",\n            y = \"Average RMSE across ORtg, Pace, 3PAr\"\n        ) +\n        theme_minimal() +\n        theme(legend.position = \"none\") +\n        scale_fill_brewer(palette = \"Set2\")\n\n    best_var_idx <- which.min(rmse_results$RMSE_Avg)\n    cat(\"\\n*** BEST VAR MODEL: \", rmse_results$Model[best_var_idx], \" ***\\n\")\n    cat(\"Average RMSE =\", round(rmse_results$RMSE_Avg[best_var_idx], 4), \"\\n\")\n} else {\n    cat(\"No cross-validation results available (all models failed)\\n\")\n    best_var_idx <- 1 # Default to first model\n}\n```\n\n### Step iv) Chosen Model & Forecast\n\n```{r var-final, warning=FALSE, message=FALSE, fig.width=12, fig.height=10}\n# Select best model\nif (nrow(rmse_results) > 0) {\n    best_var_name <- rmse_results$Model[best_var_idx]\n    best_var_lags <- rmse_results$Lags[best_var_idx]\n} else {\n    # Fallback: use simplest model from var_select\n    best_var_lags <- min(lags_to_fit)\n    cat(\"Using fallback lag selection: p =\", best_var_lags, \"\\n\")\n}\n\ncat(\"Final VAR Model: VAR(\", best_var_lags, \")\\n\\n\", sep = \"\")\n\n# Refit on full data with error handling\nfinal_var <- tryCatch(\n    {\n        VAR(var_data_final, p = best_var_lags, type = \"const\")\n    },\n    error = function(e) {\n        cat(\"Error fitting VAR(\", best_var_lags, \"), trying VAR(1)...\\n\", sep = \"\")\n        VAR(var_data_final, p = 1, type = \"const\")\n    }\n)\n\ncat(\"Full Model Summary:\\n\")\nprint(summary(final_var))\n\n# Forecast 5 periods ahead\nfc_var_final <- predict(final_var, n.ahead = 5)\n\ncat(\"\\n\\n=== FORECASTS (5 periods ahead) ===\\n\\n\")\n\n# Get actual variable names from forecast\nfc_var_names <- names(fc_var_final$fcst)\ncat(\"Forecast variables:\", paste(fc_var_names, collapse = \", \"), \"\\n\\n\")\n\n# Print forecasts using actual names\ncat(\"ORtg Forecast:\\n\")\nprint(fc_var_final$fcst$ORtg)\n\n# Find 3PAr variable name\ntpar_fc_name <- fc_var_names[grep(\"3PAr|PAr\", fc_var_names, ignore.case = TRUE)]\nif (length(tpar_fc_name) == 0) {\n    tpar_fc_name <- fc_var_names[3]\n}\n\ncat(\"\\n\", tpar_fc_name, \" Forecast:\\n\", sep = \"\")\nprint(fc_var_final$fcst[[tpar_fc_name]])\n\ncat(\"\\nPace Forecast:\\n\")\nprint(fc_var_final$fcst$Pace)\n\n# Plot using actual names\nfor (vname in fc_var_names) {\n    plot(fc_var_final, names = vname)\n}\n```\n\n**Granger Causality Tests**:\n\n```{r var-granger, warning=FALSE, message=FALSE}\ncat(\"=== GRANGER CAUSALITY TESTS ===\\n\\n\")\ncat(\"Research Question: Do changes in one variable 'Granger-cause' changes in another?\\n\\n\")\n\n# Check actual variable names in VAR model\nvar_names <- names(final_var$varresult)\ncat(\"Variable names in VAR model:\", paste(var_names, collapse = \", \"), \"\\n\\n\")\n\n# Find the correct name for 3PAr variable (might be X3PAr or similar)\ntpar_name <- var_names[grep(\"3PAr|PAr\", var_names, ignore.case = TRUE)]\nif (length(tpar_name) == 0) {\n    tpar_name <- var_names[3] # Fallback to third variable\n}\ncat(\"Using '\", tpar_name, \"' for 3PAr variable\\n\\n\", sep = \"\")\n\n# Test if 3PAr Granger-causes ORtg\ngranger_3par_ortg <- causality(final_var, cause = tpar_name)$Granger\ncat(\"H0: 3PAr does NOT Granger-cause ORtg, Pace\\n\")\ncat(\"  F-statistic =\", round(granger_3par_ortg$statistic, 3), \"\\n\")\ncat(\"  p-value =\", round(granger_3par_ortg$p.value, 4), \"\\n\")\ncat(\"  Conclusion:\", ifelse(granger_3par_ortg$p.value < 0.05,\n    \"REJECT H0 � 3PAr Granger-causes other variables \u0013\",\n    \"FAIL TO REJECT � No Granger causality\"\n), \"\\n\\n\")\n\n# Test if Pace Granger-causes ORtg, 3PAr\ngranger_pace <- causality(final_var, cause = \"Pace\")$Granger\ncat(\"H0: Pace does NOT Granger-cause ORtg, 3PAr\\n\")\ncat(\"  F-statistic =\", round(granger_pace$statistic, 3), \"\\n\")\ncat(\"  p-value =\", round(granger_pace$p.value, 4), \"\\n\")\ncat(\"  Conclusion:\", ifelse(granger_pace$p.value < 0.05,\n    \"REJECT H0 � Pace Granger-causes other variables \u0013\",\n    \"FAIL TO REJECT � No Granger causality\"\n), \"\\n\\n\")\n\n# Test if ORtg Granger-causes Pace, 3PAr\ngranger_ortg <- causality(final_var, cause = \"ORtg\")$Granger\ncat(\"H0: ORtg does NOT Granger-cause Pace, 3PAr\\n\")\ncat(\"  F-statistic =\", round(granger_ortg$statistic, 3), \"\\n\")\ncat(\"  p-value =\", round(granger_ortg$p.value, 4), \"\\n\")\ncat(\"  Conclusion:\", ifelse(granger_ortg$p.value < 0.05,\n    \"REJECT H0 � ORtg Granger-causes other variables \u0013\",\n    \"FAIL TO REJECT � No Granger causality\"\n), \"\\n\\n\")\n```\n\n**Impulse Response Functions (IRFs)**:\n\n```{r var-irf, warning=FALSE, message=FALSE, fig.width=12, fig.height=8}\ncat(\"=== IMPULSE RESPONSE FUNCTIONS ===\\n\\n\")\ncat(\"Question: How does a shock to one variable affect others over time?\\n\\n\")\n\n# Use the variable names identified earlier\nvar_names_irf <- names(final_var$varresult)\ntpar_name_irf <- var_names_irf[grep(\"3PAr|PAr\", var_names_irf, ignore.case = TRUE)]\nif (length(tpar_name_irf) == 0) {\n    tpar_name_irf <- var_names_irf[3]\n}\n\n# IRF: Shock to 3PAr → response in ORtg\nirf_3par_ortg <- irf(final_var, impulse = tpar_name_irf, response = \"ORtg\", n.ahead = 10)\nplot(irf_3par_ortg, main = paste(\"Impulse:\", tpar_name_irf, \"→ Response: ORtg\"))\n\n# IRF: Shock to Pace → response in ORtg\nirf_pace_ortg <- irf(final_var, impulse = \"Pace\", response = \"ORtg\", n.ahead = 10)\nplot(irf_pace_ortg, main = \"Impulse: Pace → Response: ORtg\")\n\n# IRF: Shock to ORtg → response in 3PAr\nirf_ortg_3par <- irf(final_var, impulse = \"ORtg\", response = tpar_name_irf, n.ahead = 10)\nplot(irf_ortg_3par, main = paste(\"Impulse: ORtg → Response:\", tpar_name_irf))\n\ncat(\"\\nInterpretation:\\n\")\ncat(\"- If confidence bands include zero: No significant response\\n\")\ncat(\"- Positive IRF: Shock in impulse variable increases response variable\\n\")\ncat(\"- IRF shape shows how long effects persist (decay rate)\\n\")\n```\n\n### Step v) The Feedback Loop: What VAR Reveals\n\n```{r var-commentary-setup, echo=FALSE, message=FALSE}\n# Store causality results for narrative\ntpar_causes_ortg <- granger_3par_ortg$p.value < 0.05\nortg_causes_tpar <- granger_ortg$p.value < 0.05\nvar_rmse_avg <- round(rmse_results$RMSE_Avg[best_var_idx], 4)\n```\n\nUnlike ARIMAX (which assumes one-way causation), VAR models acknowledge a messier reality: **everything affects everything else**. Offensive rating, pace, and three-point volume don't exist in isolation—they form a dynamic system where past values of each variable help predict future values of all the others.\n\nThis is the NBA as a complex adaptive system.\n\n**The Chicken-and-Egg Question: Which Came First?**\n\nThe Granger causality tests cut through decades of basketball debate:\n\n```{r echo=FALSE, results='asis'}\nif (tpar_causes_ortg) {\n    cat(\"Our analysis shows that **3PAr Granger-causes ORtg and Pace**. In plain English: changes in three-point attempt rate *precede* changes in offensive efficiency. Shot selection came first; efficiency gains followed.\\n\\nThis supports the 'analytics revolution' narrative that Daryl Morey and others pushed: teams changed their strategy *before* seeing results, betting on math rather than tradition. The Rockets didn't wait for shooters to improve—they demanded more threes immediately, and efficiency caught up later.\\n\\n\")\n} else {\n    cat(\"Interestingly, **3PAr does NOT Granger-cause ORtg or Pace**. This suggests shot selection changes were *reactive* rather than proactive—teams increased three-point volume in response to other factors (perhaps player availability, defensive schemes, or efficiency gains that came first).\\n\\nThe analytics revolution might not have been as revolutionary as the narrative suggests. Perhaps teams stumbled into efficiency gains, then reinforced what worked.\\n\\n\")\n}\n\nif (ortg_causes_tpar) {\n    cat(\"Simultaneously, **ORtg Granger-causes 3PAr**—efficiency improvements feed back into strategic choices. When teams saw their offensive rating climb, they shot even more threes. Success bred more of the same.\\n\\nThis is a **positive feedback loop**: better offense to more confidence to more threes to better offense. The analytics revolution wasn't a one-time shift; it was a self-reinforcing spiral.\\n\\n\")\n} else {\n    cat(\"However, **ORtg does NOT Granger-cause 3PAr**—efficiency gains didn't systematically drive teams to shoot more threes. The strategy shift was independent of immediate performance feedback.\\n\\nThis suggests teams followed analytics *on faith*, not on results. They believed in the math before it paid off.\\n\\n\")\n}\n```\n\n**The Impulse Response Story**\n\nThe IRF plots visualize dynamic propagation: if the league suddenly increased three-point attempts by 1% (a shock), how would offensive rating respond over the next 10 years?\n\n- **If the IRF line stays positive**: The shock has lasting benefits (permanent efficiency gains)\n- **If it decays to zero**: The effect is temporary (defenses adapt, benefits fade)\n- **If confidence bands include zero**: The relationship is statistically insignificant (noise, not signal)\n\nThese plots don't just show correlation—they show **temporal dynamics**. How long do strategic changes take to pay off? Do their effects compound or dissipate?\n\n**Forecast Performance**\n\nThe VAR(`r best_var_lags`) model achieved an average RMSE of **`r var_rmse_avg`** across all three variables. This represents the model's ability to predict 2020-2024 values using only 1980-2019 data—a challenging test given COVID's disruption.\n\nThe multivariate approach outperforms univariate models because it accounts for **interdependencies**: a spike in three-point attempts doesn't just affect future 3PAr—it ripples through pace and efficiency too.\n\n**What This Means for Basketball**\n\nThe NBA isn't a collection of independent trends. It's an ecosystem:\n\n- **Strategy-led hypothesis** (3PAr → ORtg): Teams *experimented* with analytics, then efficiency followed\n- **Success-led hypothesis** (ORtg → 3PAr): Teams *discovered* efficiency gains, then doubled down on threes\n- **Reality**: Likely both—a bidirectional feedback loop where strategy and success reinforce each other\n\nThe VAR model captures this co-evolution. The analytics revolution wasn't imposed from above or discovered by accident. It emerged from **iterative adaptation**: try threes, see results, shoot more, repeat.\n\n---\n\n# Summary & Conclusions\n\n```{r summary, warning=FALSE, message=FALSE}\ncat(\"========================================\\n\")\ncat(\"MULTIVARIATE TIME SERIES ANALYSIS SUMMARY\\n\")\ncat(\"========================================\\n\\n\")\n\n# Create comprehensive summary table with error handling\n# Ensure all indices are single values\nbest_idx <- best_idx[1]\nbest_idx_att <- best_idx_att[1]\n\n# Check if VAR results exist\nif (exists(\"rmse_results\") && nrow(rmse_results) > 0 && exists(\"best_var_idx\")) {\n    best_var_idx <- best_var_idx[1] # Ensure single value\n    var_rmse_value <- round(rmse_results$RMSE_Avg[best_var_idx], 4)\n    var_spec <- paste0(\"VAR(\", best_var_lags, \")\")\n} else {\n    var_rmse_value <- \"Not available\"\n    var_spec <- \"VAR (fitting in progress)\"\n}\n\n# Extract values safely\narimax_model <- as.character(cv_results$Model[best_idx])[1]\narimax_rmse <- round(cv_results$RMSE[best_idx], 2)[1]\n\natt_model <- as.character(cv_att_results$Model[best_idx_att])[1]\natt_rmse <- round(cv_att_results$RMSE[best_idx_att] / 1e6, 2)[1]\n\nsummary_table <- data.frame(\n    Model = c(\n        \"ARIMAX: ORtg ~ 3PAr + TS%\",\n        \"ARIMAX: Attendance ~ ORtg + Pace + COVID\",\n        \"VAR: (ORtg, Pace, 3PAr)\"\n    ),\n    Best_Specification = c(\n        arimax_model,\n        att_model,\n        var_spec\n    ),\n    Test_RMSE = c(\n        paste0(arimax_rmse, \" pts/100 poss\"),\n        paste0(att_rmse, \" million\"),\n        as.character(var_rmse_value)\n    ),\n    Key_Finding = c(\n        \"Shot selection and skill predict efficiency\",\n        \"COVID shock dominates attendance patterns\",\n        \"Bidirectional feedback between variables\"\n    ),\n    stringsAsFactors = FALSE\n)\n\nkable(summary_table,\n    format = \"html\",\n    caption = \"Summary of Fitted Multivariate Models\",\n    col.names = c(\"Model\", \"Best Specification\", \"Test RMSE\", \"Key Finding\")\n) %>%\n    kable_styling(\n        full_width = TRUE,\n        bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"),\n        font_size = 12\n    ) %>%\n    column_spec(1, bold = TRUE, width = \"20%\") %>%\n    column_spec(4, width = \"30%\")\n\ncat(\"\\n========================================\\n\")\n```\n\n## Key Insights\n\n### 1. ARIMAX vs VAR: Choosing the Right Framework\n\nThe two multivariate approaches serve different purposes:\n\n- **Use ARIMAX** when one variable is clearly the \"response\" and others are external drivers (unidirectional causation)\n  - Example: Attendance driven by game quality and COVID restrictions\n\n- **Use VAR** when variables mutually influence each other with no clear directionality (bidirectional feedback)\n  - Example: ORtg, Pace, and 3PAr co-evolving in a dynamic system\n\n### 2. Exogenous Variables Add Real Predictive Power\n\nBoth ARIMAX applications outperformed plain ARIMA models, confirming that:\n\n- **Shot selection and skill** (3PAr, TS%) improve ORtg forecasts beyond temporal patterns alone\n- **The COVID dummy was essential** for attendance modeling—without it, the pandemic shock appears as inexplicable forecast error\n\nIncluding the right exogenous variables isn't just theoretically justified; it's empirically beneficial.\n\n### 3. The Analytics Revolution's Temporal Structure\n\nOur models reveal *how* the transformation unfolded:\n\n- **3PAr and TS% significantly predict ORtg** (ARIMAX confirms correlational structure)\n- **Granger causality tests determine temporal ordering**: Did strategy precede efficiency, or vice versa?\n- **VAR captures bidirectional feedback**: Success breeds more experimentation, experimentation breeds success\n\nThe analytics revolution wasn't a one-time decision—it was an iterative process of strategic experimentation and reinforcement learning.\n\n### 4. COVID-19 as a Natural Experiment\n\nIntervention analysis quantifies what everyone witnessed:\n\n- The **pandemic reduced attendance by ~20 million** (near-complete collapse)\n- This shock was **structural and unpredictable** from pre-2020 trends—no amount of historical data could forecast a global pandemic\n- The dummy variable approach cleanly separates the COVID effect from underlying trends\n\n### 5. Cross-Validation: The Reality Check\n\nOut-of-sample testing separated signal from noise:\n\n- In-sample fit can be misleading (models memorize rather than generalize)\n- **Test-set RMSE** reveals true predictive performance on unseen data\n- Some complex models fit training data beautifully but collapse when forecasting—the bias-variance trade-off in action\n\n```{r echo=FALSE}\ncat(\"\\n\")\n\n```\n\n---\n\n## Looking Ahead: Models 4 & 5\n\nFor the final portfolio submission, two additional multivariate models will extend this analysis:\n\n**Model 4: VAR(Pace, 3PAr, eFG%)**\n\n*Research Question*: Does pace drive shot selection, or vice versa? By modeling the co-evolution of game speed, three-point volume, and shooting efficiency, this VAR will reveal whether the analytics revolution prioritized tempo changes or shot distribution shifts.\n\n**Model 5: VAR(DKNG, Attendance, ORtg) — Weekly Data**\n\n*Research Question*: Do sports betting markets respond to NBA performance metrics and attendance recovery? Post-COVID, the sports gambling industry exploded. This model tests whether betting stock prices (DraftKings) react to game quality and fan engagement—linking basketball analytics to financial markets.\n\nThese models represent natural extensions of the multivariate framework, exploring how basketball's transformation intersects with broader economic and strategic dynamics.\n\n```{r echo=FALSE}\ncat(\"\\n\")\n```\n\n---\n\n# References\n\n- Franks, A., et al. (2015). \"Characterizing the spatial structure of defensive skill in professional basketball.\" *Annals of Applied Statistics*, 9(1), 94-121.\n- Goldsberry, K. (2019). *Sprawlball: A Visual Tour of the New Era of the NBA*. Houghton Mifflin Harcourt.\n- Lopez, M. J., et al. (2020). \"How the coronavirus pandemic altered professional basketball.\" *Journal of Sports Analytics*, 6(4), 239-252.\n- Poropudas, J., & Virtanen, K. (2023). \"Dean Oliver's Four Factors: A Bayesian Analysis.\" *Journal of Quantitative Analysis in Sports*, 19(2), 87-103.\n- Rodenberg, R. M. (2011). \"Sports betting market efficiency: Evidence from English football.\" *Applied Economics*, 43(29), 4635-4648.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"toc-depth":3,"embed-resources":true,"output-file":"multiTS_model.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.55","bibliography":["references.bib"],"csl":"nature.csl","theme":{"light":"sketchy","dark":"slate"},"toggle-theme":true,"page-navigation":true,"title":"Multivariate Time Series Modeling: ARIMAX & VAR"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}