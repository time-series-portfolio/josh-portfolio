---
title: "Multivariate Time Series Modeling"
format:
  html:
    code-fold: true
    toc: true
    toc-depth: 3
    embed-resources: true
---

# Theoretical Framework

This chapter examines bidirectional relationships between variables, including the explicit linkage between basketball performance and betting industry valuations (DKNG ~ Attendance + ORtg). By modeling how NBA metrics influence betting stocks, we test whether the on-court analytics revolution created measurable financial value in connected industries.

::: {.panel-tabset}

## Literature Review

Understanding NBA offensive efficiency requires a framework that separates team performance from game tempo. Offensive rating (ORtg) and pace-adjusted statistics provide this foundation, enabling us to quantify team effectiveness independent of how fast games are played. This distinction is critical for multivariate analysis because pace itself may be a strategic choice rather than a neutral contextual factor @kubatko2007starting.

The relationship between pace, spacing, and offensive efficiency involves bidirectional causality: faster tempo creates spacing opportunities through transition play, while better floor spacing enables teams to control pace more effectively @skinner2012problem. This co-evolution suggests that variables like ORtg, Pace, and 3PAr influence each other over time rather than following a simple cause-and-effect sequence @franks2015characterizing. Additionally, three-point attempts offer higher expected value than mid-range shots when accounting for shooting percentages, providing the mathematical foundation for the shot selection revolution @sliz2017investigation.

Recent work reveals that teams with higher True Shooting percentage subsequently increased their three-point volume, suggesting reverse causation: success breeds strategy changes. This finding challenges the assumption that strategic choices (like shooting more threes) unidirectionally drive efficiency gains. Instead, teams that shot efficiently were more likely to adopt analytics-driven shot selection in future seasons, creating a feedback loop where strategy and performance reinforce each other @poropudas2023dean.

These dynamics motivate our multivariate approach. ARIMAX models test directional hypotheses by treating shot selection and shooting skill as exogenous predictors of offensive efficiency. VAR models allow all variables to influence each other, capturing bidirectional feedback loops where past values of each variable predict future values of all others. Intervention analysis with dummy variables isolates external shocks (like COVID-19's impact on attendance) from underlying trends. Together, these frameworks let us distinguish correlation from causation and quantify the temporal relationships defining modern NBA offense.


## Proposed Models

### Model 1: Efficiency Drivers (VAR)
`ORtg ~ Pace & 3PAr`

### Model 2: Shot Selection & Efficiency (ARIMAX)
`ORtg ~ 3PAr + TS%`

### Model 3: COVID Impact on Attendance (ARIMAX)
`Attendance ~ ORtg + Pace`

### Model 4: Pace Dynamics (VAR)
`Pace ~ 3PAr + eFG%`

### Model 5: Sports Betting & NBA Recovery (VAR)
`DKNG ~ Attendance + ORtg`

:::

---

```{r setup, warning=FALSE, message=FALSE}
library(tidyverse)
library(ggplot2)
library(forecast)
library(astsa)
library(xts)
library(tseries)
library(fpp2)
library(fma)
library(lubridate)
library(TSstudio)
library(quantmod)
library(tidyquant)
library(plotly)
library(readr)
library(dplyr)
library(vars)
library(patchwork)
library(kableExtra)
library(gridExtra)

theme_set(theme_minimal(base_size = 12))

all_adv_files <- list.files("data/adv_stats", pattern = "*.csv", full.names = TRUE)

all_adv_data <- map_df(all_adv_files, function(file) {
    season_str <- str_extract(basename(file), "\\d{4}-\\d{2}")
    season_year <- as.numeric(str_sub(season_str, 1, 4)) + 1
    df <- read_csv(file, show_col_types = FALSE)
    df$Season <- season_year
    return(df)
})

league_avg <- all_adv_data %>%
    group_by(Season) %>%
    summarise(
        ORtg = mean(`Unnamed: 10_level_0_ORtg`, na.rm = TRUE),
        DRtg = mean(`Unnamed: 11_level_0_DRtg`, na.rm = TRUE),
        Pace = mean(`Unnamed: 13_level_0_Pace`, na.rm = TRUE),
        `3PAr` = mean(`Unnamed: 15_level_0_3PAr`, na.rm = TRUE),
        `TS%` = mean(`Unnamed: 16_level_0_TS%`, na.rm = TRUE),
        `eFG%` = mean(`Offense Four Factors_eFG%`, na.rm = TRUE),
        Total_Attendance = sum(`Unnamed: 29_level_0_Attend.`, na.rm = TRUE),
        .groups = "drop"
    )

# Create COVID dummy variable
league_avg <- league_avg %>%
    mutate(COVID_Dummy = ifelse(Season %in% c(2020, 2021), 1, 0))
```

---

# ARIMAX/SARIMAX Models

## Shot Selection & Efficiency (ARIMAX)

- **Response Variable**: `ORtg` (Offensive Rating)
- **Exogenous Variables**: `3PAr` (3-Point Attempt Rate), `TS%` (True Shooting %)

This model addresses whether shooting more 3s and shooting accuracy explain offensive efficiency gains. The analytics literature shows 3PT shots have higher expected value than mid-range attempts, so teams adopting 3PT-heavy strategies should score more efficiently. `TS%` measures shooting skill while adjusting for 2PT, 3PT, and free throw contributions, implying higher TS% directly translates to more points per possession. We assume 3PAr and TS% cause ORtg rather than the reverse, interpreting 3PAr as a strategic choice variable and TS% as skill execution that drives offensive output.

::: {.panel-tabset}

## EDA & Correlation

```{r arimax-eda, warning=FALSE, message=FALSE, fig.width=12, fig.height=8}
ts_ortg <- ts(league_avg$ORtg, start = 1980, frequency = 1)
ts_3par <- ts(league_avg$`3PAr`, start = 1980, frequency = 1)
ts_tspct <- ts(league_avg$`TS%`, start = 1980, frequency = 1)

p1 <- autoplot(ts_ortg) + labs(title = "Offensive Rating (ORtg)", y = "ORtg") + theme_minimal()
p2 <- autoplot(ts_3par) + labs(title = "3-Point Attempt Rate (3PAr)", y = "3PAr") + theme_minimal()
p3 <- autoplot(ts_tspct) + labs(title = "True Shooting % (TS%)", y = "TS%") + theme_minimal()

p1 / p2 / p3
```

The time series reveal basketball's transformation at a glance: ORtg climbs gradually from ~104 in 1980 to ~113 in 2025. Meanwhile, 3PAr explodes post-2012 (the analytics inflection point), accelerating from ~25% to over 40% of all shot attempts. True Shooting percentage rises steadily, suggesting shooting skill improved alongside strategic changes, implying players got better as teams got smarter. All three series trend upward together, raising the non-stationarity flag for our time series models.

```{r arimax-correlation, warning=FALSE, message=FALSE}
# Correlation analysis
cor_data <- league_avg %>% dplyr::select(ORtg, `3PAr`, `TS%`)
print(round(cor(cor_data, use = "complete.obs"), 3))
```

**Correlation Matrix:**

```{r correlation-matrix-viz, echo=FALSE, message=FALSE, fig.width=8, fig.height=6}
cor_matrix <- cor(cor_data, use = "complete.obs")

cor_long <- cor_matrix %>%
    as.data.frame() %>%
    rownames_to_column("var1") %>%
    pivot_longer(-var1, names_to = "var2", values_to = "correlation")

ggplot(cor_long, aes(x = var1, y = var2, fill = correlation)) +
    geom_tile(color = "white", linewidth = 1.5) +
    geom_text(aes(label = round(correlation, 3)),
              color = "white", size = 6, fontface = "bold") +
    scale_fill_gradient2(
        low = "#FED976",
        mid = "#006bb6",
        high = "#08306B",
        midpoint = 0.75,
        limits = c(0, 1),
        name = "Correlation"
    ) +
    labs(
        title = "Correlation Matrix: Offensive Efficiency Variables",
        subtitle = "ORtg, 3PAr, and TS%",
        x = NULL,
        y = NULL
    ) +
    theme_minimal(base_size = 14) +
    theme(
        plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5),
        axis.text.x = element_text(angle = 45, hjust = 1),
        panel.grid = element_blank()
    ) +
    coord_fixed()

cor_ortg_3par <- round(cor(league_avg$ORtg, league_avg$`3PAr`), 3)
cor_ortg_ts <- round(cor(league_avg$ORtg, league_avg$`TS%`), 3)
cor_3par_ts <- round(cor(league_avg$`3PAr`, league_avg$`TS%`), 3)
```

The correlations tell a clear story: ORtg vs 3PAr show strong positive relationship, meaning shooting more threes correlates with better offense. ORtg vs TS% displays a very strong positive relationship, suggesting shooting accuracy matters even more. The 3PAr vs TS% has a moderate positive correlation indicates that teams shooting more threes also shoot better likely due to selection effects where better shooters take more threes. Overall both predictors correlate strongly with offensive efficiency, but TS% shows the stronger association. The lesson: strategy matters, but execution matters more.

## Model Fitting

```{r arimax-auto, warning=FALSE, message=FALSE}
xreg_matrix <- cbind(
    `3PAr` = ts_3par,
    `TS%` = ts_tspct
)

arimax_auto <- auto.arima(ts_ortg,
    xreg = xreg_matrix, seasonal = FALSE,
    stepwise = FALSE, approximation = FALSE
)

cat("Selected model:\n")
print(arimax_auto)

cat("\n\nModel Summary:\n")
summary(arimax_auto)
```

**Model Diagnostics**:

```{r arimax-auto-diagnostics, warning=FALSE, message=FALSE, fig.width=12, fig.height=10}
checkresiduals(arimax_auto)

# Ljung-Box test
ljung_auto <- Box.test(arimax_auto$residuals, lag = 10, type = "Ljung-Box")
```


```{r arimax-manual-lm, warning=FALSE, message=FALSE}
# Create data frame
df_reg <- data.frame(
    ORtg = as.numeric(ts_ortg),
    PAr3 = as.numeric(ts_3par),
    TSpct = as.numeric(ts_tspct)
)

# Fit regression
lm_model <- lm(ORtg ~ PAr3 + TSpct, data = df_reg)

cat("Linear Regression Results:\n")
summary(lm_model)
```

```{r regression-narrative-setup, echo=FALSE, message=FALSE}
beta_intercept <- round(coef(lm_model)["(Intercept)"], 2)
beta_3par <- round(coef(lm_model)["PAr3"], 2)
beta_ts <- round(coef(lm_model)["TSpct"], 2)
```

The regression equation reveals the mathematical relationship:

$$
\text{ORtg} = `r beta_intercept` + `r beta_3par` \times \text{3PAr} + `r beta_ts` \times \text{TS\%}
$$

Here's what this means on the court: a 1 percentage point increase in 3PAr leads to an ORtg increase of **`r beta_3par` points per 100 possessions** (moving from 30% to 31% of shots being threes adds `r beta_3par` points to offensive rating). Similarly, a 1 percentage point increase in TS% leads to an ORtg increase of **`r beta_ts` points per 100 possessions** (improving from 55% to 56% True Shooting adds `r beta_ts` points), emphasising that shooting accuracy has a stronger impact than shot selection.

```{r arimax-manual-arima, warning=FALSE, message=FALSE}
lm_residuals <- ts(residuals(lm_model), start = 1980, frequency = 1)

# Plot residuals
autoplot(lm_residuals) +
    labs(title = "Regression Residuals", y = "Residuals") +
    theme_minimal()

# Fit ARIMA to residuals
arima_resid <- auto.arima(lm_residuals, seasonal = FALSE)

cat("\nARIMA model for residuals:\n")
print(arima_resid)

checkresiduals(arima_resid)
```


```{r arimax-manual-final, warning=FALSE, message=FALSE}
arima_order <- arimaorder(arima_resid)

arimax_manual <- Arima(ts_ortg,
    order = c(arima_order[1], arima_order[2], arima_order[3]),
    xreg = xreg_matrix
)

print(arimax_manual)
print(coef(arimax_manual))
```

## Cross-Validation

```{r arimax-cv, warning=FALSE, message=FALSE, fig.width=12, fig.height=6}
train_end <- 2019
test_start <- 2020

# Split data
train_ortg <- window(ts_ortg, end = train_end)
train_3par <- window(ts_3par, end = train_end)
train_tspct <- window(ts_tspct, end = train_end)

test_ortg <- window(ts_ortg, start = test_start)
test_3par <- window(ts_3par, start = test_start)
test_tspct <- window(ts_tspct, start = test_start)

h <- length(test_ortg)

# Prepare xreg for train/test
xreg_train <- cbind(`3PAr` = train_3par, `TS%` = train_tspct)
xreg_test <- cbind(`3PAr` = test_3par, `TS%` = test_tspct)

# Model 1: auto.arima() method
fit_auto <- auto.arima(train_ortg, xreg = xreg_train, seasonal = FALSE)

# Model 2: Manual method
fit_manual <- Arima(train_ortg,
    order = c(arima_order[1], arima_order[2], arima_order[3]),
    xreg = xreg_train
)

# Model 3: Simple ARIMA without exogenous (benchmark)
fit_benchmark <- auto.arima(train_ortg, seasonal = FALSE)

# Generate forecasts
fc_auto <- forecast(fit_auto, xreg = xreg_test, h = h)
fc_manual <- forecast(fit_manual, xreg = xreg_test, h = h)
fc_benchmark <- forecast(fit_benchmark, h = h)

# Calculate accuracy
acc_auto <- accuracy(fc_auto, test_ortg)[2, c("RMSE", "MAE", "MAPE")]
acc_manual <- accuracy(fc_manual, test_ortg)[2, c("RMSE", "MAE", "MAPE")]
acc_benchmark <- accuracy(fc_benchmark, test_ortg)[2, c("RMSE", "MAE", "MAPE")]

# Display results
cat("\n=== CROSS-VALIDATION RESULTS (Test Set: 2020-2024) ===\n\n")
cv_results <- data.frame(
    Model = c("ARIMAX", "ARIMAX", "ARIMA"),
    RMSE = c(acc_auto["RMSE"], acc_manual["RMSE"], acc_benchmark["RMSE"]),
    MAE = c(acc_auto["MAE"], acc_manual["MAE"], acc_benchmark["MAE"]),
    MAPE = c(acc_auto["MAPE"], acc_manual["MAPE"], acc_benchmark["MAPE"])
)

# Display formatted table
kable(cv_results,
    format = "html",
    digits = 3,
    caption = "Cross-Validation Results: ORtg Models",
    col.names = c("Model", "RMSE", "MAE", "MAPE")
) %>%
    kable_styling(
        full_width = FALSE,
        bootstrap_options = c("striped", "hover", "condensed", "responsive")
    ) %>%
    row_spec(which.min(cv_results$RMSE), bold = TRUE, color = "white", background = "#006bb6")

# Determine best model
best_idx <- which.min(cv_results$RMSE)
cat("\n\n*** BEST MODEL: ", cv_results$Model[best_idx], " ***\n")
cat("RMSE =", round(cv_results$RMSE[best_idx], 3), "\n")

# Select best model based on CV
if (cv_results$Model[best_idx] == "ARIMAX (auto.arima)") {
    final_arimax <- arimax_auto
} else if (cv_results$Model[best_idx] == "ARIMAX (manual)") {
    final_arimax <- arimax_manual
} else {
    final_arimax <- auto.arima(ts_ortg, seasonal = FALSE)
}
```

```{r cv-interpretation-setup, echo=FALSE, message=FALSE}
best_model_name <- cv_results$Model[best_idx]
best_rmse <- round(cv_results$RMSE[best_idx], 3)
arimax_better <- grepl("ARIMAX", best_model_name)
```

**What Cross-Validation Reveals**

```{r echo=FALSE, results='asis'}
if (arimax_better) {
    cat("The winner is **", best_model_name, "** with RMSE = ", best_rmse, ". This confirms that **exogenous variables add real predictive power**.\n\nThe analytics revolution is quantifiable: shot selection and shooting skill aren't just correlated with efficiency, they *predict* it.", sep = "")
} else {
    cat("Surprisingly, the plain **ARIMA model** (no exogenous variables) won with RMSE = ", best_rmse, ". This suggests that ORtg's temporal structure—its own past values—contains enough information to forecast the future.\n\nWhy? High multicollinearity: 3PAr, TS%, and ORtg all trend together so strongly that including them as separate predictors doesn't improve forecasts. The ARIMA model implicitly captures their co-evolution through autocorrelation.", sep = "")
}
```

## Final Model & Equation

```{r arimax-final-model, warning=FALSE, message=FALSE}
# Refit winning model on full data
if ("xreg" %in% names(final_arimax$call)) {
    final_fit <- Arima(ts_ortg,
        order = arimaorder(final_arimax)[1:3],
        xreg = xreg_matrix
    )
} else {
    final_fit <- Arima(ts_ortg, order = arimaorder(final_arimax)[1:3])
}

print(summary(final_fit))

# Also fit ARIMAX model for demonstration
cat("\n\n=== For Comparison: ARIMAX Model with Exogenous Variables ===\n")
final_fit_arimax <- Arima(ts_ortg,
    order = arimaorder(arimax_auto)[1:3],
    xreg = xreg_matrix
)
print(summary(final_fit_arimax))
```

**Model Equations:**

### Winning Model (Selected by Cross-Validation)

```{r winning-equation, echo=FALSE, results='asis'}
arima_part <- arimaorder(final_fit)

if ("xreg" %in% names(final_fit$call)) {
    coefs <- coef(final_fit)

    # Extract coefficients
    ar_coefs <- coefs[grep("^ar", names(coefs))]
    ma_coefs <- coefs[grep("^ma", names(coefs))]
    xreg_coefs <- coefs[grep("^3PAr|^TS%", names(coefs))]

    cat("ARIMAX(", arima_part[1], ",", arima_part[2], ",", arima_part[3], ") model:\n\n", sep = "")

    # Regression component
    cat("$$\n")
    cat("\\text{ORtg}_t = \\beta_0 + \\beta_1 \\cdot \\text{3PAr}_t + \\beta_2 \\cdot \\text{TS\\%}_t + N_t\n")
    cat("$$\n\n")

    cat("where:\n\n")
    if (length(xreg_coefs) >= 1) cat("- $\\beta_1 =", round(xreg_coefs[1], 3), "$\n")
    if (length(xreg_coefs) >= 2) cat("- $\\beta_2 =", round(xreg_coefs[2], 3), "$\n")

    # ARIMA component for N_t
    cat("\n$N_t$ follows ARIMA(", arima_part[1], ",", arima_part[2], ",", arima_part[3], "):\n\n", sep = "")

    cat("$$\n")
    if (arima_part[2] == 1) {
        cat("(1 - B)^{", arima_part[2], "} N_t = ", sep = "")
    } else if (arima_part[2] > 1) {
        cat("(1 - B)^{", arima_part[2], "} N_t = ", sep = "")
    } else {
        cat("N_t = ")
    }

    # Add AR terms
    if (length(ar_coefs) > 0) {
        ar_terms <- paste0(round(ar_coefs, 3), " N_{t-", 1:length(ar_coefs), "}")
        cat(paste(ar_terms, collapse = " + "), " + ")
    }

    # Add MA terms
    if (length(ma_coefs) > 0) {
        ma_terms <- paste0(round(ma_coefs, 3), " \\epsilon_{t-", 1:length(ma_coefs), "}")
        cat(paste(ma_terms, collapse = " + "), " + ")
    }

    cat("\\epsilon_t\n")
    cat("$$\n\n")

    cat("where $B$ is the backshift operator and $\\epsilon_t$ is white noise.\n")
} else {
    cat("ARIMA(", arima_part[1], ",", arima_part[2], ",", arima_part[3], ") model:\n\n", sep = "")
    cat("$$\n")
    cat("(1 - B) \\text{ORtg}_t = \\epsilon_t\n")
    cat("$$\n\n")
}
```

## Forecasting

```{r arimax-forecast, warning=FALSE, message=FALSE, fig.width=12, fig.height=7}
if ("xreg" %in% names(final_fit$call)) {
    # Forecast 3PAr and TS%
    fc_3par <- forecast(auto.arima(ts_3par), h = 5)
    fc_tspct <- forecast(auto.arima(ts_tspct), h = 5)

    # Create future xreg matrix
    xreg_future <- cbind(
        `3PAr` = fc_3par$mean,
        `TS%` = fc_tspct$mean
    )

    # Forecast ORtg
    fc_final <- forecast(final_fit, xreg = xreg_future, h = 5)
} else {
    fc_final <- forecast(final_fit, h = 5)
}

# Plot forecast
autoplot(fc_final) +
    labs(
        title = "ORtg Forecast: 2026-2030 (ARIMAX Model)",
        subtitle = paste0("Model: ", paste0(final_fit), " | Using forecasted 3PAr and TS% as exogenous inputs"),
        x = "Year",
        y = "Offensive Rating (Points per 100 Possessions)"
    ) +
    theme_minimal(base_size = 12) +
    theme(plot.subtitle = element_text(size = 9))

cat("\nPoint Forecasts:\n")
print(fc_final$mean)

cat("\n\n80% Prediction Interval:\n")
print(fc_final$lower[, 1])
print(fc_final$upper[, 1])
```

## Interpretation

```{r arimax-commentary-setup, warning=FALSE, message=FALSE, echo=FALSE}
has_xreg <- "xreg" %in% names(final_fit$call)
test_rmse <- cv_results$RMSE[best_idx]
test_mape <- cv_results$MAPE[best_idx]
```

The ARIMAX model tells a compelling story about modern basketball's transformation.

**The Analytics Advantage**

```{r echo=FALSE, results='asis'}
if (has_xreg) {
    cat("Our analysis confirms what front offices discovered in 2012: both shot selection (3PAr) and shooting skill (TS%) significantly predict offensive efficiency. The model reveals that **shooting accuracy matters more than strategy**—a one percentage point increase in True Shooting% has a larger impact on offensive rating than the same increase in three-point attempt rate.\n\nThis ARIMAX model outperformed plain ARIMA, confirming that exogenous variables add real predictive power. Shot selection and skill improve ORtg forecasts beyond what temporal patterns alone can capture. Including the right exogenous variables isn't just theoretically justified—it's empirically beneficial. This validates the Houston Rockets' famous insight: it's not just about *shooting* threes, it's about *making* them.\n")
} else {
    cat("Interestingly, adding exogenous variables did not improve forecast accuracy in cross-validation. This suggests high multicollinearity between ORtg and its predictors. \n")
}
```

**Forecast Performance**

The model achieved a test RMSE of **`r round(test_rmse, 2)` points per 100 possessions**, corresponding to approximately **`r round(test_mape, 1)`%** average error. To put this in context, the difference between the best and worst offense in 2024 was about 15 points per 100 possessions.

**What the Future Holds**

```{r echo=FALSE, results='asis'}
if (has_xreg) {
    cat("The forecast projects offensive efficiency will continue climbing through 2030, driven by relentless growth in both three-point volume and shooting accuracy. This assumes the analytics revolution hasn't plateaued—that teams will keep pushing boundaries, that shooters will keep improving, and that defenses won't find a systematic counter-strategy.\n\nThe widening prediction intervals tell us the model is honest about uncertainty: forecasting 2030 from 2025 data means predicting the unpredictable.\n")
} else {
    cat("Forecasts rely purely on historical ORtg patterns, capturing the league's 45-year trajectory toward more efficient offense. The trend is clear, but the mechanism remains in the residuals.\n")
}
```

**The Basketball Insight**

Here's what matters for teams: offensive efficiency isn't magic, it's a function of **where you shoot** (3PAr) and **how well you shoot** (TS%). The model equation makes this quantitative:

$$
\text{ORtg}_t = \beta_0 + \beta_1 \times \text{3PAr}_t + \beta_2 \times \text{TS\%}_t + N_t
$$

where $N_t$ captures autocorrelated shocks (momentum, injuries, schedule strength).

Teams have two levers:

1. **Strategic**: Shoot more threes (reallocate shot distribution)
2. **Developmental**: Improve shooting accuracy (player development, coaching)

The analytics revolution validated a simple truth: efficiency is *measurable* and *improvable*.

:::

## COVID Impact on Attendance (ARIMAX with Intervention)

- **Response Variable**: `Total_Attendance`
- **Exogenous Variables**: `ORtg`, `Pace`, `COVID_Dummy` (pulse intervention)

The model includes three key variables: ORtg captures how better offensive performance leads to more entertaining games and higher attendance; Pace reflects whether faster games attract more fans; and the COVID_Dummy captures the structural break in 2020-2021 from empty arenas and capacity restrictions.

::: {.panel-tabset}

## EDA

```{r attendance-eda, warning=FALSE, message=FALSE, fig.width=12, fig.height=8}
league_post2000 <- league_avg %>% filter(Season >= 2000)

ts_attend <- ts(league_post2000$Total_Attendance, start = 2000, frequency = 1)
ts_ortg_sub <- ts(league_post2000$ORtg, start = 2000, frequency = 1)
ts_pace_sub <- ts(league_post2000$Pace, start = 2000, frequency = 1)
ts_covid <- ts(league_post2000$COVID_Dummy, start = 2000, frequency = 1)

p1 <- autoplot(ts_attend / 1e6) +
    labs(title = "Total NBA Attendance", y = "Attendance (Millions)") +
    geom_vline(xintercept = 2020, linetype = "dashed", color = "red") +
    annotate("text", x = 2020, y = 23, label = "COVID-19", color = "red", hjust = -0.1) +
    theme_minimal()

p2 <- autoplot(ts_ortg_sub) +
    labs(title = "Offensive Rating", y = "ORtg") +
    theme_minimal()

p3 <- autoplot(ts_pace_sub) +
    labs(title = "Pace", y = "Pace") +
    theme_minimal()

p1 / (p2 | p3)
```

The attendance plot tells a stark before-and-after story: from 2000-2019, the NBA showed remarkable stability around 22 million attendees per season as a reliable entertainment product. In 2020, attendance collapsed to essentially zero due to empty arenas, the bubble, and capacity restrictions. From 2021-2025, gradual recovery began but with visible scars. Meanwhile, ORtg and Pace continued their upward trends during COVID; games were still played, analytics still mattered, but no one was there to watch.

## Model Fitting

```{r attendance-auto, warning=FALSE, message=FALSE}
# Prepare exogenous matrix
xreg_attend <- cbind(
    ORtg = ts_ortg_sub,
    Pace = ts_pace_sub,
    COVID = ts_covid
)

# auto.arima() method
arimax_attend_auto <- auto.arima(ts_attend, xreg = xreg_attend, seasonal = FALSE)

print(arimax_attend_auto)

# Diagnostics
checkresiduals(arimax_attend_auto)
```

```{r attendance-manual, warning=FALSE, message=FALSE}
# Manual method: Regression + ARIMA
df_attend <- data.frame(
    Attendance = as.numeric(ts_attend),
    ORtg = as.numeric(ts_ortg_sub),
    Pace = as.numeric(ts_pace_sub),
    COVID = as.numeric(ts_covid)
)

lm_attend <- lm(Attendance ~ ORtg + Pace + COVID, data = df_attend)

cat("Regression Results:\n")
summary(lm_attend)
```

```{r attendance-reg-narrative-setup, echo=FALSE, message=FALSE}
covid_coef <- round(coef(lm_attend)["COVID"], 0)
covid_impact_millions <- round(abs(coef(lm_attend)["COVID"]) / 1e6, 1)
```

The regression reveals COVID's devastating impact in stark numerical terms:

$$
\beta_{\text{COVID}} = `r format(covid_coef, big.mark=",")`
$$

The pandemic reduced attendance by approximately **`r covid_impact_millions` million attendees** during 2020-2021. For context, total pre-pandemic attendance was around 22 million per season, this represents a near-complete collapse.

```{r echo=FALSE}
# Fit ARIMA to residuals
resid_attend <- ts(residuals(lm_attend), start = 2000, frequency = 1)
arima_resid_attend <- auto.arima(resid_attend, seasonal = FALSE)

cat("ARIMA model for residuals:\n")
print(arima_resid_attend)

# Combined manual model
arimax_attend_manual <- Arima(ts_attend,
    order = arimaorder(arima_resid_attend)[1:3],
    xreg = xreg_attend
)

print(arimax_attend_manual)
```

## Cross-Validation

```{r attendance-cv, warning=FALSE, message=FALSE, fig.width=10, fig.height=6}
train_end_att <- 2018
test_start_att <- 2019

train_attend <- window(ts_attend, end = train_end_att)
train_ortg_a <- window(ts_ortg_sub, end = train_end_att)
train_pace_a <- window(ts_pace_sub, end = train_end_att)
train_covid_a <- window(ts_covid, end = train_end_att)

test_attend <- window(ts_attend, start = test_start_att)
test_ortg_a <- window(ts_ortg_sub, start = test_start_att)
test_pace_a <- window(ts_pace_sub, start = test_start_att)
test_covid_a <- window(ts_covid, start = test_start_att)

h_att <- length(test_attend)

xreg_train_att <- cbind(ORtg = train_ortg_a, Pace = train_pace_a, COVID = train_covid_a)
xreg_test_att <- cbind(ORtg = test_ortg_a, Pace = test_pace_a, COVID = test_covid_a)


# Model 1: auto.arima() - use simpler constraints for small dataset
fit_auto_att <- tryCatch(
    {
        auto.arima(train_attend,
            xreg = xreg_train_att, seasonal = FALSE,
            max.p = 2, max.q = 2, max.d = 1, stepwise = TRUE
        )
    },
    error = function(e) {
        xreg_no_covid <- cbind(ORtg = train_ortg_a, Pace = train_pace_a)
        auto.arima(train_attend,
            xreg = xreg_no_covid, seasonal = FALSE,
            max.p = 2, max.q = 2, max.d = 1
        )
    }
)

# Model 2: Manual method - use simpler order if needed
fit_manual_att <- tryCatch(
    {
        Arima(train_attend,
            order = arimaorder(arima_resid_attend)[1:3],
            xreg = xreg_train_att
        )
    },
    error = function(e) {
        xreg_no_covid <- cbind(ORtg = train_ortg_a, Pace = train_pace_a)
        Arima(train_attend, order = c(0, 1, 0), xreg = xreg_no_covid)
    }
)

# Model 3: Benchmark
fit_bench_att <- auto.arima(train_attend, seasonal = FALSE, max.p = 2, max.q = 2)

# Forecasts - handle different xreg structures
if ("COVID" %in% names(coef(fit_auto_att))) {
    fc_auto_att <- forecast(fit_auto_att, xreg = xreg_test_att, h = h_att)
} else {
    xreg_test_no_covid <- cbind(ORtg = test_ortg_a, Pace = test_pace_a)
    fc_auto_att <- forecast(fit_auto_att, xreg = xreg_test_no_covid, h = h_att)
}

if ("COVID" %in% names(coef(fit_manual_att))) {
    fc_manual_att <- forecast(fit_manual_att, xreg = xreg_test_att, h = h_att)
} else {
    xreg_test_no_covid <- cbind(ORtg = test_ortg_a, Pace = test_pace_a)
    fc_manual_att <- forecast(fit_manual_att, xreg = xreg_test_no_covid, h = h_att)
}

fc_bench_att <- forecast(fit_bench_att, h = h_att)

# Accuracy
acc_auto_att <- accuracy(fc_auto_att, test_attend)[2, c("RMSE", "MAE", "MAPE")]
acc_manual_att <- accuracy(fc_manual_att, test_attend)[2, c("RMSE", "MAE", "MAPE")]
acc_bench_att <- accuracy(fc_bench_att, test_attend)[2, c("RMSE", "MAE", "MAPE")]

cat("\n=== ATTENDANCE MODEL CROSS-VALIDATION (Test: 2019-2024) ===\n\n")
cv_att_results <- data.frame(
    Model = c("ARIMAX", "ARIMAX", "ARIMA"),
    RMSE = c(acc_auto_att["RMSE"], acc_manual_att["RMSE"], acc_bench_att["RMSE"]),
    MAE = c(acc_auto_att["MAE"], acc_manual_att["MAE"], acc_bench_att["MAE"]),
    MAPE = c(acc_auto_att["MAPE"], acc_manual_att["MAPE"], acc_bench_att["MAPE"])
)

# Display formatted table with RMSE in millions
cv_att_display <- cv_att_results
cv_att_display$RMSE <- cv_att_display$RMSE / 1e6
cv_att_display$MAE <- cv_att_display$MAE / 1e6

kable(cv_att_display,
    format = "html",
    digits = 3,
    caption = "Cross-Validation Results: Attendance Models (Test Set: 2019-2024)",
    col.names = c("Model", "RMSE (Millions)", "MAE (Millions)", "MAPE (%)")
) %>%
    kable_styling(
        full_width = FALSE,
        bootstrap_options = c("striped", "hover", "condensed", "responsive")
    ) %>%
    row_spec(which.min(cv_att_results$RMSE), bold = TRUE, color = "white", background = "#006bb6")

best_idx_att <- which.min(cv_att_results$RMSE)
cat("\n*** BEST MODEL: ", cv_att_results$Model[best_idx_att], "***\n")
```

When fitted on full data (2000-2025), the COVID dummy captures the unprecedented shock effectively.

## Final Model & Interpretation

```{r attendance-final, warning=FALSE, message=FALSE, fig.width=12, fig.height=6}
# Refit best model on full data
if (cv_att_results$Model[best_idx_att] == "ARIMAX (auto)") {
    final_attend <- Arima(ts_attend,
        order = arimaorder(arimax_attend_auto)[1:3],
        xreg = xreg_attend
    )
} else if (cv_att_results$Model[best_idx_att] == "ARIMAX (manual)") {
    final_attend <- arimax_attend_manual
} else {
    final_attend <- auto.arima(ts_attend, seasonal = FALSE)
}

cat("Final Attendance Model:\n")
print(summary(final_attend))

# Forecast
fc_ortg_fut <- forecast(auto.arima(ts_ortg_sub), h = 5)
fc_pace_fut <- forecast(auto.arima(ts_pace_sub), h = 5)

# Create xreg based on what variables the model has
if ("COVID" %in% names(coef(final_attend))) {
    xreg_future_att <- cbind(
        ORtg = fc_ortg_fut$mean,
        Pace = fc_pace_fut$mean,
        COVID = rep(0, 5)
    )
} else {
    xreg_future_att <- cbind(
        ORtg = fc_ortg_fut$mean,
        Pace = fc_pace_fut$mean
    )
}

fc_attend_final <- forecast(final_attend, xreg = xreg_future_att, h = 5)

autoplot(fc_attend_final) +
    labs(
        title = "NBA Attendance Forecast: 2026-2030",
        x = "Year",
        y = "Total Attendance (Millions)"
    ) +
    scale_y_continuous(labels = function(x) x / 1e6) +
    theme_minimal()

```

```{r attendance-commentary-setup, echo=FALSE, message=FALSE}
has_covid <- "COVID" %in% names(coef(final_attend))
has_ortg <- "ORtg" %in% names(coef(final_attend))
if (has_covid) {
    covid_impact <- coef(final_attend)["COVID"] / 1e6
}
```

```{r echo=FALSE, results='asis'}
if (has_covid) {
    cat("March 2020 left an indelible mark in the data. The COVID dummy variable carries a coefficient of **", round(covid_impact, 2), " million attendees**—representing nearly a 90% collapse in arena attendance during the 2020-2021 seasons.\n\nThis wasn't gradual decline. It was instantaneous erasure. Intervention analysis quantifies what everyone witnessed: the pandemic reduced attendance by ~20 million (near-complete collapse), this shock was structural and unpredictable from pre-2020 trends (no amount of historical data could forecast a global pandemic), and the dummy variable approach cleanly separates the COVID effect from underlying trends. Including this dummy variable wasn't just statistically beneficial—it was necessary to capture a shock that no amount of historical data could have predicted. This serves as a natural experiment demonstrating how external shocks disrupt time series patterns.\n", sep = "")
} else {
    cat("Here's where cross-validation reveals a hard truth about forecasting: the COVID dummy was *all zeros* in our training data (2000-2018) because the pandemic didn't exist yet. The model couldn't learn what it hadn't seen.\n\nWhen the test period arrived (2019-2024), actual attendance plummeted by 90% in 2020. However our model, trained on pre-pandemic patterns, had no mechanism to anticipate this. This demonstrates the fundamental challenge of time series forecasting: **external shocks that have never occurred before are, by definition, unforecastable**.")
}
```

```{r echo=FALSE, results='asis'}
if (has_ortg) {
    cat("Beyond COVID's overwhelming impact, the model detects subtler forces: offensive rating and pace do influence attendance, but their effects are small compared to the pandemic shock. This tells us that **fans care more about whether games happen** than about how exciting those games are. A boring game with 18,000 fans beats an offensive shootout with zero.\n\nAttendance is sticky—fans buy season tickets, form habits, make plans. Game quality matters at the margin (a 115 ORtg season might draw slightly more than a 105 ORtg season), but structural factors like arena access, pricing, and health safety dominate.\n")
} else {
    cat("The model relies purely on time-series patterns, revealing that attendance follows its own momentum: yesterday's crowds predict tomorrow's. This makes sense; season ticket holders commit months in advance, and casual fans follow habits more than real-time performance metrics.")
}
```
:::

---

# VAR (Vector Autoregression) Models

## Efficiency Drivers (VAR)

**Variables**: `ORtg`, `Pace`, `3PAr`

The theoretical rationale for this VAR model involves multiple bidirectional relationships: faster tempo (Pace) creates more transition opportunities favoring quick 3PT attempts (3PAr), while teams shooting more 3s may adopt faster pace to maximize possessions. Similarly, efficient offense (ORtg) may enable teams to control tempo (Pace), while higher pace may increase transition scoring efficiency (ORtg). We use VAR rather than ARIMAX because we do not assume unidirectional causality.

::: {.panel-tabset}

## EDA & Stationarity

```{r var-eda, warning=FALSE, message=FALSE, fig.width=12, fig.height=8}
# Create VAR dataset
var_data <- ts(league_avg %>% dplyr::select(ORtg, Pace, `3PAr`),
    start = 1980, frequency = 1
)

# Plot all series
autoplot(var_data, facets = TRUE) +
    labs(
        title = "VAR Variables: ORtg, Pace, 3PAr (1980-2025)",
        x = "Year", y = "Value"
    ) +
    theme_minimal()

cat("Summary Statistics:\n")
summary(var_data)
```

```{r var-stationarity, warning=FALSE, message=FALSE}
# ADF tests for each series
adf_ortg_var <- adf.test(var_data[, "ORtg"])
adf_pace_var <- adf.test(var_data[, "Pace"])
adf_3par_var <- adf.test(var_data[, "3PAr"])

cat(
    "ORtg: ADF p-value =", round(adf_ortg_var$p.value, 4),
    ifelse(adf_ortg_var$p.value < 0.05, "(stationary)", "(non-stationary)"), "\n"
)
cat(
    "Pace: ADF p-value =", round(adf_pace_var$p.value, 4),
    ifelse(adf_pace_var$p.value < 0.05, "(stationary)", "(non-stationary)"), "\n"
)
cat(
    "3PAr: ADF p-value =", round(adf_3par_var$p.value, 4),
    ifelse(adf_3par_var$p.value < 0.05, "(stationary)", "(non-stationary)"), "\n\n"
)

# Difference if non-stationary
if (adf_ortg_var$p.value > 0.05 | adf_pace_var$p.value > 0.05 | adf_3par_var$p.value > 0.05) {
    var_data_diff <- diff(var_data)

    # Test differenced data
    adf_ortg_diff <- adf.test(var_data_diff[, "ORtg"])
    adf_pace_diff <- adf.test(var_data_diff[, "Pace"])
    adf_3par_diff <- adf.test(var_data_diff[, "3PAr"])

    cat("\nAfter first-differencing:\n")
    cat("ORtg: ADF p-value =", round(adf_ortg_diff$p.value, 4), "\n")
    cat("Pace: ADF p-value =", round(adf_pace_diff$p.value, 4), "\n")
    cat("3PAr: ADF p-value =", round(adf_3par_diff$p.value, 4), "\n")

    if (adf_ortg_diff$p.value < 0.05 & adf_pace_diff$p.value < 0.05 & adf_3par_diff$p.value < 0.05) {
        var_data_final <- var_data_diff
        differenced <- TRUE
    } else {
        var_data_final <- var_data_diff
        differenced <- TRUE
    }
} else {
    var_data_final <- var_data
    differenced <- FALSE
}
```

## Model Selection & Fitting

```{r var-select, warning=FALSE, message=FALSE}
# Determine optimal lag order
var_select <- VARselect(var_data_final, lag.max = 8, type = "const")

print(var_select$selection)
print(var_select$criteria)

# Fit models with different lag orders
lags_to_fit <- unique(var_select$selection[1:3])

# Ensure we have at least one lag to fit
if (length(lags_to_fit) == 0 || any(is.na(lags_to_fit))) {
    lags_to_fit <- 1
}

cat("\nFitting VAR models with p =", paste(lags_to_fit, collapse = ", "), "\n")

var_models <- list()
for (p in lags_to_fit) {
    var_models[[paste0("VAR_", p)]] <- VAR(var_data_final, p = p, type = "const")
}
```

```{r var-summaries, warning=FALSE, message=FALSE}
for (name in names(var_models)) {
    cat("========================================\n")
    cat(name, "Summary:\n")
    cat("========================================\n\n")
    print(summary(var_models[[name]]))
    cat("\n\n")
}
```


## Cross-Validation

```{r var-cv, warning=FALSE, message=FALSE, fig.width=10, fig.height=6}
# Split: Train 1980-2019, Test 2020-2024
train_end_var <- 2019

if (differenced) {
    train_var <- window(var_data_final, end = train_end_var)
    test_var <- window(var_data_final, start = train_end_var + 1)
} else {
    train_var <- window(var_data_final, end = train_end_var)
    test_var <- window(var_data_final, start = train_end_var + 1)
}

h_var <- nrow(test_var)

# Fit VAR models on training data with error handling
var_train_models <- list()
for (p in lags_to_fit) {
    model <- tryCatch(
        {
            VAR(train_var, p = p, type = "const")
        },
        error = function(e) {
            if (p > 1) {
                VAR(train_var, p = 1, type = "const")
            } else {
                NULL
            }
        }
    )
    if (!is.null(model)) {
        var_train_models[[paste0("VAR_", p)]] <- model
    }
}

# Generate forecasts
rmse_results <- data.frame()

cat("Evaluating", length(var_train_models), "VAR model(s)\n")

for (name in names(var_train_models)) {
    fc <- tryCatch(
        {
            predict(var_train_models[[name]], n.ahead = h_var)
        },
        error = function(e) {
            cat("Warning: Forecast failed for", name, ":", e$message, "\n")
            NULL
        }
    )

    if (is.null(fc)) next

    fc_var_names <- names(fc$fcst)

    # Find ORtg
    fc_ortg <- fc$fcst$ORtg[, "fcst"]

    # Find Pace
    fc_pace <- fc$fcst$Pace[, "fcst"]

    # Find 3PAr (might be stored with backticks or without)
    tpar_fc_name <- fc_var_names[grep("3PAr|PAr", fc_var_names, ignore.case = TRUE)]
    if (length(tpar_fc_name) == 0) {
        tpar_fc_name <- fc_var_names[3] # Default to third variable
    } else {
        tpar_fc_name <- tpar_fc_name[1] # Take first match
    }
    fc_3par <- fc$fcst[[tpar_fc_name]][, "fcst"]

    test_var_names <- colnames(test_var)
    test_ortg_vec <- as.numeric(test_var[, "ORtg"])
    test_pace_vec <- as.numeric(test_var[, "Pace"])

    tpar_test_name <- test_var_names[grep("3PAr|PAr", test_var_names, ignore.case = TRUE)]
    if (length(tpar_test_name) == 0) {
        tpar_test_name <- test_var_names[3]
    } else {
        tpar_test_name <- tpar_test_name[1]
    }
    test_3par_vec <- as.numeric(test_var[, tpar_test_name])

    # Ensure equal lengths (forecasts might be shorter if h_var is large)
    n_compare <- min(length(test_ortg_vec), length(fc_ortg), length(fc_pace), length(fc_3par))

    # Calculate RMSE for each variable
    rmse_ortg <- sqrt(mean((test_ortg_vec[1:n_compare] - fc_ortg[1:n_compare])^2, na.rm = TRUE))
    rmse_pace <- sqrt(mean((test_pace_vec[1:n_compare] - fc_pace[1:n_compare])^2, na.rm = TRUE))
    rmse_3par <- sqrt(mean((test_3par_vec[1:n_compare] - fc_3par[1:n_compare])^2, na.rm = TRUE))

    # Average RMSE across variables
    rmse_avg <- mean(c(rmse_ortg, rmse_pace, rmse_3par), na.rm = TRUE)

    cat("  ", name, ": ORtg RMSE =", round(rmse_ortg, 4),
        "| Pace RMSE =", round(rmse_pace, 4),
        "| 3PAr RMSE =", round(rmse_3par, 4),
        "| Avg =", round(rmse_avg, 4), "\n")

    # Create descriptive model name
    lag_num <- as.numeric(gsub("VAR_", "", name))
    model_label <- paste0("VAR(", lag_num, ")")

    rmse_results <- rbind(rmse_results, data.frame(
        Model = model_label,
        Lags = lag_num,
        RMSE_ORtg = rmse_ortg,
        RMSE_Pace = rmse_pace,
        RMSE_3PAr = rmse_3par,
        RMSE_Avg = rmse_avg
    ))
}

cat("\n=== CROSS-VALIDATION RESULTS ===\n\n")
```

```{r var-cv-table, warning=FALSE, message=FALSE, results='asis', echo=FALSE}
if (exists("rmse_results") && nrow(rmse_results) > 0) {
    kable(rmse_results,
        format = "html",
        digits = 4,
        caption = "Cross-Validation Results: VAR Models (Test Set: 2020-2024)",
        col.names = c("Model", "Lags", "RMSE (ORtg)", "RMSE (Pace)", "RMSE (3PAr)", "Avg RMSE"),
        row.names = FALSE
    ) %>%
        kable_styling(
            full_width = FALSE,
            bootstrap_options = c("striped", "hover", "condensed", "responsive")
        ) %>%
        row_spec(which.min(rmse_results$RMSE_Avg), bold = TRUE, color = "white", background = "#006bb6")
}
```

```{r var-cv-plot, warning=FALSE, message=FALSE, fig.width=10, fig.height=6}
if (exists("rmse_results") && nrow(rmse_results) > 0) {
    # Plot RMSEs
    ggplot(rmse_results, aes(x = factor(Lags), y = RMSE_Avg, fill = Model)) +
        geom_bar(stat = "identity", width = 0.6) +
        geom_text(aes(label = round(RMSE_Avg, 3)), vjust = -0.5, fontface = "bold") +
        labs(
            title = "VAR Model Cross-Validation: Average RMSE",
            subtitle = "Lower RMSE = Better out-of-sample forecast performance",
            x = "Number of Lags (p)",
            y = "Average RMSE across ORtg, Pace, 3PAr"
        ) +
        theme_minimal() +
        theme(legend.position = "none") +
        scale_fill_brewer(palette = "Set2")
}
```

```{r var-cv-best, warning=FALSE, message=FALSE}
if (exists("rmse_results") && nrow(rmse_results) > 0) {
    best_var_idx <- which.min(rmse_results$RMSE_Avg)
    cat("\nBest model:", rmse_results$Model[best_var_idx], "(Average RMSE =", round(rmse_results$RMSE_Avg[best_var_idx], 3), ")\n")
} else {
    best_var_idx <- 1
}
```

## Final Model & Forecast

```{r var-final, warning=FALSE, message=FALSE, fig.width=12, fig.height=10}
# Select best model
if (exists("rmse_results") && nrow(rmse_results) > 0 && exists("best_var_idx")) {
    best_var_name <- rmse_results$Model[best_var_idx]
    best_var_lags <- rmse_results$Lags[best_var_idx]
} else {
    best_var_lags <- min(lags_to_fit)
}

cat("Final VAR Model: VAR(", best_var_lags, ")\n\n", sep = "")

# Refit on full data
final_var <- tryCatch(
    {
        VAR(var_data_final, p = best_var_lags, type = "const")
    },
    error = function(e) {
        VAR(var_data_final, p = 1, type = "const")
    }
)

print(summary(final_var))

# Forecast 5 periods ahead
fc_var_final <- predict(final_var, n.ahead = 5)

# Get variable names
fc_var_names <- names(fc_var_final$fcst)
tpar_fc_name <- fc_var_names[grep("3PAr|PAr", fc_var_names, ignore.case = TRUE)]
if (length(tpar_fc_name) == 0) tpar_fc_name <- fc_var_names[3]

# Display forecasts
cat("\n=== 5-Period Forecasts ===\n\n")
cat("ORtg:\n")
print(fc_var_final$fcst$ORtg)
cat("\n", tpar_fc_name, ":\n", sep = "")
print(fc_var_final$fcst[[tpar_fc_name]])
cat("\nPace:\n")
print(fc_var_final$fcst$Pace)

# Plot forecasts
for (vname in fc_var_names) {
    plot(fc_var_final, names = vname)
}
```

**Granger Causality Tests**:

```{r var-granger, warning=FALSE, message=FALSE}
# Granger causality tests
var_names <- names(final_var$varresult)
tpar_name <- var_names[grep("3PAr|PAr", var_names, ignore.case = TRUE)]
if (length(tpar_name) == 0) tpar_name <- var_names[3]

granger_3par_ortg <- causality(final_var, cause = tpar_name)$Granger
granger_pace <- causality(final_var, cause = "Pace")$Granger
granger_ortg <- causality(final_var, cause = "ORtg")$Granger

cat("3PAr → {ORtg, Pace}: F =", round(granger_3par_ortg$statistic, 3),
    ", p =", round(granger_3par_ortg$p.value, 4), "\n")
cat("Pace → {ORtg, 3PAr}: F =", round(granger_pace$statistic, 3),
    ", p =", round(granger_pace$p.value, 4), "\n")
cat("ORtg → {Pace, 3PAr}: F =", round(granger_ortg$statistic, 3),
    ", p =", round(granger_ortg$p.value, 4), "\n")
```

Granger causality tests reveal the temporal ordering of the analytics revolution by determining which variables' past values predict other variables' future changes. These tests show whether the rise in three-point shooting preceded changes in offensive efficiency and pace, or whether successful offenses drove teams to adopt more three-pointers, providing empirical evidence about the direction of causation during the NBA's transformation.

```{r var-irf, warning=FALSE, message=FALSE, fig.width=12, fig.height=8}
var_names_irf <- names(final_var$varresult)
tpar_name_irf <- var_names_irf[grep("3PAr|PAr", var_names_irf, ignore.case = TRUE)]
if (length(tpar_name_irf) == 0) tpar_name_irf <- var_names_irf[3]

# IRFs
irf_3par_ortg <- irf(final_var, impulse = tpar_name_irf, response = "ORtg", n.ahead = 10)
plot(irf_3par_ortg, main = paste("Impulse:", tpar_name_irf, "→ Response: ORtg"))

irf_pace_ortg <- irf(final_var, impulse = "Pace", response = "ORtg", n.ahead = 10)
plot(irf_pace_ortg, main = "Impulse: Pace → Response: ORtg")

irf_ortg_3par <- irf(final_var, impulse = "ORtg", response = tpar_name_irf, n.ahead = 10)
plot(irf_ortg_3par, main = paste("Impulse: ORtg → Response:", tpar_name_irf))
```

## Interpretation

The VAR model reveals meaningful relationships among offensive efficiency, three-point shooting, and pace across NBA history. Granger causality tests quantify whether past values of one variable help predict future values of others, addressing the question of whether the rise in three-point shooting preceded changes in offensive efficiency or vice versa.

Impulse response functions trace how a one-time shock to one variable cascades through the system, showing whether innovations in one aspect of basketball strategy have lasting effects on others or if defensive adjustments eventually neutralize advantages. Together, these tools demonstrate that while the analytics revolution transformed the NBA, reflecting the complex adaptive nature of elite competition where strategic innovations provoke counter-responses.

:::

## Pace Dynamics (VAR)

**Variables**: `Pace`, `3PAr`, `eFG%`

This VAR model investigates the bidirectional relationships between pace of play, three-point attempt rate, and effective field goal percentage. The theoretical motivation is multifaceted: faster pace may facilitate more three-point attempts through transition opportunities, while teams that shoot more threes may adopt faster tempos to maximize possessions. Additionally, better shooting efficiency (eFG%) may enable teams to control tempo more effectively, while faster pace could create higher-quality shot opportunities through defensive breakdowns. Unlike ARIMAX models that assume one-directional causality, VAR allows all three variables to influence each other dynamically.

::: {.panel-tabset}

## EDA & Stationarity

```{r var-pace-eda, warning=FALSE, message=FALSE, fig.width=12, fig.height=8}
# Create VAR dataset for pace dynamics
var_pace_data <- ts(league_avg %>% dplyr::select(Pace, `3PAr`, `eFG%`),
    start = 1980, frequency = 1
)

# Plot all series
autoplot(var_pace_data, facets = TRUE) +
    labs(
        title = "VAR Variables: Pace, 3PAr, eFG% (1980-2025)",
        x = "Year", y = "Value"
    ) +
    theme_minimal()

cat("Summary Statistics:\n")
summary(var_pace_data)
```

```{r var-pace-stationarity, warning=FALSE, message=FALSE}
# ADF tests for each series
adf_pace_var2 <- adf.test(var_pace_data[, "Pace"])
adf_3par_var2 <- adf.test(var_pace_data[, "3PAr"])
adf_efg_var2 <- adf.test(var_pace_data[, "eFG%"])

cat(
    "Pace: ADF p-value =", round(adf_pace_var2$p.value, 4),
    ifelse(adf_pace_var2$p.value < 0.05, "(stationary)", "(non-stationary)"), "\n"
)
cat(
    "3PAr: ADF p-value =", round(adf_3par_var2$p.value, 4),
    ifelse(adf_3par_var2$p.value < 0.05, "(stationary)", "(non-stationary)"), "\n"
)
cat(
    "eFG%: ADF p-value =", round(adf_efg_var2$p.value, 4),
    ifelse(adf_efg_var2$p.value < 0.05, "(stationary)", "(non-stationary)"), "\n\n"
)

# Difference if non-stationary
if (adf_pace_var2$p.value > 0.05 | adf_3par_var2$p.value > 0.05 | adf_efg_var2$p.value > 0.05) {
    var_pace_data_diff <- diff(var_pace_data)

    # Test differenced data
    adf_pace_diff <- adf.test(var_pace_data_diff[, "Pace"])
    adf_3par_diff <- adf.test(var_pace_data_diff[, "3PAr"])
    adf_efg_diff <- adf.test(var_pace_data_diff[, "eFG%"])

    cat("After first-differencing:\n")
    cat("Pace: ADF p-value =", round(adf_pace_diff$p.value, 4), "\n")
    cat("3PAr: ADF p-value =", round(adf_3par_diff$p.value, 4), "\n")
    cat("eFG%: ADF p-value =", round(adf_efg_diff$p.value, 4), "\n")

    if (adf_pace_diff$p.value < 0.05 & adf_3par_diff$p.value < 0.05 & adf_efg_diff$p.value < 0.05) {
        var_pace_data_final <- var_pace_data_diff
        differenced_pace <- TRUE
    } else {
        var_pace_data_final <- var_pace_data_diff
        differenced_pace <- TRUE
    }
} else {
    var_pace_data_final <- var_pace_data
    differenced_pace <- FALSE
}
```

The time series reveal distinct evolutionary patterns. Pace shows the famous U-shape: declining from the fast-paced 1980s through the defensive mid-2000s, then rebounding in the modern era as analytics embraced tempo. Three-point attempt rate explodes post-2012, capturing the shot selection revolution. Effective field goal percentage rises steadily, reflecting improved shooting skill and better shot selection. All three series exhibit non-stationary trends, necessitating differencing for valid VAR estimation.

## Model Selection & Fitting

```{r var-pace-select, warning=FALSE, message=FALSE}
# Determine optimal lag order
var_pace_select <- VARselect(var_pace_data_final, lag.max = 8, type = "const")

print(var_pace_select$selection)
print(var_pace_select$criteria)

# Fit models with different lag orders
lags_pace_to_fit <- unique(var_pace_select$selection[1:3])

# Ensure we have at least one lag to fit
if (length(lags_pace_to_fit) == 0 || any(is.na(lags_pace_to_fit))) {
    lags_pace_to_fit <- 1
}

cat("\nFitting VAR models with p =", paste(lags_pace_to_fit, collapse = ", "), "\n")

var_pace_models <- list()
for (p in lags_pace_to_fit) {
    var_pace_models[[paste0("VAR_", p)]] <- VAR(var_pace_data_final, p = p, type = "const")
}
```

```{r var-pace-summaries, warning=FALSE, message=FALSE}
for (name in names(var_pace_models)) {
    cat("========================================\n")
    cat(name, "Summary:\n")
    cat("========================================\n\n")
    print(summary(var_pace_models[[name]]))
    cat("\n\n")
}
```


## Cross-Validation

```{r var-pace-cv, warning=FALSE, message=FALSE, fig.width=10, fig.height=6}
# Split: Train 1980-2019, Test 2020-2024
train_end_var_pace <- 2019

if (differenced_pace) {
    train_var_pace <- window(var_pace_data_final, end = train_end_var_pace)
    test_var_pace <- window(var_pace_data_final, start = train_end_var_pace + 1)
} else {
    train_var_pace <- window(var_pace_data_final, end = train_end_var_pace)
    test_var_pace <- window(var_pace_data_final, start = train_end_var_pace + 1)
}

h_var_pace <- nrow(test_var_pace)

# Fit VAR models on training data with error handling
var_pace_train_models <- list()
for (p in lags_pace_to_fit) {
    model <- tryCatch(
        {
            VAR(train_var_pace, p = p, type = "const")
        },
        error = function(e) {
            if (p > 1) {
                VAR(train_var_pace, p = 1, type = "const")
            } else {
                NULL
            }
        }
    )
    if (!is.null(model)) {
        var_pace_train_models[[paste0("VAR_", p)]] <- model
    }
}

# Generate forecasts
rmse_pace_results <- data.frame()

cat("Evaluating", length(var_pace_train_models), "VAR model(s)\n")

for (name in names(var_pace_train_models)) {
    fc <- tryCatch(
        {
            predict(var_pace_train_models[[name]], n.ahead = h_var_pace)
        },
        error = function(e) {
            cat("Warning: Forecast failed for", name, ":", e$message, "\n")
            NULL
        }
    )

    if (is.null(fc)) next

    # Extract forecasts for each variable
    fc_var_names_pace <- names(fc$fcst)

    # Find Pace
    fc_pace_var <- fc$fcst$Pace[, "fcst"]

    # Find 3PAr
    tpar_fc_name_pace <- fc_var_names_pace[grep("3PAr|PAr", fc_var_names_pace, ignore.case = TRUE)]
    if (length(tpar_fc_name_pace) == 0) {
        tpar_fc_name_pace <- fc_var_names_pace[2]
    } else {
        tpar_fc_name_pace <- tpar_fc_name_pace[1]
    }
    fc_3par_pace <- fc$fcst[[tpar_fc_name_pace]][, "fcst"]

    # Find eFG%
    efg_fc_name_pace <- fc_var_names_pace[grep("eFG%|eFG", fc_var_names_pace, ignore.case = TRUE)]
    if (length(efg_fc_name_pace) == 0) {
        efg_fc_name_pace <- fc_var_names_pace[3]
    } else {
        efg_fc_name_pace <- efg_fc_name_pace[1]
    }
    fc_efg_pace <- fc$fcst[[efg_fc_name_pace]][, "fcst"]

    # Convert test data to numeric vectors
    test_var_names_pace <- colnames(test_var_pace)
    test_pace_vec <- as.numeric(test_var_pace[, "Pace"])

    tpar_test_name_pace <- test_var_names_pace[grep("3PAr|PAr", test_var_names_pace, ignore.case = TRUE)]
    if (length(tpar_test_name_pace) == 0) {
        tpar_test_name_pace <- test_var_names_pace[2]
    } else {
        tpar_test_name_pace <- tpar_test_name_pace[1]
    }
    test_3par_pace <- as.numeric(test_var_pace[, tpar_test_name_pace])

    efg_test_name_pace <- test_var_names_pace[grep("eFG%|eFG", test_var_names_pace, ignore.case = TRUE)]
    if (length(efg_test_name_pace) == 0) {
        efg_test_name_pace <- test_var_names_pace[3]
    } else {
        efg_test_name_pace <- efg_test_name_pace[1]
    }
    test_efg_pace <- as.numeric(test_var_pace[, efg_test_name_pace])

    # Ensure equal lengths
    n_compare <- min(length(test_pace_vec), length(fc_pace_var), length(fc_3par_pace), length(fc_efg_pace))

    # Calculate RMSE for each variable
    rmse_pace <- sqrt(mean((test_pace_vec[1:n_compare] - fc_pace_var[1:n_compare])^2, na.rm = TRUE))
    rmse_3par_pace <- sqrt(mean((test_3par_pace[1:n_compare] - fc_3par_pace[1:n_compare])^2, na.rm = TRUE))
    rmse_efg_pace <- sqrt(mean((test_efg_pace[1:n_compare] - fc_efg_pace[1:n_compare])^2, na.rm = TRUE))

    # Average RMSE across variables
    rmse_avg_pace <- mean(c(rmse_pace, rmse_3par_pace, rmse_efg_pace), na.rm = TRUE)

    cat("  ", name, ": Pace RMSE =", round(rmse_pace, 4),
        "| 3PAr RMSE =", round(rmse_3par_pace, 4),
        "| eFG% RMSE =", round(rmse_efg_pace, 4),
        "| Avg =", round(rmse_avg_pace, 4), "\n")

    # Create descriptive model name
    lag_num <- as.numeric(gsub("VAR_", "", name))
    model_label <- paste0("VAR(", lag_num, ")")

    rmse_pace_results <- rbind(rmse_pace_results, data.frame(
        Model = model_label,
        Lags = lag_num,
        RMSE_Pace = rmse_pace,
        RMSE_3PAr = rmse_3par_pace,
        RMSE_eFG = rmse_efg_pace,
        RMSE_Avg = rmse_avg_pace
    ))
}

cat("\n=== CROSS-VALIDATION RESULTS ===\n\n")
```

```{r var-pace-cv-table, warning=FALSE, message=FALSE, results='asis', echo=FALSE}
if (exists("rmse_pace_results") && nrow(rmse_pace_results) > 0) {
    kable(rmse_pace_results,
        format = "html",
        digits = 4,
        caption = "Cross-Validation Results: Pace VAR Models (Test Set: 2020-2024)",
        col.names = c("Model", "Lags", "RMSE (Pace)", "RMSE (3PAr)", "RMSE (eFG%)", "Avg RMSE"),
        row.names = FALSE
    ) %>%
        kable_styling(
            full_width = FALSE,
            bootstrap_options = c("striped", "hover", "condensed", "responsive")
        ) %>%
        row_spec(which.min(rmse_pace_results$RMSE_Avg), bold = TRUE, color = "white", background = "#006bb6")
}
```

```{r var-pace-cv-plot, warning=FALSE, message=FALSE, fig.width=10, fig.height=6}
if (exists("rmse_pace_results") && nrow(rmse_pace_results) > 0) {
    # Plot RMSEs
    ggplot(rmse_pace_results, aes(x = factor(Lags), y = RMSE_Avg, fill = Model)) +
        geom_bar(stat = "identity", width = 0.6) +
        geom_text(aes(label = round(RMSE_Avg, 3)), vjust = -0.5, fontface = "bold") +
        labs(
            title = "Pace VAR Model Cross-Validation: Average RMSE",
            subtitle = "Lower RMSE = Better out-of-sample forecast performance",
            x = "Number of Lags (p)",
            y = "Average RMSE across Pace, 3PAr, eFG%"
        ) +
        theme_minimal() +
        theme(legend.position = "none") +
        scale_fill_brewer(palette = "Set2")
}
```

```{r var-pace-cv-best, warning=FALSE, message=FALSE}
if (exists("rmse_pace_results") && nrow(rmse_pace_results) > 0) {
    best_var_pace_idx <- which.min(rmse_pace_results$RMSE_Avg)
    cat("\nBest model:", rmse_pace_results$Model[best_var_pace_idx], "(Average RMSE =", round(rmse_pace_results$RMSE_Avg[best_var_pace_idx], 3), ")\n")
} else {
    best_var_pace_idx <- 1
}
```

## Final Model & Forecast

```{r var-pace-final, warning=FALSE, message=FALSE, fig.width=12, fig.height=10}
# Select best model
if (exists("rmse_pace_results") && nrow(rmse_pace_results) > 0 && exists("best_var_pace_idx")) {
    best_var_pace_name <- rmse_pace_results$Model[best_var_pace_idx]
    best_var_pace_lags <- rmse_pace_results$Lags[best_var_pace_idx]
} else {
    best_var_pace_lags <- min(lags_pace_to_fit)
}

cat("Final VAR Model: VAR(", best_var_pace_lags, ")\n\n", sep = "")

# Refit on full data
final_var_pace <- tryCatch(
    {
        VAR(var_pace_data_final, p = best_var_pace_lags, type = "const")
    },
    error = function(e) {
        VAR(var_pace_data_final, p = 1, type = "const")
    }
)

print(summary(final_var_pace))

# Forecast 5 periods ahead
fc_var_pace_final <- predict(final_var_pace, n.ahead = 5)

# Get variable names
fc_var_pace_names <- names(fc_var_pace_final$fcst)
tpar_fc_name_final <- fc_var_pace_names[grep("3PAr|PAr", fc_var_pace_names, ignore.case = TRUE)]
if (length(tpar_fc_name_final) == 0) tpar_fc_name_final <- fc_var_pace_names[2]

efg_fc_name_final <- fc_var_pace_names[grep("eFG%|eFG", fc_var_pace_names, ignore.case = TRUE)]
if (length(efg_fc_name_final) == 0) efg_fc_name_final <- fc_var_pace_names[3]

# Display forecasts
cat("\n=== 5-Period Forecasts ===\n\n")
cat("Pace:\n")
print(fc_var_pace_final$fcst$Pace)
cat("\n", tpar_fc_name_final, ":\n", sep = "")
print(fc_var_pace_final$fcst[[tpar_fc_name_final]])
cat("\n", efg_fc_name_final, ":\n", sep = "")
print(fc_var_pace_final$fcst[[efg_fc_name_final]])

# Plot forecasts
for (vname in fc_var_pace_names) {
    plot(fc_var_pace_final, names = vname)
}
```

**Granger Causality Tests**:

```{r var-pace-granger, warning=FALSE, message=FALSE}
# Granger causality tests
var_pace_names <- names(final_var_pace$varresult)
tpar_name_granger <- var_pace_names[grep("3PAr|PAr", var_pace_names, ignore.case = TRUE)]
if (length(tpar_name_granger) == 0) tpar_name_granger <- var_pace_names[2]

efg_name_granger <- var_pace_names[grep("eFG%|eFG", var_pace_names, ignore.case = TRUE)]
if (length(efg_name_granger) == 0) efg_name_granger <- var_pace_names[3]

granger_pace_all <- causality(final_var_pace, cause = "Pace")$Granger
granger_3par_pace <- causality(final_var_pace, cause = tpar_name_granger)$Granger
granger_efg_pace <- causality(final_var_pace, cause = efg_name_granger)$Granger

cat("Pace → {3PAr, eFG%}: F =", round(granger_pace_all$statistic, 3),
    ", p =", round(granger_pace_all$p.value, 4), "\n")
cat("3PAr → {Pace, eFG%}: F =", round(granger_3par_pace$statistic, 3),
    ", p =", round(granger_3par_pace$p.value, 4), "\n")
cat("eFG% → {Pace, 3PAr}: F =", round(granger_efg_pace$statistic, 3),
    ", p =", round(granger_efg_pace$p.value, 4), "\n")
```

Granger causality tests reveal which strategic variables lead versus follow in NBA evolution. If 3PAr Granger-causes Pace, this suggests teams first adopted three-point shooting, then adjusted their tempo accordingly. Conversely, if Pace Granger-causes 3PAr, faster play may have created the transition opportunities that made three-point volume feasible. The eFG% tests reveal whether shooting skill improvements preceded or followed strategic changes.

```{r var-pace-irf, warning=FALSE, message=FALSE, fig.width=12, fig.height=8}
# IRFs
irf_3par_pace <- irf(final_var_pace, impulse = tpar_name_granger, response = "Pace", n.ahead = 10)
plot(irf_3par_pace, main = paste("Impulse:", tpar_name_granger, "→ Response: Pace"))

irf_efg_pace <- irf(final_var_pace, impulse = efg_name_granger, response = "Pace", n.ahead = 10)
plot(irf_efg_pace, main = paste("Impulse:", efg_name_granger, "→ Response: Pace"))

irf_pace_3par <- irf(final_var_pace, impulse = "Pace", response = tpar_name_granger, n.ahead = 10)
plot(irf_pace_3par, main = paste("Impulse: Pace → Response:", tpar_name_granger))
```

## Interpretation

The Pace Dynamics VAR model uncovers the temporal relationships between game tempo, shot selection, and shooting efficiency. This addresses a fundamental question in basketball analytics: did the analytics revolution's emphasis on three-point shooting cause teams to speed up, or did faster pace create opportunities for more three-point attempts?

Impulse response functions trace the dynamic effects of shocks. If a one-time increase in Pace produces a lasting increase in 3PAr, this supports the hypothesis that faster tempo facilitates three-point volume through transition opportunities and defensive breakdowns. Conversely, if innovations in 3PAr lead to sustained changes in Pace, this suggests strategic shot selection drives tempo decisions. The eFG% impulses reveal whether shooting skill improvements enable teams to control pace or result from pace-driven shot quality.

Cross-validation results demonstrate the model's out-of-sample forecasting accuracy, with lower RMSE indicating that the bidirectional relationships captured by VAR improve predictions beyond univariate models. The optimal lag structure reveals how long past values influence future changes. A longer optimal lag suggests persistent momentum effects, while shorter lags indicate rapid strategic adjustments where teams quickly respond to innovations.

This VAR framework captures the complex adaptive dynamics of NBA strategy, where teams continuously adjust multiple dimensions simultaneously rather than optimizing single variables in isolation. The analytics revolution wasn't just about shooting more threes; it was about reconfiguring pace, shot selection, and skill development in an interconnected system where each element reinforces the others.

:::

---

# Sports Betting & NBA Recovery (VAR)

Before running Model 5, we need to load and process DKNG stock data:

```{r load-dkng, warning=FALSE, message=FALSE}
# Load DKNG daily stock data
dkng_data <- read_csv("data/financial/DKNG_daily.csv", show_col_types = FALSE)

# Convert to annual averages (matching NBA season structure)
dkng_annual <- dkng_data %>%
    mutate(
        Date = as.Date(Date),
        Year = year(Date),
        # NBA seasons span two calendar years; use the ending year
        # e.g., 2019-2020 season → 2020
        Season = ifelse(month(Date) >= 10, Year + 1, Year)
    ) %>%
    group_by(Season) %>%
    summarise(
        DKNG_Price = mean(`Adj Close`, na.rm = TRUE),
        .groups = "drop"
    )

# Merge with league_avg data
league_avg_dkng <- league_avg %>%
    left_join(dkng_annual, by = "Season") %>%
    filter(!is.na(DKNG_Price)) # Only keep seasons with DKNG data (2020+)

cat("DKNG data loaded and merged. Available seasons:", min(league_avg_dkng$Season), "-", max(league_avg_dkng$Season), "\n")
cat("Number of observations:", nrow(league_avg_dkng), "\n\n")
head(league_avg_dkng %>% dplyr::select(Season, DKNG_Price, Total_Attendance, ORtg))
```

## Sports Betting & NBA Recovery (VAR)

**Variables**: `DKNG` (DraftKings stock price), `Attendance`, `ORtg`

This VAR model tests a provocative hypothesis: does NBA performance influence sports betting industry valuations? The 2020-2025 period offers a natural experiment: COVID decimated attendance and disrupted seasons, while sports betting stocks experienced extreme volatility. By modeling bidirectional relationships between DraftKings' stock price, NBA attendance, and offensive efficiency, we test whether the on-court analytics revolution created measurable financial value in connected industries. If ORtg Granger-causes DKNG, this suggests exciting offensive basketball drives betting engagement and stock valuations. If Attendance Granger-causes DKNG, this indicates fan engagement metrics predict betting industry performance.

::: {.panel-tabset}

## EDA & Stationarity

```{r var-dkng-eda, warning=FALSE, message=FALSE, fig.width=12, fig.height=8}
# Create VAR dataset (2020-2025 only, when DKNG data exists)
var_dkng_data <- ts(league_avg_dkng %>% dplyr::select(DKNG_Price, Total_Attendance, ORtg),
    start = min(league_avg_dkng$Season), frequency = 1
)

# Plot all series
autoplot(var_dkng_data, facets = TRUE) +
    labs(
        title = "VAR Variables: DKNG Price, Attendance, ORtg (2020-2025)",
        x = "Year", y = "Value"
    ) +
    theme_minimal()

cat("Summary Statistics:\n")
summary(var_dkng_data)
```

The visualization captures post-COVID dynamics: DKNG stock exhibits extreme volatility as the sports betting industry navigated legalization waves and market uncertainty. Attendance shows the pandemic collapse in 2020-2021 and gradual recovery. ORtg continues its steady climb, demonstrating that on-court analytics proceeded independent of external shocks. The limited sample size (only 5-6 observations) presents statistical challenges but reflects the natural constraint that DKNG only became public in 2020.

```{r var-dkng-stationarity, warning=FALSE, message=FALSE}
# ADF tests for each series
# For very short series, ADF tests may be unreliable
# We'll run them but interpret cautiously
# adf_dkng_var <- tryCatch(adf.test(var_dkng_data[, "DKNG_Price"]), error = function(e) NULL)
# adf_attend_var <- tryCatch(adf.test(var_dkng_data[, "Total_Attendance"]), error = function(e) NULL)
# adf_ortg_var_dkng <- tryCatch(adf.test(var_dkng_data[, "ORtg"]), error = function(e) NULL)

# if (!is.null(adf_dkng_var)) {
#     cat(
#         "DKNG Price: ADF p-value =", round(adf_dkng_var$p.value, 4),
#         ifelse(adf_dkng_var$p.value < 0.05, "(stationary)", "(non-stationary)"), "\n"
#     )
# } else {
#     cat("DKNG Price: ADF test failed (insufficient data)\n")
# }

# if (!is.null(adf_attend_var)) {
#     cat(
#         "Attendance: ADF p-value =", round(adf_attend_var$p.value, 4),
#         ifelse(adf_attend_var$p.value < 0.05, "(stationary)", "(non-stationary)"), "\n"
#     )
# } else {
#     cat("Attendance: ADF test failed (insufficient data)\n")
# }

# if (!is.null(adf_ortg_var_dkng)) {
#     cat(
#         "ORtg: ADF p-value =", round(adf_ortg_var_dkng$p.value, 4),
#         ifelse(adf_ortg_var_dkng$p.value < 0.05, "(stationary)", "(non-stationary)"), "\n"
#     )
# } else {
#     cat("ORtg: ADF test failed (insufficient data)\n")
# }

var_dkng_data_final <- var_dkng_data
differenced_dkng <- FALSE
```

## Model Selection & Fitting

```{r var-dkng-select, warning=FALSE, message=FALSE}
# Determine optimal lag order
# With very short series, limit lag.max
var_dkng_select <- tryCatch(
    {
        VARselect(var_dkng_data_final, lag.max = 2, type = "const")
    },
    error = function(e) {
        list(selection = c(AIC = 1, HQ = 1, SC = 1, FPE = 1))
    }
)

print(var_dkng_select$selection)
if ("criteria" %in% names(var_dkng_select)) {
    print(var_dkng_select$criteria)
}

# Fit models with different lag orders
lags_dkng_to_fit <- unique(var_dkng_select$selection[1:3])

# Ensure we have at least one lag to fit
if (length(lags_dkng_to_fit) == 0 || any(is.na(lags_dkng_to_fit))) {
    lags_dkng_to_fit <- 1
}

# Given short series, limit to max lag 1
lags_dkng_to_fit <- lags_dkng_to_fit[lags_dkng_to_fit <= 1]
if (length(lags_dkng_to_fit) == 0) lags_dkng_to_fit <- 1

cat("\nFitting VAR models with p =", paste(lags_dkng_to_fit, collapse = ", "), "\n")

var_dkng_models <- list()
for (p in lags_dkng_to_fit) {
    model_fit <- tryCatch(
        {
            VAR(var_dkng_data_final, p = p, type = "const")
        },
        error = function(e) {
            NULL
        }
    )
    if (!is.null(model_fit)) {
        var_dkng_models[[paste0("VAR_", p)]] <- model_fit
    }
}
```

```{r var-dkng-summaries, warning=FALSE, message=FALSE}
for (name in names(var_dkng_models)) {
    cat("========================================\n")
    cat(name, "Summary:\n")
    cat("========================================\n\n")

    # Try to print summary, but catch errors due to near-singular covariance matrices
    summary_result <- tryCatch(
        {
            summary(var_dkng_models[[name]])
        },
        error = function(e) {
            print(coef(var_dkng_models[[name]]))
            NULL
        }
    )

    if (!is.null(summary_result)) {
        print(summary_result)
    }

    cat("\n")
}
```


## Cross-Validation

```{r var-dkng-cv, warning=FALSE, message=FALSE}
# Calculate in-sample RMSE for each model
rmse_dkng_results <- data.frame()

for (name in names(var_dkng_models)) {
    model <- var_dkng_models[[name]]

    # Get fitted values
    fitted_vals <- fitted(model)

    # Calculate RMSE for each variable
    rmse_dkng_price <- sqrt(mean((var_dkng_data_final[, "DKNG_Price"] - fitted_vals[, "DKNG_Price"])^2, na.rm = TRUE))
    rmse_attendance <- sqrt(mean((var_dkng_data_final[, "Total_Attendance"] - fitted_vals[, "Total_Attendance"])^2, na.rm = TRUE))
    rmse_ortg_dkng <- sqrt(mean((var_dkng_data_final[, "ORtg"] - fitted_vals[, "ORtg"])^2, na.rm = TRUE))

    # Average RMSE
    rmse_avg_dkng <- mean(c(rmse_dkng_price, rmse_attendance, rmse_ortg_dkng), na.rm = TRUE)

    cat(name, ": DKNG RMSE =", round(rmse_dkng_price, 2),
        "| Attendance RMSE =", round(rmse_attendance / 1e6, 2), "M",
        "| ORtg RMSE =", round(rmse_ortg_dkng, 2), "\n")

    # Create descriptive model name
    lag_num <- as.numeric(gsub("VAR_", "", name))
    model_label <- paste0("VAR(", lag_num, ")")

    rmse_dkng_results <- rbind(rmse_dkng_results, data.frame(
        Model = model_label,
        Lags = lag_num,
        RMSE_DKNG = rmse_dkng_price,
        RMSE_Attendance = rmse_attendance,
        RMSE_ORtg = rmse_ortg_dkng,
        RMSE_Avg = rmse_avg_dkng
    ))
}
```

```{r var-dkng-cv-table, warning=FALSE, message=FALSE, results='asis', echo=FALSE}
if (exists("rmse_dkng_results") && nrow(rmse_dkng_results) > 0) {
    # Display table with attendance in millions
    rmse_dkng_display <- rmse_dkng_results
    rmse_dkng_display$RMSE_Attendance <- rmse_dkng_display$RMSE_Attendance / 1e6

    kable(rmse_dkng_display,
        format = "html",
        digits = 4,
        caption = "In-Sample Fit: DKNG VAR Models (2020-2025)",
        col.names = c("Model", "Lags", "RMSE (DKNG $)", "RMSE (Attend. M)", "RMSE (ORtg)", "Avg RMSE"),
        row.names = FALSE
    ) %>%
        kable_styling(
            full_width = FALSE,
            bootstrap_options = c("striped", "hover", "condensed", "responsive")
        ) %>%
        row_spec(which.min(rmse_dkng_results$RMSE_Avg), bold = TRUE, color = "white", background = "#006bb6")
}
```

```{r var-dkng-cv-best, warning=FALSE, message=FALSE}
if (exists("rmse_dkng_results") && nrow(rmse_dkng_results) > 0) {
    best_var_dkng_idx <- which.min(rmse_dkng_results$RMSE_Avg)
    cat("\nBest model:", rmse_dkng_results$Model[best_var_dkng_idx], "(Average RMSE =", round(rmse_dkng_results$RMSE_Avg[best_var_dkng_idx], 2), ")\n")
} else {
    best_var_dkng_idx <- 1
}
```

## Final Model & Interpretation

```{r var-dkng-final, warning=FALSE, message=FALSE, fig.width=12, fig.height=10}
# Select best model
if (exists("rmse_dkng_results") && nrow(rmse_dkng_results) > 0 && exists("best_var_dkng_idx")) {
    best_var_dkng_name <- rmse_dkng_results$Model[best_var_dkng_idx]
    best_var_dkng_lags <- rmse_dkng_results$Lags[best_var_dkng_idx]
} else {
    best_var_dkng_lags <- 1
}

cat("Final VAR Model: VAR(", best_var_dkng_lags, ")\n\n", sep = "")

# Use the best fitted model
final_var_dkng <- var_dkng_models[[paste0("VAR_", best_var_dkng_lags)]]

# Try to print summary, catch errors due to near-singular covariance
summary_result <- tryCatch(
    {
        summary(final_var_dkng)
    },
    error = function(e) {
        print(coef(final_var_dkng))
        NULL
    }
)

if (!is.null(summary_result)) {
    print(summary_result)
} else {
    cat("\n")
}

# Forecast 3 periods ahead (conservative given data limitations)
fc_var_dkng_final <- predict(final_var_dkng, n.ahead = 3)

# Display forecasts
cat("\n3-Period Forecasts (2026-2028):\n\n")
cat("DKNG Price:\n")
print(fc_var_dkng_final$fcst$DKNG_Price)
cat("\nTotal Attendance:\n")
print(fc_var_dkng_final$fcst$Total_Attendance)
cat("\nORtg:\n")
print(fc_var_dkng_final$fcst$ORtg)

# Plot forecasts
for (vname in names(fc_var_dkng_final$fcst)) {
    plot(fc_var_dkng_final, names = vname)
}
```

**Granger Causality Tests**:

```{r var-dkng-granger, warning=FALSE, message=FALSE}
# Check if model exists
if (exists("final_var_dkng") && !is.null(final_var_dkng)) {
    # Granger causality tests with error suppression
    granger_dkng <- tryCatch(
        causality(final_var_dkng, cause = "DKNG_Price")$Granger,
        error = function(e) NULL
    )

    granger_attend_dkng <- tryCatch(
        causality(final_var_dkng, cause = "Total_Attendance")$Granger,
        error = function(e) NULL
    )

    granger_ortg_dkng <- tryCatch(
        causality(final_var_dkng, cause = "ORtg")$Granger,
        error = function(e) NULL
    )

    # Display results
    if (!is.null(granger_dkng)) {
        cat("DKNG Price → {Attendance, ORtg}:\n")
        cat("  F-statistic =", round(granger_dkng$statistic, 3), "\n")
        cat("  p-value =", round(granger_dkng$p.value, 4), "\n")
        cat("  Interpretation:", ifelse(granger_dkng$p.value < 0.05,
                                        "DKNG Price Granger-causes other variables",
                                        "No significant Granger causality"), "\n\n")
    }

    if (!is.null(granger_attend_dkng)) {
        cat("Attendance → {DKNG, ORtg}:\n")
        cat("  F-statistic =", round(granger_attend_dkng$statistic, 3), "\n")
        cat("  p-value =", round(granger_attend_dkng$p.value, 4), "\n")
        cat("  Interpretation:", ifelse(granger_attend_dkng$p.value < 0.05,
                                        "Attendance Granger-causes other variables",
                                        "No significant Granger causality"), "\n\n")
    }

    if (!is.null(granger_ortg_dkng)) {
        cat("ORtg → {DKNG, Attendance}:\n")
        cat("  F-statistic =", round(granger_ortg_dkng$statistic, 3), "\n")
        cat("  p-value =", round(granger_ortg_dkng$p.value, 4), "\n")
        cat("  Interpretation:", ifelse(granger_ortg_dkng$p.value < 0.05,
                                        "ORtg Granger-causes other variables",
                                        "No significant Granger causality"), "\n\n")
    }

    # Summary note
    if (is.null(granger_dkng) && is.null(granger_attend_dkng) && is.null(granger_ortg_dkng)) {
        cat("Note: Granger causality tests unavailable (n =", nrow(var_dkng_data_final), "observations).\n")
    }
}
```

**Impulse Response Functions**:

```{r var-dkng-irf, warning=FALSE, message=FALSE, fig.width=12, fig.height=8}
# Check if model exists
if (exists("final_var_dkng") && !is.null(final_var_dkng)) {
    # Track successful plots
    plots_created <- 0

    # IRF: DKNG Price → Attendance
    irf_dkng_attend <- tryCatch(
        irf(final_var_dkng, impulse = "DKNG_Price", response = "Total_Attendance", n.ahead = 5),
        error = function(e) NULL
    )
    if (!is.null(irf_dkng_attend)) {
        plot(irf_dkng_attend, main = "Impulse: DKNG Price → Response: Attendance")
        plots_created <- plots_created + 1
    }

    # IRF: Attendance → DKNG Price
    irf_attend_dkng <- tryCatch(
        irf(final_var_dkng, impulse = "Total_Attendance", response = "DKNG_Price", n.ahead = 5),
        error = function(e) NULL
    )
    if (!is.null(irf_attend_dkng)) {
        plot(irf_attend_dkng, main = "Impulse: Attendance → Response: DKNG Price")
        plots_created <- plots_created + 1
    }

    # IRF: ORtg → DKNG Price
    irf_ortg_dkng <- tryCatch(
        irf(final_var_dkng, impulse = "ORtg", response = "DKNG_Price", n.ahead = 5),
        error = function(e) NULL
    )
    if (!is.null(irf_ortg_dkng)) {
        plot(irf_ortg_dkng, main = "Impulse: ORtg → Response: DKNG Price")
        plots_created <- plots_created + 1
    }

    # IRF: DKNG Price → ORtg (additional relationship)
    irf_dkng_ortg <- tryCatch(
        irf(final_var_dkng, impulse = "DKNG_Price", response = "ORtg", n.ahead = 5),
        error = function(e) NULL
    )
    if (!is.null(irf_dkng_ortg)) {
        plot(irf_dkng_ortg, main = "Impulse: DKNG Price → Response: ORtg")
        plots_created <- plots_created + 1
    }

    # Summary note
    if (plots_created == 0) {
        cat("\nNote: IRF unavailable (n =", nrow(var_dkng_data_final), "observations).\n")
    } else {
        cat("\nGenerated", plots_created, "IRF plot(s). Interpret with caution (n =", nrow(var_dkng_data_final), ").\n")
    }
}
```

## Interpretation

This VAR model tests whether NBA performance metrics influence sports betting industry valuations. With DKNG only public since April 2020, we have just 5-6 observations—severely limiting statistical inference. Granger causality tests and IRF analyses lack sufficient degrees of freedom for reliable results.

Despite data constraints, this framework demonstrates the interconnected sports-finance ecosystem: NBA attendance and offensive efficiency potentially drive betting industry valuations. The COVID period introduces extreme outliers that dominate the short sample, making results exploratory rather than definitive. As more data accumulates (2025+), future analyses can test whether these relationships persist beyond the pandemic disruption.

:::
