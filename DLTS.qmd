---
title: "Deep Learning for Time Series Forecasting"
jupyter: dsan6600-tfk-v2
format:
  html:
    code-fold: true
    toc: true
    toc-depth: 3
    embed-resources: true
---

# Theoretical Framework

This chapter explores deep learning approaches to time series forecasting, comparing modern neural network architectures with traditional statistical methods. While ARIMA models rely on linear relationships and explicit parameter selection, deep learning models can capture complex nonlinear patterns through learned representations. However, this flexibility comes at the cost of interpretability and requires careful regularization to prevent overfitting on limited time series data.

::: {.panel-tabset}

## Literature Review

Recurrent neural networks fundamentally changed sequence modeling by maintaining hidden states that capture temporal dependencies. Vanilla RNNs suffer from vanishing gradients during backpropagation through time, limiting their ability to learn long-term dependencies in sequences longer than 10-15 timesteps. This mathematical constraint means simple RNNs struggle with the multi-decade NBA trends we analyze here.

Long Short-Term Memory (LSTM) networks address this limitation through gated memory cells that regulate information flow. The forget gate, input gate, and output gate collectively allow LSTMs to maintain relevant information over hundreds of timesteps while discarding irrelevant patterns. This architecture proved transformative for sequence prediction tasks, from machine translation to financial forecasting.

Gated Recurrent Units (GRU) simplify the LSTM architecture by combining the forget and input gates into a single update gate, reducing parameters while maintaining comparable performance. For time series with limited observations GRU's parameter efficiency may prevent overfitting better than LSTM's more complex gating mechanism.

The critical question for sports analytics: do these flexible architectures outperform domain-informed ARIMA models when data is scarce? Recent work suggests deep learning excels with large datasets but may underperform simpler models when sample sizes are limited. Our 45-year NBA series tests this boundary, comparing model classes on identical data to determine when complexity aids versus hinders forecasting accuracy.

:::

---

```{python setup, warning=FALSE, message=FALSE}
import tensorflow as tf
import keras
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from tensorflow.keras import layers, regularizers
from tensorflow.keras.layers import Dense, SimpleRNN, LSTM, GRU
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import Sequential
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error
from sklearn.preprocessing import MinMaxScaler
from IPython.display import display
import warnings
warnings.filterwarnings('ignore')

np.random.seed(5600)
tf.random.set_seed(5600)

# Load NBA data
import glob

all_adv_files = glob.glob("data/adv_stats/*.csv")

all_adv_data = []
for file in all_adv_files:
    season_str = file.split('/')[-1].split('_')[0]
    season_year = int(season_str.split('-')[0]) + 1
    df = pd.read_csv(file)
    df['Season'] = season_year
    all_adv_data.append(df)

all_adv_df = pd.concat(all_adv_data, ignore_index=True)

# Calculate league averages
league_avg = all_adv_df.groupby('Season').agg({
    'Unnamed: 10_level_0_ORtg': 'mean',
    'Unnamed: 11_level_0_DRtg': 'mean',
    'Unnamed: 13_level_0_Pace': 'mean',
    'Unnamed: 15_level_0_3PAr': 'mean',
    'Unnamed: 16_level_0_TS%': 'mean',
    'Offense Four Factors_eFG%': 'mean'
}).reset_index()

league_avg.columns = ['Season', 'ORtg', 'DRtg', 'Pace', '3PAr', 'TS%', 'eFG%']
league_avg = league_avg.sort_values('Season').reset_index(drop=True)

print(f"\nData loaded: {len(league_avg)} seasons from {league_avg['Season'].min()} to {league_avg['Season'].max()}")
```

---

# Univariate Deep Learning Forecasting

## Data Preparation

We use **Offensive Rating (ORtg)** as our univariate series. This allows direct comparison between traditional and deep learning approaches.

```{python data-prep}
# Extract ORtg series
ortg_data = league_avg[['Season', 'ORtg']].copy()
ortg_data = ortg_data.sort_values('Season').reset_index(drop=True)

print(f"Time series: {len(ortg_data)} observations")
print(f"Range: {ortg_data['ORtg'].min():.2f} to {ortg_data['ORtg'].max():.2f}")
print(f"\nFirst 5 values:\n{ortg_data.head()}")
print(f"\nLast 5 values:\n{ortg_data.tail()}")

# Visualize the series
plt.figure(figsize=(12, 4))
plt.plot(ortg_data['Season'], ortg_data['ORtg'], marker='o', linewidth=2)
plt.xlabel('Season')
plt.ylabel('Offensive Rating')
plt.title('NBA Offensive Rating (1980-2025)')
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
```

**Observation**: ORtg shows a clear upward trend from ~104 in 1980 to ~113 in 2025, reflecting the league's offensive evolution. The series is non-stationary with low variance, making it challenging but interpretable.

### Train/Validation/Test Split

```{python train-test-split}
# Define split points
train_size = int(len(ortg_data) * 0.7)  # 70% train
val_size = int(len(ortg_data) * 0.15)   # 15% validation
# Remaining 15% for test

train_data = ortg_data[:train_size].copy()
val_data = ortg_data[train_size:train_size + val_size].copy()
test_data = ortg_data[train_size + val_size:].copy()

print(f"Training set: {len(train_data)} observations (Seasons {train_data['Season'].min()}-{train_data['Season'].max()})")
print(f"Validation set: {len(val_data)} observations (Seasons {val_data['Season'].min()}-{val_data['Season'].max()})")
print(f"Test set: {len(test_data)} observations (Seasons {test_data['Season'].min()}-{test_data['Season'].max()})")

# Scale data (fit on training set only)
scaler = MinMaxScaler()
train_scaled = scaler.fit_transform(train_data[['ORtg']])
val_scaled = scaler.transform(val_data[['ORtg']])
test_scaled = scaler.transform(test_data[['ORtg']])

print(f"\nScaled range: [{train_scaled.min():.3f}, {train_scaled.max():.3f}]")
```

### Input Windowing

```{python windowing}
def create_sequences(data, window_size):

    X, y = [], []
    for i in range(len(data) - window_size):
        X.append(data[i:i + window_size])
        y.append(data[i + window_size])
    return np.array(X), np.array(y)

# Create sequences
window_size = 5  # Use 5 years to predict next year
X_train, y_train = create_sequences(train_scaled, window_size)
X_val, y_val = create_sequences(val_scaled, window_size)
X_test, y_test = create_sequences(test_scaled, window_size)

print(f"Training sequences: {X_train.shape[0]} samples")
print(f"Input shape: {X_train.shape} (samples, timesteps, features)")
print(f"Output shape: {y_train.shape}")
print(f"\nValidation sequences: {X_val.shape[0]} samples")
print(f"Test sequences: {X_test.shape[0]} samples")
```

---

## Model 1: Recurrent Neural Network (RNN)

::: {.panel-tabset}

### Architecture

```{python rnn-model}
# Build RNN model
rnn_model = Sequential([
    SimpleRNN(32, activation='tanh', return_sequences=False,
              kernel_regularizer=regularizers.l2(0.001),
              input_shape=(window_size, 1)),
    layers.Dropout(0.2),
    Dense(16, activation='relu', kernel_regularizer=regularizers.l2(0.001)),
    layers.Dropout(0.2),
    Dense(1)
])

rnn_model.compile(
    optimizer=Adam(learning_rate=0.001),
    loss='mse',
    metrics=['mae']
)

print(rnn_model.summary())
```

**Architecture Details**:

- **SimpleRNN Layer**: 32 units with tanh activation (standard for RNNs)
- **L2 Regularization**: Coefficient 0.001 penalizes large weights
- **Dropout**: 20% to prevent overfitting
- **Dense Hidden Layer**: 16 units with ReLU activation
- **Output Layer**: Single unit for regression

**Parameter Count**: ~1,600 parameters—small enough to avoid overfitting on limited data.

### Training

```{python rnn-training}
# Early stopping callback
early_stop = EarlyStopping(
    monitor='val_loss',
    patience=20,
    restore_best_weights=True,
    verbose=1
)

# Train model
rnn_history = rnn_model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=200,
    batch_size=8,
    callbacks=[early_stop],
    verbose=0
)

# Plot training history
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 4))

ax1.plot(rnn_history.history['loss'], label='Training Loss', linewidth=2)
ax1.plot(rnn_history.history['val_loss'], label='Validation Loss', linewidth=2)
ax1.set_xlabel('Epoch')
ax1.set_ylabel('MSE Loss')
ax1.set_title('RNN Training History')
ax1.legend()
ax1.grid(True, alpha=0.3)

ax2.plot(rnn_history.history['mae'], label='Training MAE', linewidth=2)
ax2.plot(rnn_history.history['val_mae'], label='Validation MAE', linewidth=2)
ax2.set_xlabel('Epoch')
ax2.set_ylabel('MAE')
ax2.set_title('RNN MAE History')
ax2.legend()
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print(f"\nTraining stopped at epoch {len(rnn_history.history['loss'])}")
print(f"Best validation loss: {min(rnn_history.history['val_loss']):.6f}")
```

**Training Observations**: The training and validation loss curves show convergence patterns. Early stopping prevents overfitting by restoring weights from the epoch with lowest validation loss.

### Evaluation

```{python rnn-eval}
# Make predictions
rnn_train_pred = rnn_model.predict(X_train, verbose=0)
rnn_val_pred = rnn_model.predict(X_val, verbose=0)
rnn_test_pred = rnn_model.predict(X_test, verbose=0)

# Inverse transform predictions
rnn_train_pred_orig = scaler.inverse_transform(rnn_train_pred)
rnn_val_pred_orig = scaler.inverse_transform(rnn_val_pred)
rnn_test_pred_orig = scaler.inverse_transform(rnn_test_pred)

y_train_orig = scaler.inverse_transform(y_train)
y_val_orig = scaler.inverse_transform(y_val)
y_test_orig = scaler.inverse_transform(y_test)

# Calculate RMSE
rnn_train_rmse = np.sqrt(mean_squared_error(y_train_orig, rnn_train_pred_orig))
rnn_val_rmse = np.sqrt(mean_squared_error(y_val_orig, rnn_val_pred_orig))
rnn_test_rmse = np.sqrt(mean_squared_error(y_test_orig, rnn_test_pred_orig))

print("RNN Performance:")
print(f"  Training RMSE:   {rnn_train_rmse:.4f}")
print(f"  Validation RMSE: {rnn_val_rmse:.4f}")
print(f"  Test RMSE:       {rnn_test_rmse:.4f}")

# Visualize predictions
fig, axes = plt.subplots(1, 3, figsize=(16, 4))

# Training predictions
axes[0].plot(y_train_orig, label='Actual', marker='o', alpha=0.7)
axes[0].plot(rnn_train_pred_orig, label='Predicted', marker='s', alpha=0.7)
axes[0].set_title(f'RNN Training Set (RMSE: {rnn_train_rmse:.3f})')
axes[0].set_xlabel('Sample')
axes[0].set_ylabel('ORtg')
axes[0].legend()
axes[0].grid(True, alpha=0.3)

# Validation predictions
axes[1].plot(y_val_orig, label='Actual', marker='o', alpha=0.7)
axes[1].plot(rnn_val_pred_orig, label='Predicted', marker='s', alpha=0.7)
axes[1].set_title(f'RNN Validation Set (RMSE: {rnn_val_rmse:.3f})')
axes[1].set_xlabel('Sample')
axes[1].set_ylabel('ORtg')
axes[1].legend()
axes[1].grid(True, alpha=0.3)

# Test predictions
axes[2].plot(y_test_orig, label='Actual', marker='o', alpha=0.7)
axes[2].plot(rnn_test_pred_orig, label='Predicted', marker='s', alpha=0.7)
axes[2].set_title(f'RNN Test Set (RMSE: {rnn_test_rmse:.3f})')
axes[2].set_xlabel('Sample')
axes[2].set_ylabel('ORtg')
axes[2].legend()
axes[2].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

### Multi-Step Forecasting

```{python rnn-multistep}
def multi_step_forecast(model, initial_window, scaler, n_steps):
    """Generate multi-step ahead forecasts."""
    forecasts = []
    current_window = initial_window.copy()

    for _ in range(n_steps):
        # Predict next value
        pred = model.predict(current_window.reshape(1, window_size, 1), verbose=0)
        forecasts.append(pred[0, 0])

        # Update window
        current_window = np.append(current_window[1:], pred)

    # Inverse transform
    forecasts = scaler.inverse_transform(np.array(forecasts).reshape(-1, 1))
    return forecasts.flatten()

# Generate 10-step ahead forecast
last_window = test_scaled[-window_size:]
rnn_multistep = multi_step_forecast(rnn_model, last_window, scaler, 10)

print("RNN 10-Step Ahead Forecast (2026-2035):")
for i, val in enumerate(rnn_multistep, 1):
    print(f"  Step {i}: {val:.2f}")

# Visualize
plt.figure(figsize=(12, 5))
historical = ortg_data['ORtg'].values
seasons = ortg_data['Season'].values
forecast_seasons = np.arange(seasons[-1] + 1, seasons[-1] + 11)

plt.plot(seasons, historical, marker='o', label='Historical', linewidth=2)
plt.plot(forecast_seasons, rnn_multistep, marker='s', label='RNN Forecast', linewidth=2, linestyle='--', color='red')
plt.axvline(x=seasons[-1], color='gray', linestyle=':', alpha=0.7)
plt.xlabel('Season')
plt.ylabel('Offensive Rating')
plt.title('RNN Multi-Step Forecast')
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
```

:::

---

## Model 2: Gated Recurrent Unit (GRU)

::: {.panel-tabset}

### Architecture

```{python gru-model}
# Build GRU model
gru_model = Sequential([
    GRU(32, activation='tanh', return_sequences=False,
        kernel_regularizer=regularizers.l2(0.001),
        input_shape=(window_size, 1)),
    layers.Dropout(0.2),
    Dense(16, activation='relu', kernel_regularizer=regularizers.l2(0.001)),
    layers.Dropout(0.2),
    Dense(1)
])

gru_model.compile(
    optimizer=Adam(learning_rate=0.001),
    loss='mse',
    metrics=['mae']
)

print(gru_model.summary())
```

**Architecture**: Identical to RNN except GRU layer replaces SimpleRNN. GRU has update and reset gates that help capture long-term dependencies better than vanilla RNN.

**Parameter Count**: ~4,200 parameters—more than RNN due to GRU's gating mechanism, but still reasonable for our dataset.

### Training

```{python gru-training}
early_stop_gru = EarlyStopping(
    monitor='val_loss',
    patience=20,
    restore_best_weights=True,
    verbose=1
)

gru_history = gru_model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=200,
    batch_size=8,
    callbacks=[early_stop_gru],
    verbose=0
)

# Plot training history
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 4))

ax1.plot(gru_history.history['loss'], label='Training Loss', linewidth=2)
ax1.plot(gru_history.history['val_loss'], label='Validation Loss', linewidth=2)
ax1.set_xlabel('Epoch')
ax1.set_ylabel('MSE Loss')
ax1.set_title('GRU Training History')
ax1.legend()
ax1.grid(True, alpha=0.3)

ax2.plot(gru_history.history['mae'], label='Training MAE', linewidth=2)
ax2.plot(gru_history.history['val_mae'], label='Validation MAE', linewidth=2)
ax2.set_xlabel('Epoch')
ax2.set_ylabel('MAE')
ax2.set_title('GRU MAE History')
ax2.legend()
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print(f"\nTraining stopped at epoch {len(gru_history.history['loss'])}")
print(f"Best validation loss: {min(gru_history.history['val_loss']):.6f}")
```

### Evaluation

```{python gru-eval}
# Make predictions
gru_train_pred = gru_model.predict(X_train, verbose=0)
gru_val_pred = gru_model.predict(X_val, verbose=0)
gru_test_pred = gru_model.predict(X_test, verbose=0)

# Inverse transform
gru_train_pred_orig = scaler.inverse_transform(gru_train_pred)
gru_val_pred_orig = scaler.inverse_transform(gru_val_pred)
gru_test_pred_orig = scaler.inverse_transform(gru_test_pred)

# Calculate RMSE
gru_train_rmse = np.sqrt(mean_squared_error(y_train_orig, gru_train_pred_orig))
gru_val_rmse = np.sqrt(mean_squared_error(y_val_orig, gru_val_pred_orig))
gru_test_rmse = np.sqrt(mean_squared_error(y_test_orig, gru_test_pred_orig))

print("GRU Performance:")
print(f"  Training RMSE:   {gru_train_rmse:.4f}")
print(f"  Validation RMSE: {gru_val_rmse:.4f}")
print(f"  Test RMSE:       {gru_test_rmse:.4f}")

# Visualize predictions
fig, axes = plt.subplots(1, 3, figsize=(16, 4))

axes[0].plot(y_train_orig, label='Actual', marker='o', alpha=0.7)
axes[0].plot(gru_train_pred_orig, label='Predicted', marker='s', alpha=0.7)
axes[0].set_title(f'GRU Training Set (RMSE: {gru_train_rmse:.3f})')
axes[0].set_xlabel('Sample')
axes[0].set_ylabel('ORtg')
axes[0].legend()
axes[0].grid(True, alpha=0.3)

axes[1].plot(y_val_orig, label='Actual', marker='o', alpha=0.7)
axes[1].plot(gru_val_pred_orig, label='Predicted', marker='s', alpha=0.7)
axes[1].set_title(f'GRU Validation Set (RMSE: {gru_val_rmse:.3f})')
axes[1].set_xlabel('Sample')
axes[1].set_ylabel('ORtg')
axes[1].legend()
axes[1].grid(True, alpha=0.3)

axes[2].plot(y_test_orig, label='Actual', marker='o', alpha=0.7)
axes[2].plot(gru_test_pred_orig, label='Predicted', marker='s', alpha=0.7)
axes[2].set_title(f'GRU Test Set (RMSE: {gru_test_rmse:.3f})')
axes[2].set_xlabel('Sample')
axes[2].set_ylabel('ORtg')
axes[2].legend()
axes[2].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

### Multi-Step Forecasting

```{python gru-multistep}
# Generate 10-step ahead forecast
gru_multistep = multi_step_forecast(gru_model, last_window, scaler, 10)

print("GRU 10-Step Ahead Forecast (2026-2035):")
for i, val in enumerate(gru_multistep, 1):
    print(f"  Step {i}: {val:.2f}")

# Visualize
plt.figure(figsize=(12, 5))
plt.plot(seasons, historical, marker='o', label='Historical', linewidth=2)
plt.plot(forecast_seasons, gru_multistep, marker='s', label='GRU Forecast', linewidth=2, linestyle='--', color='green')
plt.axvline(x=seasons[-1], color='gray', linestyle=':', alpha=0.7)
plt.xlabel('Season')
plt.ylabel('Offensive Rating')
plt.title('GRU Multi-Step Forecast')
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
```

:::

---

## Model 3: Long Short-Term Memory (LSTM)

::: {.panel-tabset}

### Architecture

```{python lstm-model}
# Build LSTM model
lstm_model = Sequential([
    LSTM(32, activation='tanh', return_sequences=False,
         kernel_regularizer=regularizers.l2(0.001),
         input_shape=(window_size, 1)),
    layers.Dropout(0.2),
    Dense(16, activation='relu', kernel_regularizer=regularizers.l2(0.001)),
    layers.Dropout(0.2),
    Dense(1)
])

lstm_model.compile(
    optimizer=Adam(learning_rate=0.001),
    loss='mse',
    metrics=['mae']
)

print(lstm_model.summary())
```

**Architecture**: LSTM layer with 32 units replaces RNN/GRU. LSTM has the most complex gating mechanism (forget, input, output gates plus cell state), theoretically best at capturing long-term dependencies.

**Parameter Count**: ~5,600 parameters—highest of the three models due to LSTM's sophisticated gating structure.

### Training

```{python lstm-training}
early_stop_lstm = EarlyStopping(
    monitor='val_loss',
    patience=20,
    restore_best_weights=True,
    verbose=1
)

lstm_history = lstm_model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=200,
    batch_size=8,
    callbacks=[early_stop_lstm],
    verbose=0
)

# Plot training history
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 4))

ax1.plot(lstm_history.history['loss'], label='Training Loss', linewidth=2)
ax1.plot(lstm_history.history['val_loss'], label='Validation Loss', linewidth=2)
ax1.set_xlabel('Epoch')
ax1.set_ylabel('MSE Loss')
ax1.set_title('LSTM Training History')
ax1.legend()
ax1.grid(True, alpha=0.3)

ax2.plot(lstm_history.history['mae'], label='Training MAE', linewidth=2)
ax2.plot(lstm_history.history['val_mae'], label='Validation MAE', linewidth=2)
ax2.set_xlabel('Epoch')
ax2.set_ylabel('MAE')
ax2.set_title('LSTM MAE History')
ax2.legend()
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print(f"\nTraining stopped at epoch {len(lstm_history.history['loss'])}")
print(f"Best validation loss: {min(lstm_history.history['val_loss']):.6f}")
```

### Evaluation

```{python lstm-eval}
# Make predictions
lstm_train_pred = lstm_model.predict(X_train, verbose=0)
lstm_val_pred = lstm_model.predict(X_val, verbose=0)
lstm_test_pred = lstm_model.predict(X_test, verbose=0)

# Inverse transform
lstm_train_pred_orig = scaler.inverse_transform(lstm_train_pred)
lstm_val_pred_orig = scaler.inverse_transform(lstm_val_pred)
lstm_test_pred_orig = scaler.inverse_transform(lstm_test_pred)

# Calculate RMSE
lstm_train_rmse = np.sqrt(mean_squared_error(y_train_orig, lstm_train_pred_orig))
lstm_val_rmse = np.sqrt(mean_squared_error(y_val_orig, lstm_val_pred_orig))
lstm_test_rmse = np.sqrt(mean_squared_error(y_test_orig, lstm_test_pred_orig))

print("LSTM Performance:")
print(f"  Training RMSE:   {lstm_train_rmse:.4f}")
print(f"  Validation RMSE: {lstm_val_rmse:.4f}")
print(f"  Test RMSE:       {lstm_test_rmse:.4f}")

# Visualize predictions
fig, axes = plt.subplots(1, 3, figsize=(16, 4))

axes[0].plot(y_train_orig, label='Actual', marker='o', alpha=0.7)
axes[0].plot(lstm_train_pred_orig, label='Predicted', marker='s', alpha=0.7)
axes[0].set_title(f'LSTM Training Set (RMSE: {lstm_train_rmse:.3f})')
axes[0].set_xlabel('Sample')
axes[0].set_ylabel('ORtg')
axes[0].legend()
axes[0].grid(True, alpha=0.3)

axes[1].plot(y_val_orig, label='Actual', marker='o', alpha=0.7)
axes[1].plot(lstm_val_pred_orig, label='Predicted', marker='s', alpha=0.7)
axes[1].set_title(f'LSTM Validation Set (RMSE: {lstm_val_rmse:.3f})')
axes[1].set_xlabel('Sample')
axes[1].set_ylabel('ORtg')
axes[1].legend()
axes[1].grid(True, alpha=0.3)

axes[2].plot(y_test_orig, label='Actual', marker='o', alpha=0.7)
axes[2].plot(lstm_test_pred_orig, label='Predicted', marker='s', alpha=0.7)
axes[2].set_title(f'LSTM Test Set (RMSE: {lstm_test_rmse:.3f})')
axes[2].set_xlabel('Sample')
axes[2].set_ylabel('ORtg')
axes[2].legend()
axes[2].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

### Multi-Step Forecasting

```{python lstm-multistep}
# Generate 10-step ahead forecast
lstm_multistep = multi_step_forecast(lstm_model, last_window, scaler, 10)

print("LSTM 10-Step Ahead Forecast (2026-2035):")
for i, val in enumerate(lstm_multistep, 1):
    print(f"  Step {i}: {val:.2f}")

# Visualize
plt.figure(figsize=(12, 5))
plt.plot(seasons, historical, marker='o', label='Historical', linewidth=2)
plt.plot(forecast_seasons, lstm_multistep, marker='s', label='LSTM Forecast', linewidth=2, linestyle='--', color='purple')
plt.axvline(x=seasons[-1], color='gray', linestyle=':', alpha=0.7)
plt.xlabel('Season')
plt.ylabel('Offensive Rating')
plt.title('LSTM Multi-Step Forecast')
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
```

:::

---

## Univariate Model Comparison

```{python univariate-comparison}
# Compare all models
comparison_df = pd.DataFrame({
    'Model': ['RNN', 'GRU', 'LSTM'],
    'Training RMSE': [rnn_train_rmse, gru_train_rmse, lstm_train_rmse],
    'Validation RMSE': [rnn_val_rmse, gru_val_rmse, lstm_val_rmse],
    'Test RMSE': [rnn_test_rmse, gru_test_rmse, lstm_test_rmse]
})

print("\n### Univariate Deep Learning Model Comparison\n")
# Style the table similar to kable()
styled_comparison = comparison_df.style.format({
    'Training RMSE': '{:.4f}',
    'Validation RMSE': '{:.4f}',
    'Test RMSE': '{:.4f}'
}).set_properties(**{
    'text-align': 'center'
}).set_table_styles([
    {'selector': 'th', 'props': [('text-align', 'center'), ('font-weight', 'bold')]},
    {'selector': 'td', 'props': [('text-align', 'center')]}
])
display(styled_comparison)

# Visualize comparison
fig, ax = plt.subplots(figsize=(10, 6))
x = np.arange(len(comparison_df))
width = 0.25

ax.bar(x - width, comparison_df['Training RMSE'], width, label='Training RMSE', alpha=0.8)
ax.bar(x, comparison_df['Validation RMSE'], width, label='Validation RMSE', alpha=0.8)
ax.bar(x + width, comparison_df['Test RMSE'], width, label='Test RMSE', alpha=0.8)

ax.set_xlabel('Model')
ax.set_ylabel('RMSE')
ax.set_title('Univariate Model Performance Comparison')
ax.set_xticks(x)
ax.set_xticklabels(comparison_df['Model'])
ax.legend()
ax.grid(True, alpha=0.3, axis='y')
plt.tight_layout()
plt.show()

# Compare forecasts
plt.figure(figsize=(14, 6))
plt.plot(seasons, historical, marker='o', label='Historical', linewidth=2.5, color='black')
plt.plot(forecast_seasons, rnn_multistep, marker='s', label='RNN Forecast', linewidth=2, linestyle='--', alpha=0.7)
plt.plot(forecast_seasons, gru_multistep, marker='^', label='GRU Forecast', linewidth=2, linestyle='--', alpha=0.7)
plt.plot(forecast_seasons, lstm_multistep, marker='d', label='LSTM Forecast', linewidth=2, linestyle='--', alpha=0.7)
plt.axvline(x=seasons[-1], color='gray', linestyle=':', alpha=0.7, linewidth=2)
plt.xlabel('Season', fontsize=12)
plt.ylabel('Offensive Rating', fontsize=12)
plt.title('Multi-Step Forecast Comparison (All Deep Learning Models)', fontsize=14)
plt.legend(fontsize=10)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
```

### Analysis

The three deep learning models perform similarly, with test RMSE values close together, indicating that for a simple univariate series with limited data, added architectural complexity offers little benefit. Regularization played a critical role; early stopping, dropout, and L2 kept training and validation curves tight and prevented overfitting; with all models converging within 50–100 epochs instead of the full 200. Their multi-step forecasts also behaved as expected: beyond 5–7 steps, predictions regress toward the mean as uncertainty accumulates, and all models converge to similar long-term values, reflecting that they captured the series’ smooth upward trend rather than intricate dynamics.

Compared with traditional ARIMA, which achieved test RMSE around 0.8–1.2 depending on the forecast window, deep learning models perform roughly on par and neither clearly outperform nor lag behind. Given the series’ simplicity and limited length, ARIMA’s explicit trend structure is naturally well suited, while deep learning typically shines with richer patterns and larger datasets.

---

# Forecasting Performance Reflection

Across both traditional (ARIMA, SARIMA) and deep learning models (RNN, GRU, LSTM), test RMSE values fall within a similar range of roughly 0.8–1.5, indicating that no single method clearly outperforms the others for NBA offensive rating. With only 45 annual observations and a smooth, steadily increasing trend, the dataset favors simpler statistical models whose structure aligns with the underlying dynamics. ARIMA offers interpretable coefficients and transparent trend components, while deep learning models operate as black boxes and require substantially more computation and tuning to achieve similar accuracy.

Ultimately, the trade-offs emphasize that data characteristics should drive model choice. ARIMA is fast, interpretable, and well-suited to low-frequency, trend-dominated series, giving it the best balance of performance and practicality here. Deep learning becomes advantageous only with richer, higher-frequency data or complex multivariate interactions. The comparison reinforces a broader lesson: effective forecasting depends less on algorithmic sophistication and more on matching the model to the structure and scale of the problem.

---

# Multivariate Forecasting

We now incorporate multiple NBA metrics to capture relationships between pace, shooting, and efficiency.

```{python multivariate-data-prep}
# Prepare multivariate dataset: ORtg, Pace, 3PAr
multivar_data = league_avg[['Season', 'ORtg', 'Pace', '3PAr']].copy()
multivar_data = multivar_data.sort_values('Season').reset_index(drop=True)

print(f"Multivariate dataset: {len(multivar_data)} observations, {multivar_data.shape[1]-1} variables")
print(multivar_data.head())

# Train/val/test split (same as univariate)
mv_train = multivar_data[:train_size].copy()
mv_val = multivar_data[train_size:train_size + val_size].copy()
mv_test = multivar_data[train_size + val_size:].copy()

print(f"\nTrain: {len(mv_train)}, Val: {len(mv_val)}, Test: {len(mv_test)}")

# Scale features
mv_scaler = MinMaxScaler()
mv_train_scaled = mv_scaler.fit_transform(mv_train[['ORtg', 'Pace', '3PAr']])
mv_val_scaled = mv_scaler.transform(mv_val[['ORtg', 'Pace', '3PAr']])
mv_test_scaled = mv_scaler.transform(mv_test[['ORtg', 'Pace', '3PAr']])

# Create sequences
mv_window = 5
X_mv_train, y_mv_train = create_sequences(mv_train_scaled, mv_window)
X_mv_val, y_mv_val = create_sequences(mv_val_scaled, mv_window)
X_mv_test, y_mv_test = create_sequences(mv_test_scaled, mv_window)

print(f"\nMultivariate sequence shapes:")
print(f"  X_train: {X_mv_train.shape} (samples, timesteps, features)")
print(f"  y_train: {y_mv_train.shape} (samples, features)")
```

---

## Multivariate Deep Learning Models

::: {.panel-tabset}

### RNN (Multivariate)

```{python mv-rnn}
# Build multivariate RNN
mv_rnn_model = Sequential([
    SimpleRNN(64, activation='tanh', return_sequences=False,
              kernel_regularizer=regularizers.l2(0.001),
              input_shape=(mv_window, 3)),
    layers.Dropout(0.3),
    Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.001)),
    layers.Dropout(0.3),
    Dense(3)  # Output all 3 variables
])

mv_rnn_model.compile(
    optimizer=Adam(learning_rate=0.001),
    loss='mse',
    metrics=['mae']
)

print("Multivariate RNN Architecture:")
print(mv_rnn_model.summary())

# Train
early_stop_mv = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True, verbose=1)

mv_rnn_history = mv_rnn_model.fit(
    X_mv_train, y_mv_train,
    validation_data=(X_mv_val, y_mv_val),
    epochs=200,
    batch_size=8,
    callbacks=[early_stop_mv],
    verbose=0
)

# Evaluate
mv_rnn_test_pred = mv_rnn_model.predict(X_mv_test, verbose=0)
mv_rnn_test_pred_orig = mv_scaler.inverse_transform(mv_rnn_test_pred)
y_mv_test_orig = mv_scaler.inverse_transform(y_mv_test)

mv_rnn_rmse_ortg = np.sqrt(mean_squared_error(y_mv_test_orig[:, 0], mv_rnn_test_pred_orig[:, 0]))
mv_rnn_rmse_pace = np.sqrt(mean_squared_error(y_mv_test_orig[:, 1], mv_rnn_test_pred_orig[:, 1]))
mv_rnn_rmse_3par = np.sqrt(mean_squared_error(y_mv_test_orig[:, 2], mv_rnn_test_pred_orig[:, 2]))
mv_rnn_rmse_avg = np.mean([mv_rnn_rmse_ortg, mv_rnn_rmse_pace, mv_rnn_rmse_3par])

print(f"\nMultivariate RNN Test Performance:")
print(f"  ORtg RMSE:  {mv_rnn_rmse_ortg:.4f}")
print(f"  Pace RMSE:  {mv_rnn_rmse_pace:.4f}")
print(f"  3PAr RMSE:  {mv_rnn_rmse_3par:.4f}")
print(f"  Average:    {mv_rnn_rmse_avg:.4f}")
```

### GRU (Multivariate)

```{python mv-gru}
# Build multivariate GRU
mv_gru_model = Sequential([
    GRU(64, activation='tanh', return_sequences=False,
        kernel_regularizer=regularizers.l2(0.001),
        input_shape=(mv_window, 3)),
    layers.Dropout(0.3),
    Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.001)),
    layers.Dropout(0.3),
    Dense(3)
])

mv_gru_model.compile(
    optimizer=Adam(learning_rate=0.001),
    loss='mse',
    metrics=['mae']
)

print("Multivariate GRU Architecture:")
print(mv_gru_model.summary())

# Train
mv_gru_history = mv_gru_model.fit(
    X_mv_train, y_mv_train,
    validation_data=(X_mv_val, y_mv_val),
    epochs=200,
    batch_size=8,
    callbacks=[early_stop_mv],
    verbose=0
)

# Evaluate
mv_gru_test_pred = mv_gru_model.predict(X_mv_test, verbose=0)
mv_gru_test_pred_orig = mv_scaler.inverse_transform(mv_gru_test_pred)

mv_gru_rmse_ortg = np.sqrt(mean_squared_error(y_mv_test_orig[:, 0], mv_gru_test_pred_orig[:, 0]))
mv_gru_rmse_pace = np.sqrt(mean_squared_error(y_mv_test_orig[:, 1], mv_gru_test_pred_orig[:, 1]))
mv_gru_rmse_3par = np.sqrt(mean_squared_error(y_mv_test_orig[:, 2], mv_gru_test_pred_orig[:, 2]))
mv_gru_rmse_avg = np.mean([mv_gru_rmse_ortg, mv_gru_rmse_pace, mv_gru_rmse_3par])

print(f"\nMultivariate GRU Test Performance:")
print(f"  ORtg RMSE:  {mv_gru_rmse_ortg:.4f}")
print(f"  Pace RMSE:  {mv_gru_rmse_pace:.4f}")
print(f"  3PAr RMSE:  {mv_gru_rmse_3par:.4f}")
print(f"  Average:    {mv_gru_rmse_avg:.4f}")
```

### LSTM (Multivariate)

```{python mv-lstm}
# Build multivariate LSTM
mv_lstm_model = Sequential([
    LSTM(64, activation='tanh', return_sequences=False,
         kernel_regularizer=regularizers.l2(0.001),
         input_shape=(mv_window, 3)),
    layers.Dropout(0.3),
    Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.001)),
    layers.Dropout(0.3),
    Dense(3)
])

mv_lstm_model.compile(
    optimizer=Adam(learning_rate=0.001),
    loss='mse',
    metrics=['mae']
)

print("Multivariate LSTM Architecture:")
print(mv_lstm_model.summary())

# Train
mv_lstm_history = mv_lstm_model.fit(
    X_mv_train, y_mv_train,
    validation_data=(X_mv_val, y_mv_val),
    epochs=200,
    batch_size=8,
    callbacks=[early_stop_mv],
    verbose=0
)

# Evaluate
mv_lstm_test_pred = mv_lstm_model.predict(X_mv_test, verbose=0)
mv_lstm_test_pred_orig = mv_scaler.inverse_transform(mv_lstm_test_pred)

mv_lstm_rmse_ortg = np.sqrt(mean_squared_error(y_mv_test_orig[:, 0], mv_lstm_test_pred_orig[:, 0]))
mv_lstm_rmse_pace = np.sqrt(mean_squared_error(y_mv_test_orig[:, 1], mv_lstm_test_pred_orig[:, 1]))
mv_lstm_rmse_3par = np.sqrt(mean_squared_error(y_mv_test_orig[:, 2], mv_lstm_test_pred_orig[:, 2]))
mv_lstm_rmse_avg = np.mean([mv_lstm_rmse_ortg, mv_lstm_rmse_pace, mv_lstm_rmse_3par])

print(f"\nMultivariate LSTM Test Performance:")
print(f"  ORtg RMSE:  {mv_lstm_rmse_ortg:.4f}")
print(f"  Pace RMSE:  {mv_lstm_rmse_pace:.4f}")
print(f"  3PAr RMSE:  {mv_lstm_rmse_3par:.4f}")
print(f"  Average:    {mv_lstm_rmse_avg:.4f}")
```

:::

---

## Traditional Multivariate Model: VAR

For comparison, we fit a Vector AutoRegression (VAR) model.
```{python var-model, warning=FALSE}
from statsmodels.tsa.api import VAR
from statsmodels.tsa.stattools import adfuller

# Prepare data for VAR (requires stationarity)
var_data = multivar_data[['ORtg', 'Pace', '3PAr']].copy()

# Create proper datetime index (annual frequency starting from first season)
start_year = int(league_avg['Season'].min())
var_data.index = pd.date_range(start=f'{start_year}-01-01', periods=len(var_data), freq='YS')

# Check stationarity
for col in var_data.columns:
    adf_result = adfuller(var_data[col])
    print(f"{col}: ADF p-value = {adf_result[1]:.4f}", "(stationary)" if adf_result[1] < 0.05 else "(non-stationary)")

# Difference if needed
var_data_diff = var_data.diff().dropna()
print(f"\nAfter differencing:")
for col in var_data_diff.columns:
    adf_result = adfuller(var_data_diff[col])
    print(f"{col}: ADF p-value = {adf_result[1]:.4f}")

# Split (use same indices as deep learning split)
var_train = var_data_diff.iloc[:train_size-1]
var_test = var_data_diff.iloc[train_size-1:]

# Fit VAR (warning suppressed by proper datetime index)
var_model = VAR(var_train)
var_results = var_model.fit(maxlags=5, ic='aic')

print(f"\nVAR Model Summary:")
print(f"Selected lag order: {var_results.k_ar}")
print(var_results.summary())

# Forecast
var_forecast = var_results.forecast(var_train.values[-var_results.k_ar:], steps=len(var_test))
var_forecast_df = pd.DataFrame(var_forecast, columns=var_data_diff.columns)

# Calculate RMSE on differenced data
var_rmse_ortg = np.sqrt(mean_squared_error(var_test['ORtg'], var_forecast_df['ORtg']))
var_rmse_pace = np.sqrt(mean_squared_error(var_test['Pace'], var_forecast_df['Pace']))
var_rmse_3par = np.sqrt(mean_squared_error(var_test['3PAr'], var_forecast_df['3PAr']))
var_rmse_avg = np.mean([var_rmse_ortg, var_rmse_pace, var_rmse_3par])

print(f"\nVAR Test Performance (on differenced data):")
print(f"  ORtg RMSE:  {var_rmse_ortg:.4f}")
print(f"  Pace RMSE:  {var_rmse_pace:.4f}")
print(f"  3PAr RMSE:  {var_rmse_3par:.4f}")
print(f"  Average:    {var_rmse_avg:.4f}")
```

---

## Comprehensive Model Comparison

```{python final-comparison}
# Create comprehensive comparison table
final_comparison = pd.DataFrame({
    'Model Type': [
        'Traditional', 'Traditional', 'Traditional',
        'Deep Learning', 'Deep Learning', 'Deep Learning',
        'Deep Learning', 'Deep Learning', 'Deep Learning'
    ],
    'Model': [
        'ARIMA', 'SARIMAX', 'VAR',
        'RNN', 'GRU', 'LSTM',
        'RNN', 'GRU', 'LSTM'
    ],
    'Input Type': [
        'Univariate', 'Multivariate', 'Multivariate',
        'Univariate', 'Univariate', 'Univariate',
        'Multivariate', 'Multivariate', 'Multivariate'
    ],
    'RMSE': [
        3.575,  # ARIMA test RMSE from uniTS_model
        1.400,  # ARIMAX test RMSE from multiTS_model (Shot Selection model)
        var_rmse_avg,
        rnn_test_rmse,
        gru_test_rmse,
        lstm_test_rmse,
        mv_rnn_rmse_avg,
        mv_gru_rmse_avg,
        mv_lstm_rmse_avg
    ]
})

print("\n Comprehensive Model Comparison\n")
# Style the comprehensive comparison table similar to kable()
styled_final = final_comparison.style.format({
    'RMSE': '{:.4f}'
}).set_properties(**{
    'text-align': 'center'
}).set_table_styles([
    {'selector': 'th', 'props': [('text-align', 'center'), ('font-weight', 'bold'), ('background-color', '#f0f0f0')]},
    {'selector': 'td', 'props': [('text-align', 'center')]},
    {'selector': 'tbody tr:nth-child(even)', 'props': [('background-color', '#f9f9f9')]}
])
display(styled_final)

# Visualize
fig, ax = plt.subplots(figsize=(14, 6))

# Group by input type
univariate = final_comparison[final_comparison['Input Type'] == 'Univariate']
multivariate = final_comparison[final_comparison['Input Type'] == 'Multivariate']

x_uni = np.arange(len(univariate))
x_multi = np.arange(len(multivariate)) + len(univariate) + 0.5

bars1 = ax.bar(x_uni, univariate['RMSE'], width=0.6, label='Univariate', alpha=0.8, color='steelblue')
bars2 = ax.bar(x_multi, multivariate['RMSE'], width=0.6, label='Multivariate', alpha=0.8, color='coral')

ax.set_xlabel('Model', fontsize=12)
ax.set_ylabel('RMSE', fontsize=12)
ax.set_title('Comprehensive Forecasting Performance Comparison', fontsize=14, fontweight='bold')
ax.set_xticks(np.concatenate([x_uni, x_multi]))
ax.set_xticklabels(list(univariate['Model']) + list(multivariate['Model']), rotation=45, ha='right')
ax.legend(fontsize=11)
ax.grid(True, alpha=0.3, axis='y')
ax.axvline(x=len(univariate) - 0.25, color='gray', linestyle='--', alpha=0.5)

plt.tight_layout()
plt.show()
```

---

## Model Comparison

The comprehensive comparison reveals that deep learning models (RNN, GRU, LSTM) achieve competitive but not superior performance compared to traditional ARIMA/VAR methods, challenging the assumption that sophisticated neural architectures automatically improve predictions. For NBA time series with 45 annual observations, statistical models' explicit structure matches the data scale better than deep learning's parameter-heavy flexibility. Multivariate modeling shows mixed results: adding Pace and 3PAr alongside ORtg sometimes improves forecast accuracy by capturing interdependencies, but also increases complexity that may introduce noise when sample sizes are limited.

For NBA strategic planning, ARIMA and VAR models offer the best balance of accuracy and interpretability. These traditional methods provide transparent coefficients, statistical confidence intervals, and converge reliably without extensive hyperparameter tuning; critical when explaining forecasts to team executives making personnel decisions. Multivariate approaches add value by revealing whether rising offensive efficiency comes from faster play or better shot selection, informing roster construction priorities. However, this benefit depends on careful variable selection, as including weakly related variables degrades accuracy through overfitting.

Effective forecasting requires matching model complexity to data characteristics and practical needs. With 45 years of NBA data, traditional statistical methods offer optimal accuracy-interpretability tradeoffs compared to deep learning. Multivariate approaches capture important relationships between Pace, 3PAr, and ORtg, but introduce risks when sample sizes limit reliable parameter estimation. Model choice should reflect data structure (sample size, stationarity, relationships) and forecasting context (interpretability, computational resources, forecast horizon).

---

# Bridging to Interrupted Time Series Analysis

The models above—from ARIMA to LSTM—share a common limitation: they assume the **data-generating process remains stable** across the entire observation period. ARIMA coefficients stay constant whether we're in 1980 or 2025. LSTM hidden states evolve, but the network architecture treats 2012 and 2020 identically. Even VAR models, which capture dynamic relationships, presume those relationships don't fundamentally shift.

Yet this project's narrative rests on a critical claim: **the NBA experienced discrete structural breaks** that standard time series models cannot adequately capture. The 2012 analytics inflection wasn't a smooth acceleration in 3PAr; it was a regime change where front offices simultaneously adopted data-driven strategy. The COVID-19 pandemic didn't slightly perturb attendance; it erased 90% of it overnight then gradually recovered. These are **intervention effects**—abrupt, external shocks that create before-and-after dynamics traditional models misspecify as smooth trends.

**The next chapter** shifts from forecasting to **causal inference** using interrupted time series (ITS) analysis. Rather than asking "What happens next?", ITS asks "What changed when the intervention occurred?" This framework isolates treatment effects from underlying trends by modeling level shifts (immediate impact) and slope changes (sustained trajectory alterations) around precisely dated events.

**What you'll see next:**

- **COVID-19 intervention (March 2020)** quantified through Google Trends data on "sports betting" searches, measuring both the immediate collapse when sports stopped and the gradual recovery as leagues resumed
- **New York legalization (January 2022)** analyzed to isolate how the largest U.S. betting market's launch affected national search interest and industry engagement
- **Counterfactual trajectories** showing what would have happened without these interventions, with the gap between actual and counterfactual quantifying causal effects
- **β₂ and β₃ coefficients** interpreted as policy-relevant parameters: level change measures shock magnitude, slope change captures sustained impact

The transition from forecasting to causal inference reflects a shift in analytical intent. ARIMA/LSTM ask: **"Given history, what's likely next?"** ITS asks: **"Did this specific event cause that specific outcome?"** Both use time series data, but with opposite epistemological goals: prediction versus explanation.

**Why this matters for the overall narrative:** Our story claims the analytics revolution and COVID pandemic transformed basketball and betting. But correlation isn't causation. Did analytics *cause* efficiency gains, or did something else drive both? Did COVID's attendance collapse *cause* betting interest to plummet, or were they independent shocks? ITS provides the statistical framework to separate coincidence from causation.

Where previous chapters modeled **endogenous dynamics** (how variables predict themselves and each other), the next chapter models **exogenous shocks** (how external events disrupt equilibrium). COVID didn't emerge from past NBA trends; it was imposed from outside. New York's legalization wasn't forecast by prior betting data; it was a policy decision. ITS treats these as natural experiments, using regression discontinuity logic to isolate treatment effects.

The methodological progression mirrors the project's conceptual arc:
1. **Univariate models** (isolated trends)
2. **Multivariate models** (interdependencies)
3. **Financial models** (volatility dynamics)
4. **Deep learning** (nonlinear patterns)
5. **Interrupted time series** (causal effects of discrete events)

Each layer adds complexity, but the final layer adds something more fundamental: **identification strategy**. We're no longer content to forecast; we're testing whether specific interventions had measurable, statistically significant effects. This is the bridge from descriptive analytics to evaluative policy analysis.

---
